Using Theano backend.
Using Theano backend.
Using Theano backend.
[2020-08-28 15:09:25,408 INFO] Loading data from data/814_train.h5
[2020-08-28 15:09:25,660 INFO] Loading data from data/824_train.h5
[2020-08-28 15:09:25,761 INFO] Loading data from data/812_train.h5
Using Theano backend.
[2020-08-28 15:09:29,848 INFO] Loading data from data/naturalsplittrainingsample.h5
[2020-08-28 15:09:38,299 INFO] Building model from share/reference_number.py
[2020-08-28 15:09:40,024 INFO] Building model from share/reference_number.py
[2020-08-28 15:09:42,688 INFO] Compiling model
[2020-08-28 15:09:42,697 INFO] Fitting model
[2020-08-28 15:09:44,608 INFO] Compiling model
[2020-08-28 15:09:44,646 INFO] Fitting model
WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.
[2020-08-28 15:09:45,320 WARNING] We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.
[2020-08-28 15:09:45,724 INFO] Building model from share/reference_number.py
INFO (theano.gof.compilelock): Waiting for existing lock by process '13590' (I am process '49753')
[2020-08-28 15:09:49,340 INFO] Waiting for existing lock by process '13590' (I am process '49753')
INFO (theano.gof.compilelock): To manually release the lock, delete /global/u2/c/chkoda/.theano/compiledir_Linux-4.12-lp150.12.82-default-x86_64-with-glibc2.2.5-x86_64-2.7.18-64/lock_dir
[2020-08-28 15:09:49,340 INFO] To manually release the lock, delete /global/u2/c/chkoda/.theano/compiledir_Linux-4.12-lp150.12.82-default-x86_64-with-glibc2.2.5-x86_64-2.7.18-64/lock_dir
[2020-08-28 15:09:49,623 INFO] Building model from share/reference_number.py
INFO (theano.gof.compilelock): Waiting for existing lock by process '20298' (I am process '49753')
[2020-08-28 15:09:54,715 INFO] Waiting for existing lock by process '20298' (I am process '49753')
INFO (theano.gof.compilelock): To manually release the lock, delete /global/u2/c/chkoda/.theano/compiledir_Linux-4.12-lp150.12.82-default-x86_64-with-glibc2.2.5-x86_64-2.7.18-64/lock_dir
[2020-08-28 15:09:54,715 INFO] To manually release the lock, delete /global/u2/c/chkoda/.theano/compiledir_Linux-4.12-lp150.12.82-default-x86_64-with-glibc2.2.5-x86_64-2.7.18-64/lock_dir
[2020-08-28 15:09:56,539 INFO] Compiling model
[2020-08-28 15:09:56,548 INFO] Fitting model
WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.
[2020-08-28 15:09:57,136 WARNING] We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.
WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.
[2020-08-28 15:10:04,329 WARNING] We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.
[2020-08-28 15:10:08,110 INFO] Compiling model
[2020-08-28 15:10:08,175 INFO] Fitting model
WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.
[2020-08-28 15:10:10,724 WARNING] We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.
Train on 10800000 samples, validate on 1200000 samples
Epoch 1/1000
 - 62s - loss: 0.4551 - val_loss: 0.3078
Train on 11131813 samples, validate on 1236869 samples
Epoch 1/1000
 - 62s - loss: 0.4633 - val_loss: 2.3457
Train on 15300000 samples, validate on 1700000 samples
Epoch 1/1000
 - 86s - loss: 0.5027 - val_loss: 0.3140
Train on 17999998 samples, validate on 2000000 samples
Epoch 1/1000
 - 104s - loss: 0.4499 - val_loss: 1.9577

Epoch 00001: val_loss improved from inf to 0.30778, saving model to modelWeights/812_sigmoid.h5
Epoch 2/1000
 - 62s - loss: 0.4161 - val_loss: 0.2974

Epoch 00001: val_loss improved from inf to 2.34566, saving model to modelWeights/814_sigmoid.h5
Epoch 2/1000
 - 64s - loss: 0.4279 - val_loss: 1.9283

Epoch 00001: val_loss improved from inf to 0.31402, saving model to modelWeights/naturalsplit_sigmoid.h5
Epoch 2/1000
 - 87s - loss: 0.4652 - val_loss: 0.3649

Epoch 00002: val_loss improved from 0.30778 to 0.29742, saving model to modelWeights/812_sigmoid.h5
Epoch 3/1000
 - 62s - loss: 0.4098 - val_loss: 0.2972

Epoch 00002: val_loss improved from 2.34566 to 1.92833, saving model to modelWeights/814_sigmoid.h5
Epoch 3/1000
 - 64s - loss: 0.4202 - val_loss: 1.8323

Epoch 00001: val_loss improved from inf to 1.95775, saving model to modelWeights/824_sigmoid.h5
Epoch 2/1000
 - 95s - loss: 0.4196 - val_loss: 1.9999

Epoch 00003: val_loss improved from 0.29742 to 0.29718, saving model to modelWeights/812_sigmoid.h5
Epoch 4/1000
 - 63s - loss: 0.4065 - val_loss: 0.3039

Epoch 00002: val_loss did not improve
Epoch 3/1000
 - 83s - loss: 0.4578 - val_loss: 0.3318

Epoch 00003: val_loss improved from 1.92833 to 1.83227, saving model to modelWeights/814_sigmoid.h5
Epoch 4/1000
 - 63s - loss: 0.4154 - val_loss: 1.8003

Epoch 00004: val_loss did not improve
Epoch 5/1000
 - 63s - loss: 0.4045 - val_loss: 0.2918

Epoch 00002: val_loss did not improve
Epoch 3/1000
 - 95s - loss: 0.4141 - val_loss: 2.0403

Epoch 00004: val_loss improved from 1.83227 to 1.80032, saving model to modelWeights/814_sigmoid.h5
Epoch 5/1000
 - 63s - loss: 0.4116 - val_loss: 1.9023

Epoch 00003: val_loss did not improve
Epoch 4/1000
 - 86s - loss: 0.4541 - val_loss: 0.3779

Epoch 00005: val_loss improved from 0.29718 to 0.29181, saving model to modelWeights/812_sigmoid.h5
Epoch 6/1000
 - 63s - loss: 0.4029 - val_loss: 0.2919

Epoch 00005: val_loss did not improve
Epoch 6/1000
 - 62s - loss: 0.4088 - val_loss: 1.7806

Epoch 00003: val_loss did not improve
Epoch 4/1000
 - 94s - loss: 0.4109 - val_loss: 2.1198

Epoch 00004: val_loss did not improve
Epoch 5/1000
 - 84s - loss: 0.4516 - val_loss: 0.3583

Epoch 00006: val_loss did not improve
Epoch 7/1000
 - 63s - loss: 0.4016 - val_loss: 0.2902

Epoch 00006: val_loss improved from 1.80032 to 1.78061, saving model to modelWeights/814_sigmoid.h5
Epoch 7/1000
 - 63s - loss: 0.4067 - val_loss: 2.0307

Epoch 00007: val_loss improved from 0.29181 to 0.29015, saving model to modelWeights/812_sigmoid.h5
Epoch 8/1000
 - 64s - loss: 0.4006 - val_loss: 0.2899

Epoch 00004: val_loss did not improve
Epoch 5/1000
 - 94s - loss: 0.4084 - val_loss: 2.0249

Epoch 00005: val_loss did not improve
Epoch 6/1000
 - 83s - loss: 0.4497 - val_loss: 0.3929

Epoch 00007: val_loss did not improve
Epoch 8/1000
 - 62s - loss: 0.4049 - val_loss: 1.8140

Epoch 00008: val_loss improved from 0.29015 to 0.28995, saving model to modelWeights/812_sigmoid.h5
Epoch 9/1000
 - 64s - loss: 0.3997 - val_loss: 0.2988

Epoch 00008: val_loss did not improve
Epoch 9/1000
 - 64s - loss: 0.4037 - val_loss: 1.8602

Epoch 00005: val_loss did not improve
Epoch 6/1000
 - 94s - loss: 0.4065 - val_loss: 1.9352

Epoch 00006: val_loss did not improve
Epoch 7/1000
 - 85s - loss: 0.4484 - val_loss: 0.3406

Epoch 00009: val_loss did not improve
Epoch 10/1000
 - 64s - loss: 0.3990 - val_loss: 0.2905

Epoch 00009: val_loss did not improve
Epoch 10/1000
 - 63s - loss: 0.4028 - val_loss: 2.1380

Epoch 00007: val_loss did not improve
Epoch 8/1000
 - 86s - loss: 0.4474 - val_loss: 0.3428

Epoch 00006: val_loss improved from 1.95775 to 1.93524, saving model to modelWeights/824_sigmoid.h5
Epoch 7/1000
 - 94s - loss: 0.4049 - val_loss: 1.9986

Epoch 00010: val_loss did not improve
Epoch 11/1000
 - 61s - loss: 0.3983 - val_loss: 0.2896

Epoch 00010: val_loss did not improve
Epoch 11/1000
 - 62s - loss: 0.4020 - val_loss: 1.9036

Epoch 00011: val_loss improved from 0.28995 to 0.28958, saving model to modelWeights/812_sigmoid.h5
Epoch 12/1000
 - 63s - loss: 0.3977 - val_loss: 0.2877

Epoch 00011: val_loss did not improve
Epoch 12/1000
 - 62s - loss: 0.4013 - val_loss: 1.8134

Epoch 00008: val_loss did not improve
Epoch 9/1000
 - 83s - loss: 0.4466 - val_loss: 0.2998

Epoch 00007: val_loss did not improve
Epoch 8/1000
 - 95s - loss: 0.4037 - val_loss: 2.0409

Epoch 00012: val_loss improved from 0.28958 to 0.28766, saving model to modelWeights/812_sigmoid.h5
Epoch 13/1000
 - 63s - loss: 0.3972 - val_loss: 0.2913

Epoch 00012: val_loss did not improve
Epoch 13/1000
 - 62s - loss: 0.4008 - val_loss: 2.0196

Epoch 00009: val_loss improved from 0.31402 to 0.29981, saving model to modelWeights/naturalsplit_sigmoid.h5
Epoch 10/1000
 - 86s - loss: 0.4458 - val_loss: 0.3489

Epoch 00008: val_loss did not improve
Epoch 9/1000
 - 94s - loss: 0.4028 - val_loss: 1.9570

Epoch 00013: val_loss did not improve
Epoch 14/1000
 - 64s - loss: 0.3967 - val_loss: 0.2894

Epoch 00013: val_loss did not improve
Epoch 14/1000
 - 62s - loss: 0.4003 - val_loss: 1.9527

Epoch 00010: val_loss did not improve
Epoch 11/1000
 - 86s - loss: 0.4451 - val_loss: 0.3549

Epoch 00014: val_loss did not improve
Epoch 15/1000
 - 64s - loss: 0.3963 - val_loss: 0.2869

Epoch 00014: val_loss did not improve
Epoch 15/1000
 - 63s - loss: 0.3998 - val_loss: 2.0077

Epoch 00009: val_loss did not improve
Epoch 10/1000
 - 94s - loss: 0.4020 - val_loss: 1.9262

Epoch 00015: val_loss improved from 0.28766 to 0.28688, saving model to modelWeights/812_sigmoid.h5
Epoch 16/1000
 - 64s - loss: 0.3960 - val_loss: 0.2874

Epoch 00015: val_loss did not improve
Epoch 16/1000
 - 63s - loss: 0.3994 - val_loss: 2.0946

Epoch 00011: val_loss did not improve
Epoch 12/1000
 - 84s - loss: 0.4445 - val_loss: 0.3834

Epoch 00010: val_loss improved from 1.93524 to 1.92624, saving model to modelWeights/824_sigmoid.h5
Epoch 11/1000
 - 95s - loss: 0.4014 - val_loss: 1.9820

Epoch 00016: val_loss did not improve
Epoch 17/1000
 - 64s - loss: 0.3957 - val_loss: 0.2900

Epoch 00016: val_loss did not improve
Epoch 17/1000
 - 63s - loss: 0.3990 - val_loss: 1.7902

Epoch 00012: val_loss did not improve
Epoch 13/1000
 - 86s - loss: 0.4439 - val_loss: 0.3581

Epoch 00017: val_loss did not improve
Epoch 18/1000
 - 64s - loss: 0.3954 - val_loss: 0.2894

Epoch 00017: val_loss did not improve
Epoch 18/1000
 - 62s - loss: 0.3987 - val_loss: 2.0160

Epoch 00011: val_loss did not improve
Epoch 12/1000
 - 95s - loss: 0.4008 - val_loss: 1.8557

Epoch 00013: val_loss did not improve
Epoch 14/1000
 - 86s - loss: 0.4434 - val_loss: 0.3252

Epoch 00018: val_loss did not improve
Epoch 19/1000
 - 64s - loss: 0.3951 - val_loss: 0.2869

Epoch 00018: val_loss did not improve
Epoch 19/1000
 - 62s - loss: 0.3984 - val_loss: 1.9895

Epoch 00012: val_loss improved from 1.92624 to 1.85567, saving model to modelWeights/824_sigmoid.h5
Epoch 13/1000
 - 94s - loss: 0.4003 - val_loss: 2.0687

Epoch 00019: val_loss did not improve
Epoch 20/1000
 - 62s - loss: 0.3981 - val_loss: 1.9333

Epoch 00019: val_loss improved from 0.28688 to 0.28686, saving model to modelWeights/812_sigmoid.h5
Epoch 20/1000
 - 64s - loss: 0.3949 - val_loss: 0.2867

Epoch 00014: val_loss did not improve
Epoch 15/1000
 - 84s - loss: 0.4429 - val_loss: 0.3795

Epoch 00020: val_loss did not improve
Epoch 21/1000
 - 62s - loss: 0.3979 - val_loss: 1.8379

Epoch 00020: val_loss improved from 0.28686 to 0.28670, saving model to modelWeights/812_sigmoid.h5
Epoch 21/1000
 - 64s - loss: 0.3946 - val_loss: 0.2864

Epoch 00013: val_loss did not improve
Epoch 14/1000
 - 95s - loss: 0.3999 - val_loss: 1.9169

Epoch 00015: val_loss did not improve
Epoch 16/1000
 - 86s - loss: 0.4424 - val_loss: 0.3324

Epoch 00021: val_loss improved from 0.28670 to 0.28644, saving model to modelWeights/812_sigmoid.h5
Epoch 22/1000
 - 61s - loss: 0.3944 - val_loss: 0.2874

Epoch 00021: val_loss did not improve
Epoch 22/1000
 - 64s - loss: 0.3977 - val_loss: 1.9772

Epoch 00014: val_loss did not improve
Epoch 15/1000
 - 95s - loss: 0.3996 - val_loss: 1.9575

Epoch 00016: val_loss did not improve
Epoch 17/1000
 - 83s - loss: 0.4420 - val_loss: 0.3522

Epoch 00022: val_loss did not improve
Epoch 23/1000
 - 63s - loss: 0.3942 - val_loss: 0.2878

Epoch 00022: val_loss did not improve
Epoch 23/1000
 - 64s - loss: 0.3974 - val_loss: 1.9157

Epoch 00023: val_loss did not improve
Epoch 24/1000
 - 62s - loss: 0.3940 - val_loss: 0.2867

Epoch 00023: val_loss did not improve
Epoch 24/1000
 - 63s - loss: 0.3973 - val_loss: 1.7859

Epoch 00017: val_loss did not improve
Epoch 18/1000
 - 85s - loss: 0.4417 - val_loss: 0.3647

Epoch 00015: val_loss did not improve
Epoch 16/1000
 - 94s - loss: 0.3993 - val_loss: 1.8660

Epoch 00024: val_loss did not improve
Epoch 25/1000
 - 63s - loss: 0.3938 - val_loss: 0.2885

Epoch 00024: val_loss did not improve
Epoch 25/1000
 - 63s - loss: 0.3971 - val_loss: 1.9827

Epoch 00018: val_loss did not improve
Epoch 19/1000
 - 85s - loss: 0.4414 - val_loss: 0.3256

Epoch 00016: val_loss did not improve
Epoch 17/1000
 - 94s - loss: 0.3990 - val_loss: 2.0847

Epoch 00025: val_loss did not improve
Epoch 26/1000
 - 63s - loss: 0.3936 - val_loss: 0.2865

Epoch 00025: val_loss did not improve
Epoch 26/1000
 - 62s - loss: 0.3969 - val_loss: 1.9979

Epoch 00026: val_loss did not improve
Epoch 27/1000
 - 62s - loss: 0.3967 - val_loss: 1.7657

Epoch 00019: val_loss did not improve
Epoch 20/1000
 - 85s - loss: 0.4411 - val_loss: 0.3016

Epoch 00026: val_loss did not improve
Epoch 27/1000
 - 63s - loss: 0.3935 - val_loss: 0.2867

Epoch 00017: val_loss did not improve
Epoch 18/1000
 - 94s - loss: 0.3988 - val_loss: 1.8968

Epoch 00027: val_loss improved from 1.78061 to 1.76574, saving model to modelWeights/814_sigmoid.h5
Epoch 28/1000
 - 62s - loss: 0.3966 - val_loss: 2.1193

Epoch 00027: val_loss did not improve
Epoch 28/1000
 - 64s - loss: 0.3933 - val_loss: 0.2887

Epoch 00020: val_loss did not improve
Epoch 21/1000
 - 88s - loss: 0.4409 - val_loss: 0.3413

Epoch 00018: val_loss did not improve
Epoch 19/1000
 - 94s - loss: 0.3985 - val_loss: 1.8513

Epoch 00028: val_loss did not improve
Epoch 29/1000
 - 63s - loss: 0.3965 - val_loss: 2.0763

Epoch 00028: val_loss did not improve
Epoch 29/1000
 - 63s - loss: 0.3932 - val_loss: 0.2871

Epoch 00021: val_loss did not improve
Epoch 22/1000
 - 86s - loss: 0.4407 - val_loss: 0.3381

Epoch 00029: val_loss did not improve
Epoch 30/1000
 - 63s - loss: 0.3963 - val_loss: 1.7666

Epoch 00029: val_loss did not improve
Epoch 30/1000
 - 64s - loss: 0.3931 - val_loss: 0.2858

Epoch 00019: val_loss improved from 1.85567 to 1.85127, saving model to modelWeights/824_sigmoid.h5
Epoch 20/1000
 - 94s - loss: 0.3983 - val_loss: 2.0023

Epoch 00030: val_loss did not improve
Epoch 31/1000
 - 62s - loss: 0.3962 - val_loss: 2.0874

Epoch 00030: val_loss improved from 0.28644 to 0.28585, saving model to modelWeights/812_sigmoid.h5
Epoch 31/1000
 - 64s - loss: 0.3930 - val_loss: 0.2881

Epoch 00022: val_loss did not improve
Epoch 23/1000
 - 83s - loss: 0.4404 - val_loss: 0.3538

Epoch 00020: val_loss did not improve
Epoch 21/1000
 - 96s - loss: 0.3981 - val_loss: 1.8284

Epoch 00031: val_loss did not improve
Epoch 32/1000
 - 62s - loss: 0.3961 - val_loss: 1.9261

Epoch 00031: val_loss did not improve
Epoch 32/1000
 - 61s - loss: 0.3929 - val_loss: 0.2871

Epoch 00023: val_loss did not improve
Epoch 24/1000
 - 85s - loss: 0.4402 - val_loss: 0.3385

Epoch 00032: val_loss did not improve
Epoch 33/1000
 - 62s - loss: 0.3960 - val_loss: 1.8136

Epoch 00032: val_loss did not improve
Epoch 33/1000
 - 63s - loss: 0.3927 - val_loss: 0.2858

Epoch 00021: val_loss improved from 1.85127 to 1.82841, saving model to modelWeights/824_sigmoid.h5
Epoch 22/1000
 - 96s - loss: 0.3979 - val_loss: 1.7350

Epoch 00024: val_loss did not improve
Epoch 25/1000
 - 85s - loss: 0.4400 - val_loss: 0.3199

Epoch 00033: val_loss did not improve
Epoch 34/1000
 - 62s - loss: 0.3959 - val_loss: 1.9025

Epoch 00033: val_loss improved from 0.28585 to 0.28578, saving model to modelWeights/812_sigmoid.h5
Epoch 34/1000
 - 63s - loss: 0.3927 - val_loss: 0.2861

Epoch 00022: val_loss improved from 1.82841 to 1.73501, saving model to modelWeights/824_sigmoid.h5
Epoch 23/1000
 - 94s - loss: 0.3977 - val_loss: 1.9463

Epoch 00034: val_loss did not improve
Epoch 35/1000
 - 63s - loss: 0.3958 - val_loss: 1.9019

Epoch 00034: val_loss did not improve
Epoch 35/1000
 - 63s - loss: 0.3926 - val_loss: 0.2890

Epoch 00025: val_loss did not improve
Epoch 26/1000
 - 83s - loss: 0.4398 - val_loss: 0.3283

Epoch 00035: val_loss did not improve
Epoch 36/1000
 - 63s - loss: 0.3957 - val_loss: 1.8080

Epoch 00035: val_loss did not improve
Epoch 36/1000
 - 64s - loss: 0.3925 - val_loss: 0.2871

Epoch 00026: val_loss did not improve
Epoch 27/1000
 - 86s - loss: 0.4396 - val_loss: 0.3221

Epoch 00023: val_loss did not improve
Epoch 24/1000
 - 98s - loss: 0.3976 - val_loss: 1.9765

Epoch 00036: val_loss did not improve
Epoch 37/1000
 - 63s - loss: 0.3957 - val_loss: 1.6632

Epoch 00036: val_loss did not improve
Epoch 37/1000
 - 63s - loss: 0.3924 - val_loss: 0.2865

Epoch 00027: val_loss did not improve
Epoch 28/1000
 - 86s - loss: 0.4395 - val_loss: 0.3359

Epoch 00037: val_loss improved from 1.76574 to 1.66318, saving model to modelWeights/814_sigmoid.h5
Epoch 38/1000
 - 63s - loss: 0.3956 - val_loss: 1.9981

Epoch 00024: val_loss did not improve
Epoch 25/1000
 - 97s - loss: 0.3974 - val_loss: 2.0955

Epoch 00037: val_loss did not improve
Epoch 38/1000
 - 63s - loss: 0.3923 - val_loss: 0.2861

Epoch 00038: val_loss did not improve
Epoch 39/1000
 - 63s - loss: 0.3955 - val_loss: 1.9609

Epoch 00038: val_loss did not improve
Epoch 39/1000
 - 63s - loss: 0.3923 - val_loss: 0.2867

Epoch 00028: val_loss did not improve
Epoch 29/1000
 - 83s - loss: 0.4393 - val_loss: 0.3463

Epoch 00025: val_loss did not improve
Epoch 26/1000
 - 95s - loss: 0.3973 - val_loss: 1.8992

Epoch 00039: val_loss did not improve
Epoch 40/1000
 - 63s - loss: 0.3954 - val_loss: 1.9067

Epoch 00039: val_loss did not improve
Epoch 40/1000
 - 63s - loss: 0.3922 - val_loss: 0.2898

Epoch 00029: val_loss did not improve
Epoch 30/1000
 - 86s - loss: 0.4392 - val_loss: 0.3766

Epoch 00040: val_loss did not improve
Epoch 41/1000
 - 63s - loss: 0.3954 - val_loss: 1.8168

Epoch 00040: val_loss did not improve
Epoch 41/1000
 - 63s - loss: 0.3921 - val_loss: 0.2857

Epoch 00026: val_loss did not improve
Epoch 27/1000
 - 109s - loss: 0.3971 - val_loss: 1.7763

Epoch 00030: val_loss did not improve
Epoch 31/1000
 - 85s - loss: 0.4391 - val_loss: 0.3496

Epoch 00041: val_loss did not improve
Epoch 42/1000
 - 63s - loss: 0.3953 - val_loss: 2.0045

Epoch 00041: val_loss improved from 0.28578 to 0.28571, saving model to modelWeights/812_sigmoid.h5
Epoch 42/1000
 - 62s - loss: 0.3920 - val_loss: 0.2872

Epoch 00027: val_loss did not improve
Epoch 28/1000
 - 96s - loss: 0.3969 - val_loss: 2.0266

Epoch 00042: val_loss did not improve
Epoch 43/1000
 - 64s - loss: 0.3953 - val_loss: 1.8820

Epoch 00042: val_loss did not improve
Epoch 43/1000
 - 61s - loss: 0.3920 - val_loss: 0.2854

Epoch 00031: val_loss did not improve
Epoch 32/1000
 - 83s - loss: 0.4390 - val_loss: 0.3424

Epoch 00043: val_loss did not improve
Epoch 44/1000
 - 63s - loss: 0.3952 - val_loss: 1.9320

Epoch 00043: val_loss improved from 0.28571 to 0.28537, saving model to modelWeights/812_sigmoid.h5
Epoch 44/1000
 - 63s - loss: 0.3919 - val_loss: 0.2879

Epoch 00028: val_loss did not improve
Epoch 29/1000
 - 96s - loss: 0.3968 - val_loss: 1.7985

Epoch 00032: val_loss did not improve
Epoch 33/1000
 - 86s - loss: 0.4389 - val_loss: 0.3269

Epoch 00044: val_loss did not improve
Epoch 45/1000
 - 62s - loss: 0.3951 - val_loss: 1.6264

Epoch 00044: val_loss did not improve
Epoch 45/1000
 - 63s - loss: 0.3919 - val_loss: 0.2865

Epoch 00029: val_loss did not improve
Epoch 30/1000
 - 96s - loss: 0.3967 - val_loss: 1.9194

Epoch 00033: val_loss did not improve
Epoch 34/1000
 - 86s - loss: 0.4388 - val_loss: 0.3629

Epoch 00045: val_loss improved from 1.66318 to 1.62636, saving model to modelWeights/814_sigmoid.h5
Epoch 46/1000
 - 62s - loss: 0.3951 - val_loss: 1.8626

Epoch 00045: val_loss did not improve
Epoch 46/1000
 - 63s - loss: 0.3919 - val_loss: 0.2854

Epoch 00046: val_loss did not improve
Epoch 47/1000
 - 62s - loss: 0.3951 - val_loss: 1.9978

Epoch 00046: val_loss did not improve
Epoch 47/1000
 - 63s - loss: 0.3918 - val_loss: 0.2862

Epoch 00034: val_loss did not improve
Epoch 35/1000
 - 83s - loss: 0.4387 - val_loss: 0.3603

Epoch 00030: val_loss did not improve
Epoch 31/1000
 - 96s - loss: 0.3966 - val_loss: 1.8958

Epoch 00047: val_loss did not improve
Epoch 48/1000
 - 62s - loss: 0.3950 - val_loss: 2.0173

Epoch 00047: val_loss did not improve
Epoch 48/1000
 - 63s - loss: 0.3918 - val_loss: 0.2879

Epoch 00035: val_loss did not improve
Epoch 36/1000
 - 86s - loss: 0.4386 - val_loss: 0.3009

Epoch 00031: val_loss did not improve
Epoch 32/1000
 - 96s - loss: 0.3965 - val_loss: 1.9258

Epoch 00048: val_loss did not improve
Epoch 49/1000
 - 63s - loss: 0.3950 - val_loss: 1.8105

Epoch 00048: val_loss did not improve
Epoch 49/1000
 - 64s - loss: 0.3917 - val_loss: 0.2853

Epoch 00049: val_loss did not improve
Epoch 50/1000
 - 63s - loss: 0.3949 - val_loss: 2.1348

Epoch 00036: val_loss did not improve
Epoch 37/1000
 - 86s - loss: 0.4385 - val_loss: 0.3327

Epoch 00049: val_loss improved from 0.28537 to 0.28532, saving model to modelWeights/812_sigmoid.h5
Epoch 50/1000
 - 64s - loss: 0.3917 - val_loss: 0.2859

Epoch 00032: val_loss did not improve
Epoch 33/1000
 - 96s - loss: 0.3964 - val_loss: 1.7162

Epoch 00050: val_loss did not improve
Epoch 51/1000
 - 62s - loss: 0.3949 - val_loss: 1.9847

Epoch 00050: val_loss did not improve
Epoch 51/1000
 - 65s - loss: 0.3917 - val_loss: 0.2857
[2020-08-28 16:03:32,614 INFO] Writing fit history to modelWeights/812_sigmoid.history.h5
Epoch 00050: early stopping

Epoch 00051: val_loss did not improve

Epoch 00037: val_loss did not improve
Epoch 38/1000
 - 84s - loss: 0.4384 - val_loss: 0.3413

Epoch 00051: val_loss did not improve
Epoch 52/1000
 - 62s - loss: 0.3949 - val_loss: 2.1639

Epoch 00033: val_loss improved from 1.73501 to 1.71624, saving model to modelWeights/824_sigmoid.h5
Epoch 34/1000
 - 96s - loss: 0.3963 - val_loss: 1.8643

Epoch 00038: val_loss did not improve
Epoch 39/1000
 - 85s - loss: 0.4383 - val_loss: 0.3246

Epoch 00052: val_loss did not improve
Epoch 53/1000
 - 62s - loss: 0.3948 - val_loss: 2.0535

Epoch 00034: val_loss did not improve
Epoch 35/1000
 - 96s - loss: 0.3962 - val_loss: 1.9668

Epoch 00053: val_loss did not improve
Epoch 54/1000
 - 62s - loss: 0.3947 - val_loss: 1.9487

Epoch 00039: val_loss did not improve
Epoch 40/1000
 - 84s - loss: 0.4382 - val_loss: 0.3277

Epoch 00054: val_loss did not improve
Epoch 55/1000
 - 62s - loss: 0.3947 - val_loss: 1.9392

Epoch 00035: val_loss did not improve
Epoch 36/1000
 - 96s - loss: 0.3962 - val_loss: 1.9350

Epoch 00040: val_loss did not improve
Epoch 41/1000
 - 85s - loss: 0.4382 - val_loss: 0.3167

Epoch 00055: val_loss did not improve
Epoch 56/1000
 - 63s - loss: 0.3947 - val_loss: 1.8942

Epoch 00036: val_loss did not improve
Epoch 37/1000
 - 96s - loss: 0.3961 - val_loss: 1.8118

Epoch 00041: val_loss did not improve
Epoch 42/1000
 - 86s - loss: 0.4381 - val_loss: 0.3452

Epoch 00056: val_loss did not improve
Epoch 57/1000
 - 64s - loss: 0.3947 - val_loss: 1.9141

Epoch 00057: val_loss did not improve
Epoch 58/1000
 - 61s - loss: 0.3947 - val_loss: 1.9724

Epoch 00037: val_loss did not improve
Epoch 38/1000
 - 96s - loss: 0.3960 - val_loss: 1.8470

Epoch 00042: val_loss did not improve
Epoch 43/1000
 - 84s - loss: 0.4380 - val_loss: 0.3838

Epoch 00058: val_loss did not improve
Epoch 59/1000
 - 62s - loss: 0.3947 - val_loss: 1.9148

Epoch 00043: val_loss did not improve
Epoch 44/1000
 - 86s - loss: 0.4380 - val_loss: 0.3364

Epoch 00038: val_loss did not improve
Epoch 39/1000
 - 96s - loss: 0.3959 - val_loss: 1.8771

Epoch 00059: val_loss did not improve
Epoch 60/1000
 - 61s - loss: 0.3946 - val_loss: 1.7669

Epoch 00060: val_loss did not improve
Epoch 61/1000
 - 61s - loss: 0.3946 - val_loss: 1.9045

Epoch 00044: val_loss did not improve
Epoch 45/1000
 - 86s - loss: 0.4379 - val_loss: 0.3039

Epoch 00039: val_loss did not improve
Epoch 40/1000
 - 95s - loss: 0.3959 - val_loss: 1.8456

Epoch 00061: val_loss did not improve
Epoch 62/1000
 - 62s - loss: 0.3946 - val_loss: 2.0551

Epoch 00045: val_loss did not improve
Epoch 46/1000
 - 84s - loss: 0.4378 - val_loss: 0.3494

Epoch 00040: val_loss did not improve
Epoch 41/1000
 - 96s - loss: 0.3958 - val_loss: 1.8276

Epoch 00062: val_loss did not improve
Epoch 63/1000
 - 63s - loss: 0.3945 - val_loss: 1.7100

Epoch 00046: val_loss did not improve
Epoch 47/1000
 - 88s - loss: 0.4378 - val_loss: 0.3602

Epoch 00063: val_loss did not improve
Epoch 64/1000
 - 63s - loss: 0.3945 - val_loss: 1.8266

Epoch 00041: val_loss did not improve
Epoch 42/1000
 - 96s - loss: 0.3958 - val_loss: 1.8053

Epoch 00064: val_loss did not improve
Epoch 65/1000
 - 61s - loss: 0.3945 - val_loss: 2.0347

Epoch 00047: val_loss did not improve
Epoch 48/1000
 - 87s - loss: 0.4377 - val_loss: 0.3452

Epoch 00042: val_loss did not improve
Epoch 43/1000
 - 96s - loss: 0.3957 - val_loss: 1.8783

Epoch 00065: val_loss did not improve
Epoch 66/1000
 - 61s - loss: 0.3945 - val_loss: 1.9180

Epoch 00048: val_loss did not improve
Epoch 49/1000
 - 84s - loss: 0.4376 - val_loss: 0.3554

Epoch 00066: val_loss did not improve
Epoch 67/1000
 - 61s - loss: 0.3945 - val_loss: 1.7814

Epoch 00043: val_loss did not improve
Epoch 44/1000
 - 96s - loss: 0.3956 - val_loss: 1.8479

Epoch 00049: val_loss did not improve
Epoch 50/1000
 - 86s - loss: 0.4375 - val_loss: 0.3347

Epoch 00067: val_loss did not improve
Epoch 68/1000
 - 61s - loss: 0.3945 - val_loss: 2.0029

Epoch 00068: val_loss did not improve
Epoch 69/1000
 - 62s - loss: 0.3944 - val_loss: 1.8105

Epoch 00044: val_loss did not improve
Epoch 45/1000
 - 96s - loss: 0.3956 - val_loss: 1.8192

Epoch 00050: val_loss did not improve
Epoch 51/1000
 - 86s - loss: 0.4375 - val_loss: 0.3877
[2020-08-28 16:22:16,119 INFO] Writing fit history to modelWeights/naturalsplit_sigmoid.history.h5
Epoch 00050: early stopping

Epoch 00051: val_loss did not improve

Epoch 00069: val_loss did not improve
Epoch 70/1000
 - 64s - loss: 0.3944 - val_loss: 1.8896

Epoch 00045: val_loss did not improve
Epoch 46/1000
 - 96s - loss: 0.3956 - val_loss: 1.9072

Epoch 00070: val_loss did not improve
Epoch 71/1000
 - 62s - loss: 0.3944 - val_loss: 2.3165

Epoch 00071: val_loss did not improve
Epoch 72/1000
 - 62s - loss: 0.3944 - val_loss: 1.9618

Epoch 00046: val_loss did not improve
Epoch 47/1000
 - 96s - loss: 0.3955 - val_loss: 1.8960

Epoch 00072: val_loss did not improve
Epoch 73/1000
 - 62s - loss: 0.3943 - val_loss: 2.0335

Epoch 00047: val_loss did not improve
Epoch 48/1000
 - 95s - loss: 0.3955 - val_loss: 1.8412

Epoch 00073: val_loss did not improve
Epoch 74/1000
 - 62s - loss: 0.3943 - val_loss: 1.9243

Epoch 00074: val_loss did not improve
Epoch 75/1000
 - 63s - loss: 0.3943 - val_loss: 1.9246

Epoch 00048: val_loss did not improve
Epoch 49/1000
 - 96s - loss: 0.3954 - val_loss: 1.8309

Epoch 00075: val_loss did not improve
Epoch 76/1000
 - 63s - loss: 0.3943 - val_loss: 1.7347

Epoch 00049: val_loss did not improve
Epoch 50/1000
 - 96s - loss: 0.3954 - val_loss: 1.8407

Epoch 00076: val_loss did not improve
Epoch 77/1000
 - 65s - loss: 0.3943 - val_loss: 1.7338

Epoch 00077: val_loss did not improve
Epoch 78/1000
 - 62s - loss: 0.3943 - val_loss: 1.8921
[2020-08-28 16:31:21,649 INFO] Writing fit history to modelWeights/814_sigmoid.history.h5
Epoch 00077: early stopping

Epoch 00078: val_loss did not improve

Epoch 00050: val_loss did not improve
Epoch 51/1000
 - 96s - loss: 0.3953 - val_loss: 1.9287

Epoch 00051: val_loss did not improve
Epoch 52/1000
 - 96s - loss: 0.3953 - val_loss: 1.6664

Epoch 00052: val_loss improved from 1.71624 to 1.66641, saving model to modelWeights/824_sigmoid.h5
Epoch 53/1000
 - 96s - loss: 0.3952 - val_loss: 1.7848

Epoch 00053: val_loss did not improve
Epoch 54/1000
 - 96s - loss: 0.3952 - val_loss: 1.9563

Epoch 00054: val_loss did not improve
Epoch 55/1000
 - 96s - loss: 0.3951 - val_loss: 1.8669

Epoch 00055: val_loss did not improve
Epoch 56/1000
 - 96s - loss: 0.3951 - val_loss: 1.8126

Epoch 00056: val_loss did not improve
Epoch 57/1000
 - 97s - loss: 0.3951 - val_loss: 1.8568

Epoch 00057: val_loss did not improve
Epoch 58/1000
 - 96s - loss: 0.3950 - val_loss: 1.8944

Epoch 00058: val_loss did not improve
Epoch 59/1000
 - 96s - loss: 0.3950 - val_loss: 1.7753

Epoch 00059: val_loss did not improve
Epoch 60/1000
 - 95s - loss: 0.3949 - val_loss: 1.8396

Epoch 00060: val_loss did not improve
Epoch 61/1000
 - 95s - loss: 0.3949 - val_loss: 1.8940

Epoch 00061: val_loss did not improve
Epoch 62/1000
 - 95s - loss: 0.3948 - val_loss: 1.8308

Epoch 00062: val_loss did not improve
Epoch 63/1000
 - 97s - loss: 0.3948 - val_loss: 1.7567

Epoch 00063: val_loss did not improve
Epoch 64/1000
 - 100s - loss: 0.3947 - val_loss: 1.6935

Epoch 00064: val_loss did not improve
Epoch 65/1000
 - 100s - loss: 0.3947 - val_loss: 1.8647

Epoch 00065: val_loss did not improve
Epoch 66/1000
 - 97s - loss: 0.3947 - val_loss: 1.8154

Epoch 00066: val_loss did not improve
Epoch 67/1000
 - 95s - loss: 0.3946 - val_loss: 1.9175

Epoch 00067: val_loss did not improve
Epoch 68/1000
 - 95s - loss: 0.3946 - val_loss: 1.7505

Epoch 00068: val_loss did not improve
Epoch 69/1000
 - 95s - loss: 0.3946 - val_loss: 1.8151

Epoch 00069: val_loss did not improve
Epoch 70/1000
 - 95s - loss: 0.3946 - val_loss: 1.7518

Epoch 00070: val_loss did not improve
Epoch 71/1000
 - 95s - loss: 0.3945 - val_loss: 1.8984

Epoch 00071: val_loss did not improve
Epoch 72/1000
 - 93s - loss: 0.3945 - val_loss: 1.9087

Epoch 00072: val_loss did not improve
Epoch 73/1000
 - 93s - loss: 0.3945 - val_loss: 1.8051

Epoch 00073: val_loss did not improve
Epoch 74/1000
 - 93s - loss: 0.3945 - val_loss: 1.7711

Epoch 00074: val_loss did not improve
Epoch 75/1000
 - 93s - loss: 0.3944 - val_loss: 2.0547

Epoch 00075: val_loss did not improve
Epoch 76/1000
 - 93s - loss: 0.3944 - val_loss: 1.8432

Epoch 00076: val_loss did not improve
Epoch 77/1000
 - 93s - loss: 0.3944 - val_loss: 1.7621

Epoch 00077: val_loss did not improve
Epoch 78/1000
 - 94s - loss: 0.3944 - val_loss: 1.8782

Epoch 00078: val_loss did not improve
Epoch 79/1000
 - 93s - loss: 0.3944 - val_loss: 2.0157

Epoch 00079: val_loss did not improve
Epoch 80/1000
 - 94s - loss: 0.3943 - val_loss: 1.7881

Epoch 00080: val_loss did not improve
Epoch 81/1000
 - 94s - loss: 0.3943 - val_loss: 1.9642

Epoch 00081: val_loss did not improve
Epoch 82/1000
 - 93s - loss: 0.3943 - val_loss: 1.8163

Epoch 00082: val_loss did not improve
Epoch 83/1000
 - 94s - loss: 0.3943 - val_loss: 1.8910

Epoch 00083: val_loss did not improve
Epoch 84/1000
 - 94s - loss: 0.3943 - val_loss: 1.8951

Epoch 00084: val_loss did not improve
Epoch 85/1000
 - 94s - loss: 0.3943 - val_loss: 1.8532

Epoch 00085: val_loss did not improve
Epoch 86/1000
 - 94s - loss: 0.3943 - val_loss: 1.7096

Epoch 00086: val_loss did not improve
Epoch 87/1000
 - 94s - loss: 0.3942 - val_loss: 2.0197

Epoch 00087: val_loss did not improve
Epoch 88/1000
 - 94s - loss: 0.3942 - val_loss: 1.9489

Epoch 00088: val_loss did not improve
Epoch 89/1000
 - 94s - loss: 0.3942 - val_loss: 2.0535

Epoch 00089: val_loss did not improve
Epoch 90/1000
 - 94s - loss: 0.3942 - val_loss: 1.8007

Epoch 00090: val_loss did not improve
Epoch 91/1000
 - 94s - loss: 0.3942 - val_loss: 1.7491
[2020-08-28 17:34:48,772 INFO] Writing fit history to modelWeights/824_sigmoid.history.h5
Epoch 00090: early stopping

Epoch 00091: val_loss did not improve
