Using Theano backend.
Using Theano backend.
Using Theano backend.
Using Theano backend.
[2020-08-28 14:33:28,559 INFO] Loading data from data/814_train.h5
[2020-08-28 14:33:28,607 INFO] Loading data from data/824_train.h5
[2020-08-28 14:33:28,618 INFO] Loading data from data/812_train.h5
[2020-08-28 14:33:28,636 INFO] Loading data from data/naturalsplittrainingsample.h5
[2020-08-28 14:33:40,890 INFO] Building model from share/reference_number.py
[2020-08-28 14:33:42,117 INFO] Building model from share/reference_number.py
[2020-08-28 14:33:46,372 INFO] Compiling model
[2020-08-28 14:33:46,381 INFO] Fitting model
WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.
[2020-08-28 14:33:47,224 WARNING] We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.
[2020-08-28 14:33:48,068 INFO] Building model from share/reference_number.py
[2020-08-28 14:33:48,772 INFO] Building model from share/reference_number.py
[2020-08-28 14:33:53,819 INFO] Compiling model
[2020-08-28 14:33:53,827 INFO] Fitting model
WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.
[2020-08-28 14:33:54,622 WARNING] We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.
INFO (theano.gof.compilelock): Waiting for existing lock by process '75188' (I am process '18670')
[2020-08-28 14:33:54,813 INFO] Waiting for existing lock by process '75188' (I am process '18670')
INFO (theano.gof.compilelock): To manually release the lock, delete /global/u2/c/chkoda/.theano/compiledir_Linux-4.12-lp150.12.82-default-x86_64-with-glibc2.2.5-x86_64-2.7.18-64/lock_dir
[2020-08-28 14:33:54,814 INFO] To manually release the lock, delete /global/u2/c/chkoda/.theano/compiledir_Linux-4.12-lp150.12.82-default-x86_64-with-glibc2.2.5-x86_64-2.7.18-64/lock_dir
[2020-08-28 14:34:03,105 INFO] Compiling model
[2020-08-28 14:34:03,114 INFO] Fitting model
WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.
[2020-08-28 14:34:03,900 WARNING] We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.
[2020-08-28 14:34:10,566 INFO] Compiling model
[2020-08-28 14:34:10,638 INFO] Fitting model
WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.
[2020-08-28 14:34:13,559 WARNING] We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.
Train on 11131813 samples, validate on 1236869 samples
Epoch 1/1000
 - 75s - loss: 0.4355 - val_loss: 2.3879
Train on 10800000 samples, validate on 1200000 samples
Epoch 1/1000
 - 70s - loss: 0.4314 - val_loss: 0.3062
Train on 15300000 samples, validate on 1700000 samples
Epoch 1/1000
 - 105s - loss: 0.4825 - val_loss: 0.3118

Epoch 00001: val_loss improved from inf to 2.38792, saving model to modelWeights/814.h5
Epoch 2/1000
 - 75s - loss: 0.4123 - val_loss: 2.0486
Train on 17999998 samples, validate on 2000000 samples
Epoch 1/1000
 - 127s - loss: 0.4296 - val_loss: 1.9651

Epoch 00001: val_loss improved from inf to 0.30624, saving model to modelWeights/812.h5
Epoch 2/1000
 - 70s - loss: 0.4088 - val_loss: 0.2936

Epoch 00001: val_loss improved from inf to 0.31175, saving model to modelWeights/naturalsplit.h5
Epoch 2/1000
 - 109s - loss: 0.4549 - val_loss: 0.3630

Epoch 00002: val_loss improved from 2.38792 to 2.04860, saving model to modelWeights/814.h5
Epoch 3/1000
 - 75s - loss: 0.4079 - val_loss: 1.9115

Epoch 00002: val_loss improved from 0.30624 to 0.29364, saving model to modelWeights/812.h5
Epoch 3/1000
 - 70s - loss: 0.4039 - val_loss: 0.2931

Epoch 00001: val_loss improved from inf to 1.96512, saving model to modelWeights/824.h5
Epoch 2/1000
 - 121s - loss: 0.4103 - val_loss: 1.9927

Epoch 00003: val_loss improved from 0.29364 to 0.29310, saving model to modelWeights/812.h5
Epoch 4/1000
 - 70s - loss: 0.4010 - val_loss: 0.2985

Epoch 00003: val_loss improved from 2.04860 to 1.91154, saving model to modelWeights/814.h5
Epoch 4/1000
 - 75s - loss: 0.4055 - val_loss: 1.7971

Epoch 00002: val_loss did not improve
Epoch 3/1000
 - 107s - loss: 0.4488 - val_loss: 0.3378

Epoch 00004: val_loss did not improve
Epoch 5/1000
 - 71s - loss: 0.3994 - val_loss: 0.2909

Epoch 00004: val_loss improved from 1.91154 to 1.79710, saving model to modelWeights/814.h5
Epoch 5/1000
 - 79s - loss: 0.4041 - val_loss: 1.9236

Epoch 00002: val_loss did not improve
Epoch 3/1000
 - 119s - loss: 0.4065 - val_loss: 1.8840

Epoch 00003: val_loss did not improve
Epoch 4/1000
 - 106s - loss: 0.4454 - val_loss: 0.3681

Epoch 00005: val_loss improved from 0.29310 to 0.29094, saving model to modelWeights/812.h5
Epoch 6/1000
 - 70s - loss: 0.3984 - val_loss: 0.2923

Epoch 00005: val_loss did not improve
Epoch 6/1000
 - 80s - loss: 0.4031 - val_loss: 1.9012

Epoch 00006: val_loss did not improve
Epoch 7/1000
 - 69s - loss: 0.3977 - val_loss: 0.2903

Epoch 00003: val_loss improved from 1.96512 to 1.88401, saving model to modelWeights/824.h5
Epoch 4/1000
 - 120s - loss: 0.4045 - val_loss: 2.0504

Epoch 00004: val_loss did not improve
Epoch 5/1000
 - 105s - loss: 0.4432 - val_loss: 0.3583

Epoch 00006: val_loss did not improve
Epoch 7/1000
 - 80s - loss: 0.4024 - val_loss: 1.9363

Epoch 00007: val_loss improved from 0.29094 to 0.29031, saving model to modelWeights/812.h5
Epoch 8/1000
 - 70s - loss: 0.3971 - val_loss: 0.2894

Epoch 00007: val_loss did not improve
Epoch 8/1000
 - 80s - loss: 0.4018 - val_loss: 1.9544

Epoch 00004: val_loss did not improve
Epoch 5/1000
 - 120s - loss: 0.4034 - val_loss: 1.9971

Epoch 00008: val_loss improved from 0.29031 to 0.28937, saving model to modelWeights/812.h5
Epoch 9/1000
 - 70s - loss: 0.3966 - val_loss: 0.2995

Epoch 00005: val_loss did not improve
Epoch 6/1000
 - 108s - loss: 0.4419 - val_loss: 0.3775

Epoch 00008: val_loss did not improve
Epoch 9/1000
 - 81s - loss: 0.4013 - val_loss: 1.8436

Epoch 00009: val_loss did not improve
Epoch 10/1000
 - 70s - loss: 0.3962 - val_loss: 0.2915

Epoch 00006: val_loss did not improve
Epoch 7/1000
 - 105s - loss: 0.4410 - val_loss: 0.3352

Epoch 00005: val_loss did not improve
Epoch 6/1000
 - 119s - loss: 0.4027 - val_loss: 1.9272

Epoch 00009: val_loss did not improve
Epoch 10/1000
 - 81s - loss: 0.4009 - val_loss: 2.0288

Epoch 00010: val_loss did not improve
Epoch 11/1000
 - 70s - loss: 0.3958 - val_loss: 0.2893

Epoch 00011: val_loss improved from 0.28937 to 0.28927, saving model to modelWeights/812.h5
Epoch 12/1000
 - 70s - loss: 0.3955 - val_loss: 0.2881

Epoch 00007: val_loss did not improve
Epoch 8/1000
 - 104s - loss: 0.4403 - val_loss: 0.3298

Epoch 00010: val_loss did not improve
Epoch 11/1000
 - 80s - loss: 0.4007 - val_loss: 1.8660

Epoch 00006: val_loss did not improve
Epoch 7/1000
 - 120s - loss: 0.4021 - val_loss: 2.0072

Epoch 00012: val_loss improved from 0.28927 to 0.28815, saving model to modelWeights/812.h5
Epoch 13/1000
 - 70s - loss: 0.3953 - val_loss: 0.2921

Epoch 00011: val_loss did not improve
Epoch 12/1000
 - 81s - loss: 0.4004 - val_loss: 1.9112

Epoch 00008: val_loss did not improve
Epoch 9/1000
 - 104s - loss: 0.4399 - val_loss: 0.3047

Epoch 00007: val_loss did not improve
Epoch 8/1000
 - 119s - loss: 0.4017 - val_loss: 1.9869

Epoch 00013: val_loss did not improve
Epoch 14/1000
 - 70s - loss: 0.3952 - val_loss: 0.2898

Epoch 00012: val_loss did not improve
Epoch 13/1000
 - 81s - loss: 0.4001 - val_loss: 2.0392

Epoch 00014: val_loss did not improve
Epoch 15/1000
 - 70s - loss: 0.3950 - val_loss: 0.2880

Epoch 00009: val_loss improved from 0.31175 to 0.30474, saving model to modelWeights/naturalsplit.h5
Epoch 10/1000
 - 109s - loss: 0.4395 - val_loss: 0.3348

Epoch 00013: val_loss did not improve
Epoch 14/1000
 - 80s - loss: 0.3999 - val_loss: 2.0008

Epoch 00008: val_loss did not improve
Epoch 9/1000
 - 121s - loss: 0.4014 - val_loss: 1.9594

Epoch 00015: val_loss improved from 0.28815 to 0.28798, saving model to modelWeights/812.h5
Epoch 16/1000
 - 71s - loss: 0.3949 - val_loss: 0.2889

Epoch 00010: val_loss did not improve
Epoch 11/1000
 - 106s - loss: 0.4392 - val_loss: 0.3400

Epoch 00014: val_loss did not improve
Epoch 15/1000
 - 81s - loss: 0.3997 - val_loss: 1.9647

Epoch 00016: val_loss did not improve
Epoch 17/1000
 - 70s - loss: 0.3947 - val_loss: 0.2894

Epoch 00009: val_loss did not improve
Epoch 10/1000
 - 119s - loss: 0.4012 - val_loss: 2.0066

Epoch 00015: val_loss did not improve
Epoch 16/1000
 - 80s - loss: 0.3995 - val_loss: 2.0124

Epoch 00017: val_loss did not improve
Epoch 18/1000
 - 72s - loss: 0.3946 - val_loss: 0.2939

Epoch 00011: val_loss did not improve
Epoch 12/1000
 - 105s - loss: 0.4389 - val_loss: 0.3669

Epoch 00016: val_loss did not improve
Epoch 17/1000
 - 81s - loss: 0.3993 - val_loss: 1.8927

Epoch 00010: val_loss did not improve
Epoch 11/1000
 - 119s - loss: 0.4010 - val_loss: 1.9400

Epoch 00018: val_loss did not improve
Epoch 19/1000
 - 71s - loss: 0.3945 - val_loss: 0.2872

Epoch 00012: val_loss did not improve
Epoch 13/1000
 - 106s - loss: 0.4387 - val_loss: 0.3452

Epoch 00019: val_loss improved from 0.28798 to 0.28725, saving model to modelWeights/812.h5
Epoch 20/1000
 - 70s - loss: 0.3945 - val_loss: 0.2887

Epoch 00017: val_loss did not improve
Epoch 18/1000
 - 80s - loss: 0.3991 - val_loss: 2.0759

Epoch 00011: val_loss did not improve
Epoch 12/1000
 - 118s - loss: 0.4009 - val_loss: 1.8746

Epoch 00020: val_loss did not improve
Epoch 21/1000
 - 71s - loss: 0.3943 - val_loss: 0.2879

Epoch 00013: val_loss did not improve
Epoch 14/1000
 - 109s - loss: 0.4385 - val_loss: 0.3275

Epoch 00018: val_loss did not improve
Epoch 19/1000
 - 80s - loss: 0.3989 - val_loss: 2.0367

Epoch 00021: val_loss did not improve
Epoch 22/1000
 - 71s - loss: 0.3942 - val_loss: 0.2888

Epoch 00019: val_loss did not improve
Epoch 20/1000
 - 80s - loss: 0.3986 - val_loss: 1.9734

Epoch 00012: val_loss improved from 1.88401 to 1.87455, saving model to modelWeights/824.h5
Epoch 13/1000
 - 118s - loss: 0.4008 - val_loss: 2.0630

Epoch 00014: val_loss did not improve
Epoch 15/1000
 - 106s - loss: 0.4383 - val_loss: 0.3755

Epoch 00022: val_loss did not improve
Epoch 23/1000
 - 71s - loss: 0.3941 - val_loss: 0.2892

Epoch 00020: val_loss did not improve
Epoch 21/1000
 - 80s - loss: 0.3984 - val_loss: 1.9212

Epoch 00023: val_loss did not improve
Epoch 24/1000
 - 71s - loss: 0.3941 - val_loss: 0.2882

Epoch 00013: val_loss did not improve
Epoch 14/1000
 - 120s - loss: 0.4007 - val_loss: 1.9399

Epoch 00015: val_loss did not improve
Epoch 16/1000
 - 104s - loss: 0.4381 - val_loss: 0.3242

Epoch 00021: val_loss did not improve
Epoch 22/1000
 - 78s - loss: 0.3982 - val_loss: 1.9237

Epoch 00024: val_loss did not improve
Epoch 25/1000
 - 71s - loss: 0.3940 - val_loss: 0.2894

Epoch 00016: val_loss did not improve
Epoch 17/1000
 - 104s - loss: 0.4380 - val_loss: 0.3474

Epoch 00022: val_loss did not improve
Epoch 23/1000
 - 80s - loss: 0.3980 - val_loss: 1.8911

Epoch 00014: val_loss did not improve
Epoch 15/1000
 - 118s - loss: 0.4006 - val_loss: 1.9881

Epoch 00025: val_loss did not improve
Epoch 26/1000
 - 70s - loss: 0.3939 - val_loss: 0.2881

Epoch 00023: val_loss did not improve
Epoch 24/1000
 - 80s - loss: 0.3979 - val_loss: 1.8715

Epoch 00026: val_loss did not improve
Epoch 27/1000
 - 71s - loss: 0.3938 - val_loss: 0.2883

Epoch 00017: val_loss did not improve
Epoch 18/1000
 - 108s - loss: 0.4378 - val_loss: 0.3560

Epoch 00015: val_loss did not improve
Epoch 16/1000
 - 118s - loss: 0.4005 - val_loss: 1.9700

Epoch 00024: val_loss did not improve
Epoch 25/1000
 - 79s - loss: 0.3977 - val_loss: 2.0245

Epoch 00027: val_loss did not improve
Epoch 28/1000
 - 72s - loss: 0.3938 - val_loss: 0.2919

Epoch 00018: val_loss did not improve
Epoch 19/1000
 - 106s - loss: 0.4377 - val_loss: 0.3256

Epoch 00016: val_loss did not improve
Epoch 17/1000
 - 118s - loss: 0.4005 - val_loss: 1.9967

Epoch 00028: val_loss did not improve
Epoch 29/1000
 - 72s - loss: 0.3938 - val_loss: 0.2884

Epoch 00025: val_loss did not improve
Epoch 26/1000
 - 80s - loss: 0.3976 - val_loss: 1.9463

Epoch 00019: val_loss did not improve
Epoch 20/1000
 - 106s - loss: 0.4376 - val_loss: 0.3011

Epoch 00029: val_loss did not improve
Epoch 30/1000
 - 72s - loss: 0.3937 - val_loss: 0.2877

Epoch 00026: val_loss did not improve
Epoch 27/1000
 - 80s - loss: 0.3975 - val_loss: 1.7992

Epoch 00017: val_loss did not improve
Epoch 18/1000
 - 120s - loss: 0.4004 - val_loss: 1.9234

Epoch 00030: val_loss did not improve
Epoch 31/1000
 - 71s - loss: 0.3936 - val_loss: 0.2916

Epoch 00027: val_loss did not improve
Epoch 28/1000
 - 81s - loss: 0.3973 - val_loss: 1.9987

Epoch 00020: val_loss improved from 0.30474 to 0.30106, saving model to modelWeights/naturalsplit.h5
Epoch 21/1000
 - 109s - loss: 0.4375 - val_loss: 0.3319

Epoch 00031: val_loss did not improve
Epoch 32/1000
 - 71s - loss: 0.3937 - val_loss: 0.2884

Epoch 00018: val_loss did not improve
Epoch 19/1000
 - 121s - loss: 0.4003 - val_loss: 1.8811

Epoch 00028: val_loss did not improve
Epoch 29/1000
 - 80s - loss: 0.3972 - val_loss: 1.9970

Epoch 00032: val_loss did not improve
Epoch 33/1000
 - 70s - loss: 0.3936 - val_loss: 0.2875

Epoch 00021: val_loss did not improve
Epoch 22/1000
 - 111s - loss: 0.4374 - val_loss: 0.3274

Epoch 00029: val_loss did not improve
Epoch 30/1000
 - 81s - loss: 0.3971 - val_loss: 1.8191

Epoch 00033: val_loss did not improve
Epoch 34/1000
 - 71s - loss: 0.3936 - val_loss: 0.2887

Epoch 00019: val_loss did not improve
Epoch 20/1000
 - 121s - loss: 0.4003 - val_loss: 1.9961

Epoch 00022: val_loss did not improve
Epoch 23/1000
 - 110s - loss: 0.4374 - val_loss: 0.3381

Epoch 00030: val_loss did not improve
Epoch 31/1000
 - 80s - loss: 0.3970 - val_loss: 2.0250

Epoch 00034: val_loss did not improve
Epoch 35/1000
 - 71s - loss: 0.3935 - val_loss: 0.2916

Epoch 00020: val_loss did not improve
Epoch 21/1000
 - 121s - loss: 0.4001 - val_loss: 1.9131

Epoch 00031: val_loss did not improve
Epoch 32/1000
 - 80s - loss: 0.3969 - val_loss: 1.9013

Epoch 00035: val_loss did not improve
Epoch 36/1000
 - 71s - loss: 0.3935 - val_loss: 0.2895

Epoch 00023: val_loss did not improve
Epoch 24/1000
 - 109s - loss: 0.4373 - val_loss: 0.3351

Epoch 00032: val_loss did not improve
Epoch 33/1000
 - 81s - loss: 0.3969 - val_loss: 1.8553

Epoch 00036: val_loss did not improve
Epoch 37/1000
 - 71s - loss: 0.3934 - val_loss: 0.2880

Epoch 00021: val_loss did not improve
Epoch 22/1000
 - 121s - loss: 0.4001 - val_loss: 1.8302

Epoch 00024: val_loss did not improve
Epoch 25/1000
 - 109s - loss: 0.4372 - val_loss: 0.3177

Epoch 00037: val_loss did not improve
Epoch 38/1000
 - 71s - loss: 0.3934 - val_loss: 0.2878

Epoch 00033: val_loss did not improve
Epoch 34/1000
 - 80s - loss: 0.3968 - val_loss: 2.0023

Epoch 00038: val_loss did not improve
Epoch 39/1000
 - 71s - loss: 0.3934 - val_loss: 0.2885

Epoch 00022: val_loss improved from 1.87455 to 1.83024, saving model to modelWeights/824.h5
Epoch 23/1000
 - 121s - loss: 0.4000 - val_loss: 1.9360

Epoch 00034: val_loss did not improve
Epoch 35/1000
 - 80s - loss: 0.3967 - val_loss: 1.8777

Epoch 00025: val_loss did not improve
Epoch 26/1000
 - 111s - loss: 0.4372 - val_loss: 0.3322

Epoch 00039: val_loss did not improve
Epoch 40/1000
 - 71s - loss: 0.3933 - val_loss: 0.2910

Epoch 00035: val_loss did not improve
Epoch 36/1000
 - 80s - loss: 0.3966 - val_loss: 1.8904

Epoch 00026: val_loss did not improve
Epoch 27/1000
 - 109s - loss: 0.4371 - val_loss: 0.3289

Epoch 00023: val_loss did not improve
Epoch 24/1000
 - 122s - loss: 0.3999 - val_loss: 2.0601

Epoch 00040: val_loss did not improve
Epoch 41/1000
 - 71s - loss: 0.3933 - val_loss: 0.2881

Epoch 00036: val_loss did not improve
Epoch 37/1000
 - 80s - loss: 0.3966 - val_loss: 1.8070

Epoch 00041: val_loss did not improve
Epoch 42/1000
 - 71s - loss: 0.3932 - val_loss: 0.2884

Epoch 00027: val_loss did not improve
Epoch 28/1000
 - 108s - loss: 0.4370 - val_loss: 0.3349

Epoch 00024: val_loss did not improve
Epoch 25/1000
 - 121s - loss: 0.3999 - val_loss: 2.0604

Epoch 00037: val_loss did not improve
Epoch 38/1000
 - 81s - loss: 0.3964 - val_loss: 1.9994

Epoch 00042: val_loss did not improve
Epoch 43/1000
 - 71s - loss: 0.3932 - val_loss: 0.2865

Epoch 00038: val_loss did not improve
Epoch 39/1000
 - 80s - loss: 0.3964 - val_loss: 2.0189

Epoch 00028: val_loss did not improve
Epoch 29/1000
 - 110s - loss: 0.4370 - val_loss: 0.3586

Epoch 00043: val_loss improved from 0.28725 to 0.28651, saving model to modelWeights/812.h5
Epoch 44/1000
 - 71s - loss: 0.3932 - val_loss: 0.2889

Epoch 00025: val_loss did not improve
Epoch 26/1000
 - 121s - loss: 0.3998 - val_loss: 1.8667

Epoch 00039: val_loss did not improve
Epoch 40/1000
 - 80s - loss: 0.3962 - val_loss: 1.8969

Epoch 00044: val_loss did not improve
Epoch 45/1000
 - 71s - loss: 0.3932 - val_loss: 0.2873

Epoch 00029: val_loss did not improve
Epoch 30/1000
 - 110s - loss: 0.4369 - val_loss: 0.3753

Epoch 00040: val_loss did not improve
Epoch 41/1000
 - 81s - loss: 0.3962 - val_loss: 1.7984

Epoch 00026: val_loss did not improve
Epoch 27/1000
 - 122s - loss: 0.3998 - val_loss: 1.8373

Epoch 00045: val_loss did not improve
Epoch 46/1000
 - 71s - loss: 0.3931 - val_loss: 0.2869

Epoch 00030: val_loss did not improve
Epoch 31/1000
 - 109s - loss: 0.4368 - val_loss: 0.3497

Epoch 00046: val_loss did not improve
Epoch 47/1000
 - 71s - loss: 0.3931 - val_loss: 0.2876

Epoch 00041: val_loss did not improve
Epoch 42/1000
 - 81s - loss: 0.3961 - val_loss: 2.1735

Epoch 00027: val_loss did not improve
Epoch 28/1000
 - 121s - loss: 0.3997 - val_loss: 1.9180

Epoch 00047: val_loss did not improve
Epoch 48/1000
 - 71s - loss: 0.3932 - val_loss: 0.2910

Epoch 00042: val_loss did not improve
Epoch 43/1000
 - 81s - loss: 0.3960 - val_loss: 1.9326

Epoch 00031: val_loss did not improve
Epoch 32/1000
 - 109s - loss: 0.4368 - val_loss: 0.3424

Epoch 00048: val_loss did not improve
Epoch 49/1000
 - 71s - loss: 0.3931 - val_loss: 0.2866

Epoch 00028: val_loss did not improve
Epoch 29/1000
 - 121s - loss: 0.3997 - val_loss: 1.8635

Epoch 00043: val_loss did not improve
Epoch 44/1000
 - 82s - loss: 0.3959 - val_loss: 1.9215

Epoch 00032: val_loss did not improve
Epoch 33/1000
 - 110s - loss: 0.4368 - val_loss: 0.3338

Epoch 00049: val_loss did not improve
Epoch 50/1000
 - 71s - loss: 0.3930 - val_loss: 0.2879

Epoch 00044: val_loss did not improve
Epoch 45/1000
 - 83s - loss: 0.3958 - val_loss: 1.6815

Epoch 00050: val_loss did not improve
Epoch 51/1000
 - 71s - loss: 0.3929 - val_loss: 0.2876
[2020-08-28 15:34:15,150 INFO] Writing fit history to modelWeights/812.history.h5
Epoch 00050: early stopping

Epoch 00051: val_loss did not improve

Epoch 00029: val_loss did not improve
Epoch 30/1000
 - 121s - loss: 0.3996 - val_loss: 1.9506

Epoch 00033: val_loss did not improve
Epoch 34/1000
 - 111s - loss: 0.4367 - val_loss: 0.3508

Epoch 00045: val_loss improved from 1.79710 to 1.68153, saving model to modelWeights/814.h5
Epoch 46/1000
 - 84s - loss: 0.3957 - val_loss: 1.8686

Epoch 00030: val_loss did not improve
Epoch 31/1000
 - 122s - loss: 0.3995 - val_loss: 1.9510

Epoch 00046: val_loss did not improve
Epoch 47/1000
 - 84s - loss: 0.3956 - val_loss: 2.1768

Epoch 00034: val_loss did not improve
Epoch 35/1000
 - 109s - loss: 0.4367 - val_loss: 0.3529

Epoch 00047: val_loss did not improve
Epoch 48/1000
 - 84s - loss: 0.3955 - val_loss: 2.0026

Epoch 00031: val_loss did not improve
Epoch 32/1000
 - 121s - loss: 0.3994 - val_loss: 1.9135

Epoch 00035: val_loss did not improve
Epoch 36/1000
 - 108s - loss: 0.4366 - val_loss: 0.3289

Epoch 00048: val_loss did not improve
Epoch 49/1000
 - 85s - loss: 0.3954 - val_loss: 1.7705

Epoch 00036: val_loss did not improve
Epoch 37/1000
 - 109s - loss: 0.4366 - val_loss: 0.3247

Epoch 00032: val_loss did not improve
Epoch 33/1000
 - 121s - loss: 0.3993 - val_loss: 1.8274

Epoch 00049: val_loss did not improve
Epoch 50/1000
 - 86s - loss: 0.3953 - val_loss: 2.1093

Epoch 00037: val_loss did not improve
Epoch 38/1000
 - 109s - loss: 0.4366 - val_loss: 0.3303

Epoch 00050: val_loss did not improve
Epoch 51/1000
 - 85s - loss: 0.3953 - val_loss: 1.8972

Epoch 00033: val_loss improved from 1.83024 to 1.82741, saving model to modelWeights/824.h5
Epoch 34/1000
 - 122s - loss: 0.3992 - val_loss: 1.8735

Epoch 00051: val_loss did not improve
Epoch 52/1000
 - 85s - loss: 0.3952 - val_loss: 2.0801

Epoch 00038: val_loss did not improve
Epoch 39/1000
 - 108s - loss: 0.4365 - val_loss: 0.3179

Epoch 00034: val_loss did not improve
Epoch 35/1000
 - 124s - loss: 0.3991 - val_loss: 1.9546

Epoch 00052: val_loss did not improve
Epoch 53/1000
 - 87s - loss: 0.3951 - val_loss: 2.1025

Epoch 00039: val_loss did not improve
Epoch 40/1000
 - 108s - loss: 0.4365 - val_loss: 0.3102

Epoch 00053: val_loss did not improve
Epoch 54/1000
 - 86s - loss: 0.3950 - val_loss: 2.0396

Epoch 00035: val_loss did not improve
Epoch 36/1000
 - 122s - loss: 0.3990 - val_loss: 1.9538

Epoch 00040: val_loss did not improve
Epoch 41/1000
 - 110s - loss: 0.4365 - val_loss: 0.3324

Epoch 00054: val_loss did not improve
Epoch 55/1000
 - 86s - loss: 0.3949 - val_loss: 1.9174

Epoch 00036: val_loss did not improve
Epoch 37/1000
 - 126s - loss: 0.3989 - val_loss: 1.9155

Epoch 00055: val_loss did not improve
Epoch 56/1000
 - 87s - loss: 0.3948 - val_loss: 1.8649

Epoch 00041: val_loss did not improve
Epoch 42/1000
 - 110s - loss: 0.4364 - val_loss: 0.3306

Epoch 00037: val_loss did not improve
Epoch 38/1000
 - 123s - loss: 0.3989 - val_loss: 1.8116

Epoch 00056: val_loss did not improve
Epoch 57/1000
 - 88s - loss: 0.3948 - val_loss: 1.9286

Epoch 00042: val_loss did not improve
Epoch 43/1000
 - 109s - loss: 0.4364 - val_loss: 0.3654

Epoch 00057: val_loss did not improve
Epoch 58/1000
 - 87s - loss: 0.3948 - val_loss: 1.9874

Epoch 00038: val_loss improved from 1.82741 to 1.81162, saving model to modelWeights/824.h5
Epoch 39/1000
 - 136s - loss: 0.3988 - val_loss: 1.9519

Epoch 00043: val_loss did not improve
Epoch 44/1000
 - 110s - loss: 0.4364 - val_loss: 0.3396

Epoch 00058: val_loss did not improve
Epoch 59/1000
 - 87s - loss: 0.3947 - val_loss: 1.9673

Epoch 00044: val_loss did not improve
Epoch 45/1000
 - 111s - loss: 0.4364 - val_loss: 0.3032

Epoch 00039: val_loss did not improve
Epoch 40/1000
 - 123s - loss: 0.3988 - val_loss: 1.8819

Epoch 00059: val_loss did not improve
Epoch 60/1000
 - 87s - loss: 0.3946 - val_loss: 1.8033

Epoch 00060: val_loss did not improve
Epoch 61/1000
 - 87s - loss: 0.3946 - val_loss: 2.0080

Epoch 00045: val_loss did not improve
Epoch 46/1000
 - 109s - loss: 0.4363 - val_loss: 0.3412

Epoch 00040: val_loss did not improve
Epoch 41/1000
 - 122s - loss: 0.3988 - val_loss: 1.9819

Epoch 00061: val_loss did not improve
Epoch 62/1000
 - 87s - loss: 0.3946 - val_loss: 2.0152

Epoch 00046: val_loss did not improve
Epoch 47/1000
 - 108s - loss: 0.4363 - val_loss: 0.3483

Epoch 00041: val_loss did not improve
Epoch 42/1000
 - 122s - loss: 0.3987 - val_loss: 1.8575

Epoch 00062: val_loss did not improve
Epoch 63/1000
 - 87s - loss: 0.3945 - val_loss: 1.7156

Epoch 00047: val_loss did not improve
Epoch 48/1000
 - 108s - loss: 0.4363 - val_loss: 0.3396

Epoch 00063: val_loss did not improve
Epoch 64/1000
 - 87s - loss: 0.3945 - val_loss: 1.8864

Epoch 00042: val_loss did not improve
Epoch 43/1000
 - 122s - loss: 0.3987 - val_loss: 1.9461

Epoch 00048: val_loss did not improve
Epoch 49/1000
 - 111s - loss: 0.4363 - val_loss: 0.3420

Epoch 00064: val_loss did not improve
Epoch 65/1000
 - 87s - loss: 0.3944 - val_loss: 2.0086

Epoch 00043: val_loss did not improve
Epoch 44/1000
 - 122s - loss: 0.3986 - val_loss: 1.9197

Epoch 00065: val_loss did not improve
Epoch 66/1000
 - 88s - loss: 0.3944 - val_loss: 1.9210

Epoch 00049: val_loss did not improve
Epoch 50/1000
 - 108s - loss: 0.4362 - val_loss: 0.3276

Epoch 00044: val_loss did not improve
Epoch 45/1000
 - 122s - loss: 0.3986 - val_loss: 1.9465

Epoch 00066: val_loss did not improve
Epoch 67/1000
 - 88s - loss: 0.3944 - val_loss: 1.9301

Epoch 00050: val_loss did not improve
Epoch 51/1000
 - 109s - loss: 0.4362 - val_loss: 0.3716
[2020-08-28 16:05:48,905 INFO] Writing fit history to modelWeights/naturalsplit.history.h5
Epoch 00050: early stopping

Epoch 00051: val_loss did not improve

Epoch 00067: val_loss did not improve
Epoch 68/1000
 - 88s - loss: 0.3944 - val_loss: 1.9848

Epoch 00045: val_loss did not improve
Epoch 46/1000
 - 122s - loss: 0.3986 - val_loss: 1.9843

Epoch 00068: val_loss did not improve
Epoch 69/1000
 - 88s - loss: 0.3943 - val_loss: 1.8386

Epoch 00046: val_loss did not improve
Epoch 47/1000
 - 122s - loss: 0.3986 - val_loss: 1.9354

Epoch 00069: val_loss did not improve
Epoch 70/1000
 - 88s - loss: 0.3943 - val_loss: 1.9021

Epoch 00070: val_loss did not improve
Epoch 71/1000
 - 87s - loss: 0.3943 - val_loss: 2.2529

Epoch 00047: val_loss did not improve
Epoch 48/1000
 - 122s - loss: 0.3986 - val_loss: 1.8548

Epoch 00071: val_loss did not improve
Epoch 72/1000
 - 88s - loss: 0.3943 - val_loss: 1.9757

Epoch 00048: val_loss did not improve
Epoch 49/1000
 - 122s - loss: 0.3985 - val_loss: 1.9161

Epoch 00072: val_loss did not improve
Epoch 73/1000
 - 88s - loss: 0.3942 - val_loss: 1.9729

Epoch 00049: val_loss did not improve
Epoch 50/1000
 - 122s - loss: 0.3984 - val_loss: 1.8995

Epoch 00073: val_loss did not improve
Epoch 74/1000
 - 88s - loss: 0.3942 - val_loss: 1.9079

Epoch 00074: val_loss did not improve
Epoch 75/1000
 - 88s - loss: 0.3942 - val_loss: 1.9781

Epoch 00050: val_loss did not improve
Epoch 51/1000
 - 122s - loss: 0.3984 - val_loss: 1.9672

Epoch 00075: val_loss did not improve
Epoch 76/1000
 - 86s - loss: 0.3942 - val_loss: 1.7683

Epoch 00051: val_loss did not improve
Epoch 52/1000
 - 122s - loss: 0.3983 - val_loss: 1.7139

Epoch 00076: val_loss did not improve
Epoch 77/1000
 - 84s - loss: 0.3942 - val_loss: 1.8034

Epoch 00077: val_loss did not improve
Epoch 78/1000
 - 83s - loss: 0.3942 - val_loss: 1.9189
[2020-08-28 16:21:21,337 INFO] Writing fit history to modelWeights/814.history.h5
Epoch 00077: early stopping

Epoch 00078: val_loss did not improve

Epoch 00052: val_loss improved from 1.81162 to 1.71387, saving model to modelWeights/824.h5
Epoch 53/1000
 - 123s - loss: 0.3982 - val_loss: 1.7777

Epoch 00053: val_loss did not improve
Epoch 54/1000
 - 122s - loss: 0.3982 - val_loss: 2.0021

Epoch 00054: val_loss did not improve
Epoch 55/1000
 - 122s - loss: 0.3981 - val_loss: 1.7750

Epoch 00055: val_loss did not improve
Epoch 56/1000
 - 122s - loss: 0.3981 - val_loss: 1.8821

Epoch 00056: val_loss did not improve
Epoch 57/1000
 - 122s - loss: 0.3980 - val_loss: 1.9426

Epoch 00057: val_loss did not improve
Epoch 58/1000
 - 122s - loss: 0.3980 - val_loss: 1.9326

Epoch 00058: val_loss did not improve
Epoch 59/1000
 - 122s - loss: 0.3979 - val_loss: 1.9358

Epoch 00059: val_loss did not improve
Epoch 60/1000
 - 122s - loss: 0.3979 - val_loss: 1.8510

Epoch 00060: val_loss did not improve
Epoch 61/1000
 - 122s - loss: 0.3978 - val_loss: 1.8172

Epoch 00061: val_loss did not improve
Epoch 62/1000
 - 123s - loss: 0.3978 - val_loss: 1.8612

Epoch 00062: val_loss did not improve
Epoch 63/1000
 - 123s - loss: 0.3978 - val_loss: 1.8391

Epoch 00063: val_loss did not improve
Epoch 64/1000
 - 123s - loss: 0.3978 - val_loss: 1.7237

Epoch 00064: val_loss did not improve
Epoch 65/1000
 - 122s - loss: 0.3977 - val_loss: 1.8188

Epoch 00065: val_loss did not improve
Epoch 66/1000
 - 122s - loss: 0.3977 - val_loss: 1.8506

Epoch 00066: val_loss did not improve
Epoch 67/1000
 - 123s - loss: 0.3977 - val_loss: 1.9890

Epoch 00067: val_loss did not improve
Epoch 68/1000
 - 127s - loss: 0.3977 - val_loss: 1.7701

Epoch 00068: val_loss did not improve
Epoch 69/1000
 - 128s - loss: 0.3976 - val_loss: 1.8203

Epoch 00069: val_loss did not improve
Epoch 70/1000
 - 123s - loss: 0.3976 - val_loss: 1.7482

Epoch 00070: val_loss did not improve
Epoch 71/1000
 - 122s - loss: 0.3976 - val_loss: 1.9864

Epoch 00071: val_loss did not improve
Epoch 72/1000
 - 122s - loss: 0.3976 - val_loss: 1.9757

Epoch 00072: val_loss did not improve
Epoch 73/1000
 - 121s - loss: 0.3975 - val_loss: 1.9462
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** JOB 977560 ON cgpu01 CANCELLED AT 2020-08-28T17:03:31 DUE TO TIME LIMIT ***
slurmstepd: error: *** STEP 977560.3 ON cgpu18 CANCELLED AT 2020-08-28T17:03:31 DUE TO TIME LIMIT ***
