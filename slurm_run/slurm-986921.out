Using Theano backend.
[2020-09-01 01:17:35,530 INFO] Loading data from data/824_train.h5
[2020-09-01 01:17:55,742 INFO] Building model from share/reference_number.py
[2020-09-01 01:18:10,490 INFO] Compiling model
[2020-09-01 01:18:10,529 INFO] Fitting model
WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.
[2020-09-01 01:18:12,843 WARNING] We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.
Train on 17999998 samples, validate on 2000000 samples
Epoch 1/1000
 - 122s - loss: 0.4470 - val_loss: 1.9769

Epoch 00001: val_loss improved from inf to 1.97691, saving model to modelWeights/824sigmoid_newstruct.h5
Epoch 2/1000
 - 113s - loss: 0.4127 - val_loss: 1.9053

Epoch 00002: val_loss improved from 1.97691 to 1.90530, saving model to modelWeights/824sigmoid_newstruct.h5
Epoch 3/1000
 - 112s - loss: 0.4066 - val_loss: 1.8368

Epoch 00003: val_loss improved from 1.90530 to 1.83676, saving model to modelWeights/824sigmoid_newstruct.h5
Epoch 4/1000
 - 113s - loss: 0.4034 - val_loss: 2.1131

Epoch 00004: val_loss did not improve
Epoch 5/1000
 - 111s - loss: 0.4011 - val_loss: 1.8721

Epoch 00005: val_loss did not improve
Epoch 6/1000
 - 111s - loss: 0.3994 - val_loss: 1.8278

Epoch 00006: val_loss improved from 1.83676 to 1.82785, saving model to modelWeights/824sigmoid_newstruct.h5
Epoch 7/1000
 - 112s - loss: 0.3981 - val_loss: 1.8679

Epoch 00007: val_loss did not improve
Epoch 8/1000
 - 112s - loss: 0.3970 - val_loss: 1.8178

Epoch 00008: val_loss improved from 1.82785 to 1.81776, saving model to modelWeights/824sigmoid_newstruct.h5
Epoch 9/1000
 - 112s - loss: 0.3963 - val_loss: 1.8971

Epoch 00009: val_loss did not improve
Epoch 10/1000
 - 112s - loss: 0.3957 - val_loss: 1.9515

Epoch 00010: val_loss did not improve
Epoch 11/1000
 - 112s - loss: 0.3951 - val_loss: 1.9010

Epoch 00011: val_loss did not improve
Epoch 12/1000
 - 113s - loss: 0.3946 - val_loss: 1.9122

Epoch 00012: val_loss did not improve
Epoch 13/1000
 - 112s - loss: 0.3942 - val_loss: 1.7776

Epoch 00013: val_loss improved from 1.81776 to 1.77761, saving model to modelWeights/824sigmoid_newstruct.h5
Epoch 14/1000
 - 113s - loss: 0.3938 - val_loss: 1.8597

Epoch 00014: val_loss did not improve
Epoch 15/1000
 - 112s - loss: 0.3934 - val_loss: 1.8361

Epoch 00015: val_loss did not improve
Epoch 16/1000
 - 112s - loss: 0.3931 - val_loss: 1.9432

Epoch 00016: val_loss did not improve
Epoch 17/1000
 - 112s - loss: 0.3927 - val_loss: 1.9223

Epoch 00017: val_loss did not improve
Epoch 18/1000
 - 112s - loss: 0.3924 - val_loss: 1.9370

Epoch 00018: val_loss did not improve
Epoch 19/1000
 - 112s - loss: 0.3921 - val_loss: 1.9144

Epoch 00019: val_loss did not improve
Epoch 20/1000
 - 111s - loss: 0.3918 - val_loss: 1.7000

Epoch 00020: val_loss improved from 1.77761 to 1.70000, saving model to modelWeights/824sigmoid_newstruct.h5
Epoch 21/1000
 - 112s - loss: 0.3914 - val_loss: 1.8479

Epoch 00021: val_loss did not improve
Epoch 22/1000
 - 112s - loss: 0.3912 - val_loss: 1.8174

Epoch 00022: val_loss did not improve
Epoch 23/1000
 - 112s - loss: 0.3909 - val_loss: 1.7742

Epoch 00023: val_loss did not improve
Epoch 24/1000
 - 112s - loss: 0.3907 - val_loss: 1.9108

Epoch 00024: val_loss did not improve
Epoch 25/1000
 - 112s - loss: 0.3906 - val_loss: 1.8860

Epoch 00025: val_loss did not improve
Epoch 26/1000
 - 112s - loss: 0.3903 - val_loss: 1.8878

Epoch 00026: val_loss did not improve
Epoch 27/1000
 - 111s - loss: 0.3902 - val_loss: 1.8589

Epoch 00027: val_loss did not improve
Epoch 28/1000
 - 112s - loss: 0.3900 - val_loss: 1.6883

Epoch 00028: val_loss improved from 1.70000 to 1.68828, saving model to modelWeights/824sigmoid_newstruct.h5
Epoch 29/1000
 - 112s - loss: 0.3899 - val_loss: 1.8331

Epoch 00029: val_loss did not improve
Epoch 30/1000
 - 112s - loss: 0.3898 - val_loss: 1.7324

Epoch 00030: val_loss did not improve
Epoch 31/1000
 - 112s - loss: 0.3896 - val_loss: 1.9875

Epoch 00031: val_loss did not improve
Epoch 32/1000
 - 112s - loss: 0.3895 - val_loss: 1.7941

Epoch 00032: val_loss did not improve
Epoch 33/1000
 - 112s - loss: 0.3894 - val_loss: 1.9142

Epoch 00033: val_loss did not improve
Epoch 34/1000
 - 112s - loss: 0.3893 - val_loss: 1.8514

Epoch 00034: val_loss did not improve
Epoch 35/1000
 - 112s - loss: 0.3892 - val_loss: 1.7941

Epoch 00035: val_loss did not improve
Epoch 36/1000
 - 112s - loss: 0.3891 - val_loss: 1.8050

Epoch 00036: val_loss did not improve
Epoch 37/1000
 - 112s - loss: 0.3891 - val_loss: 1.7690

Epoch 00037: val_loss did not improve
Epoch 38/1000
 - 112s - loss: 0.3889 - val_loss: 1.7808

Epoch 00038: val_loss did not improve
Epoch 39/1000
 - 113s - loss: 0.3889 - val_loss: 1.6996

Epoch 00039: val_loss did not improve
Epoch 40/1000
 - 112s - loss: 0.3888 - val_loss: 1.7691

Epoch 00040: val_loss did not improve
Epoch 41/1000
 - 112s - loss: 0.3887 - val_loss: 1.8141

Epoch 00041: val_loss did not improve
Epoch 42/1000
 - 113s - loss: 0.3886 - val_loss: 1.8284

Epoch 00042: val_loss did not improve
Epoch 43/1000
 - 112s - loss: 0.3886 - val_loss: 1.8796

Epoch 00043: val_loss did not improve
Epoch 44/1000
 - 113s - loss: 0.3885 - val_loss: 1.8770

Epoch 00044: val_loss did not improve
Epoch 45/1000
 - 113s - loss: 0.3884 - val_loss: 1.9355

Epoch 00045: val_loss did not improve
Epoch 46/1000
 - 113s - loss: 0.3884 - val_loss: 1.9451

Epoch 00046: val_loss did not improve
Epoch 47/1000
 - 114s - loss: 0.3883 - val_loss: 1.8261
slurmstepd: error: *** STEP 986921.0 ON cgpu09 CANCELLED AT 2020-09-01T02:47:45 DUE TO TIME LIMIT ***
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** JOB 986921 ON cgpu09 CANCELLED AT 2020-09-01T02:47:45 DUE TO TIME LIMIT ***
