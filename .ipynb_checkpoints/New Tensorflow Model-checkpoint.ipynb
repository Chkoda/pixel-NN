{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py as h5\n",
    "import logging\n",
    "from collections import namedtuple\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Option = namedtuple(\"MyStruct\", \"data_input model_output structure learning_rate regularizer batch_size epochs \\\n",
    "                    momentum patience\")\n",
    "                    # folds batch_size epochs\")\n",
    "                    #structure learning_rate regularizer epochs\")\n",
    "args = Option(\n",
    "    data_input='data/training.h5',\n",
    "    model_output='output/tf_model',\n",
    "    structure=[25, 20],\n",
    "    learning_rate=0.008,\n",
    "    regularizer=1e-7,\n",
    "    batch_size=60,\n",
    "    epochs=20,\n",
    "    #folds=10,\n",
    "    momentum=0.4,\n",
    "    patience=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000001, 60)\n"
     ]
    }
   ],
   "source": [
    "logging.info(f'Loading data from {args.data_input}')\n",
    "\n",
    "with h5.File(args.data_input, 'r') as data:\n",
    "    data_x = data['input'][()]\n",
    "    data_y = data['target'][()]\n",
    "    #data_x = data['input'][:5000]\n",
    "    #data_y = data['target'][:5000]\n",
    "\n",
    "    \n",
    "labels = ['1particle', '2particle', '3particle']\n",
    "print(data_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.initializers import GlorotNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OffsetAndScale(keras.layers.Layer):\n",
    "    \"\"\" (x + offset) * scale \"\"\"\n",
    "\n",
    "    def __init__(self, offset, scale, **kwargs):\n",
    "        self.offset = offset\n",
    "        self.scale = scale\n",
    "\n",
    "        if isinstance(self.scale, dict) and self.scale['type'] == 'ndarray':\n",
    "            self.scale = np.array(self.scale['value']).astype('float32')\n",
    "\n",
    "        if isinstance(self.offset, dict) and self.offset['type'] == 'ndarray':\n",
    "            self.offset = np.array(self.offset['value']).astype('float32')\n",
    "\n",
    "        super(OffsetAndScale, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, x):\n",
    "        return (x + self.offset) * self.scale\n",
    "\n",
    "    def get_config(self):\n",
    "        return _config(self, {\n",
    "            'offset': self.offset,\n",
    "            'scale': self.scale\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = GlorotNormal(seed=42)\n",
    "inputs = Input((data_x.shape[1],))\n",
    "std = np.std(data_x, axis=0, ddof=1)\n",
    "std[np.where(std == 0)] = 1\n",
    "model = OffsetAndScale(\n",
    "    offset=-np.mean(data_x, axis=0),\n",
    "    scale=1.0/std\n",
    ")(inputs)\n",
    "h = Dense(args.structure[0], activation='sigmoid', kernel_regularizer=l2(args.regularizer), kernel_initializer=init)(inputs)\n",
    "for l in range(1, len(args.structure)):\n",
    "    h = Dense(args.structure[l], activation='sigmoid', kernel_regularizer=l2(args.regularizer), kernel_initializer=init)(h)\n",
    "output_layer = Dense(3, activation='softmax')(h)\n",
    "model = tf.keras.models.Model(inputs=inputs, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 60)]              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 25)                1525      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 20)                520       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 63        \n",
      "=================================================================\n",
      "Total params: 2,108\n",
      "Trainable params: 2,108\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_args = {\n",
    "    'optimizer': Adam(learning_rate=args.learning_rate),\n",
    "    'loss': 'categorical_crossentropy'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(**compile_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_args = {\n",
    "    'batch_size': args.batch_size,\n",
    "    'epochs': args.epochs,\n",
    "    'callbacks': [\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=args.patience, verbose=1, mode='auto'),\n",
    "        tf.keras.callbacks.ModelCheckpoint(args.model_output+'.h5', save_best_only=True, verbose=2)\n",
    "    ],\n",
    "    'verbose': 1,\n",
    "    'validation_split': 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "179988/180000 [============================>.] - ETA: 0s - loss: 0.8025\n",
      "Epoch 00001: val_loss improved from inf to 0.79257, saving model to output/tf_model.h5\n",
      "180000/180000 [==============================] - 129s 719us/step - loss: 0.8025 - val_loss: 0.7926\n",
      "Epoch 2/20\n",
      "179979/180000 [============================>.] - ETA: 0s - loss: 0.7976\n",
      "Epoch 00002: val_loss did not improve from 0.79257\n",
      "180000/180000 [==============================] - 129s 717us/step - loss: 0.7976 - val_loss: 0.8147\n",
      "Epoch 3/20\n",
      "179978/180000 [============================>.] - ETA: 0s - loss: 0.7952\n",
      "Epoch 00003: val_loss improved from 0.79257 to 0.79153, saving model to output/tf_model.h5\n",
      "180000/180000 [==============================] - 129s 718us/step - loss: 0.7952 - val_loss: 0.7915\n",
      "Epoch 4/20\n",
      "179936/180000 [============================>.] - ETA: 0s - loss: 0.7951\n",
      "Epoch 00004: val_loss improved from 0.79153 to 0.77515, saving model to output/tf_model.h5\n",
      "180000/180000 [==============================] - 132s 736us/step - loss: 0.7950 - val_loss: 0.7752\n",
      "Epoch 5/20\n",
      "179962/180000 [============================>.] - ETA: 0s - loss: 0.7945\n",
      "Epoch 00005: val_loss did not improve from 0.77515\n",
      "180000/180000 [==============================] - 129s 717us/step - loss: 0.7945 - val_loss: 0.8322\n",
      "Epoch 6/20\n",
      "179929/180000 [============================>.] - ETA: 0s - loss: 0.8045\n",
      "Epoch 00006: val_loss did not improve from 0.77515\n",
      "180000/180000 [==============================] - 129s 716us/step - loss: 0.8045 - val_loss: 0.8029\n",
      "Epoch 7/20\n",
      "179941/180000 [============================>.] - ETA: 0s - loss: 0.8027\n",
      "Epoch 00007: val_loss did not improve from 0.77515\n",
      "180000/180000 [==============================] - 128s 712us/step - loss: 0.8027 - val_loss: 0.8008\n",
      "Epoch 8/20\n",
      "179982/180000 [============================>.] - ETA: 0s - loss: 0.7914\n",
      "Epoch 00008: val_loss did not improve from 0.77515\n",
      "180000/180000 [==============================] - 128s 710us/step - loss: 0.7914 - val_loss: 0.7881\n",
      "Epoch 9/20\n",
      "179997/180000 [============================>.] - ETA: 0s - loss: 0.8032\n",
      "Epoch 00009: val_loss did not improve from 0.77515\n",
      "180000/180000 [==============================] - 128s 713us/step - loss: 0.8032 - val_loss: 0.8073\n",
      "Epoch 00009: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(data_x, data_y, **fit_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(f'Loading data from data/test.h5')\n",
    "\n",
    "with h5.File('data/test.h5', 'r') as data:\n",
    "    data_x = data['input'][()]\n",
    "    data_y = data['target'][()]\n",
    "    #data_x = data['input'][:5000]\n",
    "    #data_y = data['target'][:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3494872 , 0.3409898 , 0.30952302], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _do_number(data_x, data_y, pred, thrs):\n",
    "\n",
    "    outdata = np.zeros(\n",
    "        (pred.shape[0],),\n",
    "        dtype=[\n",
    "            ('Output_number', np.dtype(('f4', 3))),\n",
    "            ('Output_number_true', 'i4'),\n",
    "            ('Output_number_estimated', 'i4'),\n",
    "            ('NN_layer', 'i4'),\n",
    "            ('NN_barrelEC', 'i4'),\n",
    "            ('globalEta', 'f4'),\n",
    "            ('globalPhi', 'f4'),\n",
    "            ('cluster_size', 'i4'),\n",
    "            ('cluster_size_X', 'i4'),\n",
    "            ('cluster_size_Y', 'i4'),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    outdata['Output_number'] = pred # / np.sum(pred, axis=1, keepdims=True)\n",
    "    outdata['Output_number_true'] = 1 * data_y[:,0] + \\\n",
    "                                    2 * data_y[:,1] + \\\n",
    "                                    3 * data_y[:,2]\n",
    "\n",
    "    outdata['Output_number_estimated'][\n",
    "        np.where(np.logical_and(pred[:,1] < thrs[0], pred[:,2] < thrs[1]))\n",
    "    ] = 1\n",
    "    outdata['Output_number_estimated'][\n",
    "        np.where(np.logical_and(pred[:,1] >= thrs[0], pred[:,2] < thrs[1]))\n",
    "    ] = 2\n",
    "    outdata['Output_number_estimated'][\n",
    "        np.where(pred[:,2] >= thrs[1])\n",
    "    ] = 3\n",
    "\n",
    "    auxfields = [\n",
    "        'NN_layer',\n",
    "        'NN_barrelEC',\n",
    "        'globalEta',\n",
    "        'globalPhi',\n",
    "        'cluster_size',\n",
    "        'cluster_size_X',\n",
    "        'cluster_size_Y'\n",
    "    ]\n",
    "\n",
    "    outdata['NN_layer'] = data_x[:, 56]\n",
    "    outdata['NN_barrelEC'] = data_x[:, 57]\n",
    "    #for field in auxfields:\n",
    "    #    outdata[field] = data_x[field]\n",
    "\n",
    "    return outdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdata = _do_number(data_x, data_y, pred, [0.6, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([([0.3494872 , 0.3409898 , 0.30952302], 2, 3, 1, 0, 0., 0., 0, 0, 0),\n",
       "       ([0.49721277, 0.31337038, 0.18941684], 3, 1, 1, 0, 0., 0., 0, 0, 0),\n",
       "       ([0.11120865, 0.3469584 , 0.54183286], 2, 3, 0, 0, 0., 0., 0, 0, 0),\n",
       "       ...,\n",
       "       ([0.59994906, 0.27551344, 0.12453755], 2, 1, 1, 2, 0., 0., 0, 0, 0),\n",
       "       ([0.18376118, 0.3736561 , 0.44258276], 3, 3, 3, 0, 0., 0., 0, 0, 0),\n",
       "       ([0.1837612 , 0.37365606, 0.4425828 ], 3, 3, 3, 0, 0., 0., 0, 0, 0)],\n",
       "      dtype=[('Output_number', '<f4', (3,)), ('Output_number_true', '<i4'), ('Output_number_estimated', '<i4'), ('NN_layer', '<i4'), ('NN_barrelEC', '<i4'), ('globalEta', '<f4'), ('globalPhi', '<f4'), ('cluster_size', '<i4'), ('cluster_size_X', '<i4'), ('cluster_size_Y', '<i4')])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5.File('{}/{}.h5'.format('output', 'trained_tf_model_apply'), 'w') as hfile:\n",
    "    for key in outdata.dtype.names:\n",
    "        hfile.create_dataset(\n",
    "            key,\n",
    "            data=outdata[key],\n",
    "            compression='gzip'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doNumber(data_EC, data_Layer, data_number, data_true):\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    outdata = np.zeros(\n",
    "        (data_number.shape[0],),\n",
    "        dtype=[\n",
    "            ('Output_number', np.dtype(('f4', 3))),\n",
    "            ('Output_number_true', 'i4')\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    IBL = np.logical_and(data_Layer == 0, data_EC == 0)\n",
    "    Barrel = np.logical_and(data_Layer > 0, data_EC == 0)\n",
    "    Endcap = data_EC != 0\n",
    "\n",
    "    outdata['Output_number'] = data_number\n",
    "    outdata['Output_number_true'] = data_true\n",
    "\n",
    "    data['IBL'] = outdata[IBL]\n",
    "    data['Barrel'] = outdata[Barrel]\n",
    "    data['Endcap'] = outdata[Endcap]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rocGraph(data, classes, name):\n",
    "\n",
    "    fpr = [[0]*(10) for i in range(len(data))]\n",
    "    tpr = [[0]*(10) for i in range(len(data))]\n",
    "    auc1 = [[0]*(10) for i in range(len(data))]\n",
    "\n",
    "    npoints = 200\n",
    "    base_fpr = np.exp(np.linspace(math.log(0.0005), 0., npoints))\n",
    "    colors = [\"r\", \"g\", \"b\"]\n",
    "\n",
    "    pos, neg = classes\n",
    "    linetypes = ['-', '--', ':']\n",
    "\n",
    "    for j, layer in enumerate(data):\n",
    "\n",
    "        for i, data_split in enumerate(data[layer]):\n",
    "            \n",
    "            pos_sel = data_split['Output_number_true'] == pos\n",
    "            neg_sel = data_split['Output_number_true'] == neg\n",
    "\n",
    "            isel = np.where(\n",
    "                np.logical_or(\n",
    "                    pos_sel,\n",
    "                    neg_sel,\n",
    "                )\n",
    "            )[0]\n",
    "\n",
    "            fpr[j][i], tpr[j][i], _ = roc_curve(\n",
    "                data_split['Output_number_true'][isel],\n",
    "                data_split['Output_number'][isel][:, pos - 1],\n",
    "                pos_label=pos\n",
    "            )\n",
    "            auc1[j][i] = auc(fpr[j][i], tpr[j][i])\n",
    "        \n",
    "    for i, layer in enumerate(data):\n",
    "        \n",
    "        tpr_array = np.array([])\n",
    "\n",
    "        for j in range(10):\n",
    "            tpr_interpolated = np.interp(base_fpr, fpr[i][j], tpr[i][j])\n",
    "            tpr_interpolated = tpr_interpolated.reshape((1,npoints))\n",
    "            tpr_array = np.concatenate([tpr_array, tpr_interpolated], axis=0) if tpr_array.size else tpr_interpolated\n",
    "            \n",
    "        mean_tpr = np.mean(tpr_array, axis=0)\n",
    "        rms_tpr = np.std(tpr_array, axis=0)\n",
    "        plus_tpr = np.minimum(mean_tpr+rms_tpr, np.ones(npoints))\n",
    "        minus_tpr = np.maximum(mean_tpr-rms_tpr,np.zeros(npoints))\n",
    "        plt.plot(base_fpr, mean_tpr, linetypes[i], label=f'{layer} (AUC = {np.mean(auc1[i]):.2f} (+- {np.std(auc1[i]):.4f}))')\n",
    "        plt.fill_between(base_fpr, minus_tpr, plus_tpr, alpha=0.3)\n",
    "        \n",
    "        \n",
    "    rand_chance = np.linspace(0, 1, 100)\n",
    "    plt.plot(rand_chance,rand_chance, ':', color='grey', label='Random (AUC = 0.5)')\n",
    "    plt.semilogx()\n",
    "    plt.ylabel(f\"Pr(Estimated: {pos}-particle | True: {pos}-particle)\")\n",
    "    plt.xlabel(f\"Pr(Estimated: {pos}-particle | True: {neg}-particle)\")\n",
    "    plt.xlim([0.001, 1.05])\n",
    "    plt.ylim(0,1.05)\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid(True)\n",
    "    plt.figtext(0.25, 0.90,f'{pos} vs {neg}',fontweight='bold', wrap=True, horizontalalignment='right', fontsize=10)\n",
    "    plt.savefig(f'output/{name}{pos}{neg}_ROC.png')\n",
    "    plt.close()\n",
    "    \n",
    "def doRocs(data, name):\n",
    "    rocGraph(data, (3, 2), name)\n",
    "    rocGraph(data, (3, 1), name)\n",
    "    rocGraph(data, (2, 3), name)\n",
    "    rocGraph(data, (2, 1), name)\n",
    "    rocGraph(data, (1, 2), name)\n",
    "    rocGraph(data, (1, 3), name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5.File(f'output/trained_tf_model_apply.h5', 'r') as data:\n",
    "    data_EC = data['NN_barrelEC'][()]\n",
    "    data_Layer = data['NN_layer'][()]\n",
    "    data_number = data['Output_number'][()]\n",
    "    data_true = data['Output_number_true'][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = doNumber(data_EC, data_Layer, data_number, data_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IBL': array([([0.11120865, 0.3469584 , 0.54183286], 2),\n",
       "        ([0.027356  , 0.24427903, 0.728365  ], 2),\n",
       "        ([0.49721277, 0.31337038, 0.18941684], 1), ...,\n",
       "        ([0.492184  , 0.30863628, 0.19917971], 1),\n",
       "        ([0.59994906, 0.2755134 , 0.12453754], 1),\n",
       "        ([0.17813696, 0.36525327, 0.45660982], 1)],\n",
       "       dtype=[('Output_number', '<f4', (3,)), ('Output_number_true', '<i4')]),\n",
       " 'Barrel': array([([0.3494872 , 0.3409898 , 0.30952302], 2),\n",
       "        ([0.49721277, 0.31337038, 0.18941684], 3),\n",
       "        ([0.00292538, 0.09012875, 0.9069459 ], 3), ...,\n",
       "        ([0.11034908, 0.3376255 , 0.55202544], 1),\n",
       "        ([0.18376118, 0.3736561 , 0.44258276], 3),\n",
       "        ([0.1837612 , 0.37365606, 0.4425828 ], 3)],\n",
       "       dtype=[('Output_number', '<f4', (3,)), ('Output_number_true', '<i4')]),\n",
       " 'Endcap': array([([0.00292538, 0.09012875, 0.9069459 ], 2),\n",
       "        ([0.59994906, 0.2755134 , 0.12453754], 1),\n",
       "        ([0.59994906, 0.2755134 , 0.12453754], 1), ...,\n",
       "        ([0.4129499 , 0.35010922, 0.23694089], 3),\n",
       "        ([0.59994906, 0.2755134 , 0.12453754], 2),\n",
       "        ([0.59994906, 0.27551344, 0.12453755], 2)],\n",
       "       dtype=[('Output_number', '<f4', (3,)), ('Output_number_true', '<i4')])}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(data):\n",
    "    data[layer] = np.array_split(data[layer], 10)\n",
    "doRocs(data, 'trained_tf_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21986   , 0.26010373, 0.5200362 ],\n",
       "       [0.21986   , 0.26010373, 0.5200362 ],\n",
       "       [0.21986   , 0.26010373, 0.5200362 ],\n",
       "       ...,\n",
       "       [0.21986   , 0.26010373, 0.5200362 ],\n",
       "       [0.21986   , 0.26010373, 0.5200362 ],\n",
       "       [0.21986002, 0.26010373, 0.5200362 ]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('EPE_ML_TF2': conda)",
   "language": "python",
   "name": "python361064bitepemltf2conda8b97cfd37faf40f9a7f0d8196617388c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
