{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "sys.path.append('scripts')\n",
    "sys.path.append('share')\n",
    "sys.path.append('python')\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py as h5\n",
    "import matplotlib.pyplot as plt\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "import tensorflow\n",
    "import tensorflow.keras as keras\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from run_training import _build_model, _find_py_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=1, format='[%(asctime)s %(levelname)s] %(message)s')\n",
    "Option = namedtuple(\"MyStruct\", \"input model name folds batch_size epochs\")\n",
    "                    #structure learning_rate regularizer epochs\")\n",
    "args = Option(\n",
    "    input='data/train.h5',\n",
    "    model='share/reference_number.py',\n",
    "    name='NumberNetworkKFOLD',\n",
    "    folds=10,\n",
    "    batch_size=60,\n",
    "    epochs=20,\n",
    "    #learning_rate=0.0001,\n",
    "    #regularizer=0.0001,\n",
    ")\n",
    "\n",
    "path = _find_py_file(args.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold Validation\n",
    "## Load and Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-09 03:16:25,205 INFO] Loading data from data/train.h5\n"
     ]
    }
   ],
   "source": [
    "logging.info(f'Loading data from {args.input}')\n",
    "\n",
    "with h5.File(args.input, 'r') as data:\n",
    "    data_x = data['input'][()]\n",
    "    data_y = data['target'][()]\n",
    "\n",
    "labels = ['1particle', '2particle', '3particle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-09 03:16:34,200 INFO] Building model from share/reference_number.py\n"
     ]
    }
   ],
   "source": [
    "logging.info('Building model from %s', path)\n",
    "model, compile_args, fit_args, params = _build_model(path, data_x, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR ITERATIVE TESTING QUICKER\n",
    "#data_x = data_x[:5000]\n",
    "#data_y = data_y[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "#histories = []\n",
    "#preds = []\n",
    "#reals = []\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "auc1 = {}\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "# DATA COMES PRESHUFFLED NOW\n",
    "\n",
    "#dont forget to shuffle\n",
    "#data = np.concatenate([data_x, data_y], axis=1)\n",
    "#rng = np.random.default_rng(seed=42)\n",
    "#rng.shuffle(data)\n",
    "\n",
    "#data_x = data[:, 0:data_x.shape[1]]\n",
    "#data_y = data[:, data_x.shape[1]:data.shape[1]]\n",
    "\n",
    "#K-Fold Split Indices\n",
    "kfold = KFold(n_splits=args.folds)\n",
    "splits = kfold.split(data_x,data_y)\n",
    "\n",
    "#\n",
    "# To Do: Barrel and Endcap Layer Seperation\n",
    "# Index of data_x in axis=1 corresponds to\n",
    "# IBL: array[56] ==0 && array[57]==0\n",
    "# Barrel: array[56] >0 && array[57]==0\n",
    "# Endcap: array[57]!=0\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-09 03:29:30,549 INFO] output/NumberNetworkKFOLD.h5 created/emptied\n",
      "[2020-07-09 03:29:30,657 INFO] Building model for fold 1 from share/reference_number.py...\n",
      "[2020-07-09 03:29:34,312 INFO] Compiling for fold 1 ...\n",
      "[2020-07-09 03:29:34,325 INFO] Training for fold 1 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "197372/197417 [============================>.] - ETA: 0s - loss: 0.5419 - accuracy: 0.7597\n",
      "Epoch 00001: val_loss improved from inf to 0.55265, saving model to NumberNetworkKFOLD1.h5\n",
      "197417/197417 [==============================] - 153s 777us/step - loss: 0.5418 - accuracy: 0.7597 - val_loss: 0.5527 - val_accuracy: 0.7541\n",
      "Epoch 2/20\n",
      "197390/197417 [============================>.] - ETA: 0s - loss: 0.4938 - accuracy: 0.7866\n",
      "Epoch 00002: val_loss improved from 0.55265 to 0.48407, saving model to NumberNetworkKFOLD1.h5\n",
      "197417/197417 [==============================] - 157s 798us/step - loss: 0.4938 - accuracy: 0.7866 - val_loss: 0.4841 - val_accuracy: 0.7913\n",
      "Epoch 3/20\n",
      "197355/197417 [============================>.] - ETA: 0s - loss: 0.4839 - accuracy: 0.7923\n",
      "Epoch 00003: val_loss improved from 0.48407 to 0.47611, saving model to NumberNetworkKFOLD1.h5\n",
      "197417/197417 [==============================] - 156s 792us/step - loss: 0.4839 - accuracy: 0.7923 - val_loss: 0.4761 - val_accuracy: 0.7976\n",
      "Epoch 4/20\n",
      "197378/197417 [============================>.] - ETA: 0s - loss: 0.4790 - accuracy: 0.7950\n",
      "Epoch 00004: val_loss did not improve from 0.47611\n",
      "197417/197417 [==============================] - 153s 777us/step - loss: 0.4790 - accuracy: 0.7950 - val_loss: 0.4802 - val_accuracy: 0.7937\n",
      "Epoch 5/20\n",
      "197379/197417 [============================>.] - ETA: 0s - loss: 0.4753 - accuracy: 0.7970\n",
      "Epoch 00005: val_loss did not improve from 0.47611\n",
      "197417/197417 [==============================] - 154s 780us/step - loss: 0.4753 - accuracy: 0.7970 - val_loss: 0.4764 - val_accuracy: 0.7951\n",
      "Epoch 6/20\n",
      "197371/197417 [============================>.] - ETA: 0s - loss: 0.4725 - accuracy: 0.7982\n",
      "Epoch 00006: val_loss improved from 0.47611 to 0.47273, saving model to NumberNetworkKFOLD1.h5\n",
      "197417/197417 [==============================] - 156s 789us/step - loss: 0.4725 - accuracy: 0.7982 - val_loss: 0.4727 - val_accuracy: 0.7981\n",
      "Epoch 7/20\n",
      "197358/197417 [============================>.] - ETA: 0s - loss: 0.4701 - accuracy: 0.7993\n",
      "Epoch 00007: val_loss did not improve from 0.47273\n",
      "197417/197417 [==============================] - 155s 785us/step - loss: 0.4701 - accuracy: 0.7993 - val_loss: 0.4758 - val_accuracy: 0.7956\n",
      "Epoch 8/20\n",
      "197386/197417 [============================>.] - ETA: 0s - loss: 0.4683 - accuracy: 0.8001\n",
      "Epoch 00008: val_loss did not improve from 0.47273\n",
      "197417/197417 [==============================] - 155s 786us/step - loss: 0.4683 - accuracy: 0.8001 - val_loss: 0.4829 - val_accuracy: 0.7912\n",
      "Epoch 9/20\n",
      "197381/197417 [============================>.] - ETA: 0s - loss: 0.4669 - accuracy: 0.8008\n",
      "Epoch 00009: val_loss improved from 0.47273 to 0.47049, saving model to NumberNetworkKFOLD1.h5\n",
      "197417/197417 [==============================] - 155s 783us/step - loss: 0.4669 - accuracy: 0.8008 - val_loss: 0.4705 - val_accuracy: 0.7984\n",
      "Epoch 10/20\n",
      "197403/197417 [============================>.] - ETA: 0s - loss: 0.4659 - accuracy: 0.8013\n",
      "Epoch 00010: val_loss improved from 0.47049 to 0.46363, saving model to NumberNetworkKFOLD1.h5\n",
      "197417/197417 [==============================] - 155s 785us/step - loss: 0.4659 - accuracy: 0.8013 - val_loss: 0.4636 - val_accuracy: 0.8025\n",
      "Epoch 11/20\n",
      "197348/197417 [============================>.] - ETA: 0s - loss: 0.4650 - accuracy: 0.8017\n",
      "Epoch 00011: val_loss did not improve from 0.46363\n",
      "197417/197417 [==============================] - 150s 758us/step - loss: 0.4650 - accuracy: 0.8017 - val_loss: 0.4723 - val_accuracy: 0.7981\n",
      "Epoch 12/20\n",
      "197409/197417 [============================>.] - ETA: 0s - loss: 0.4643 - accuracy: 0.8021\n",
      "Epoch 00012: val_loss did not improve from 0.46363\n",
      "197417/197417 [==============================] - 150s 759us/step - loss: 0.4643 - accuracy: 0.8021 - val_loss: 0.4930 - val_accuracy: 0.7861\n",
      "Epoch 13/20\n",
      "197381/197417 [============================>.] - ETA: 0s - loss: 0.4637 - accuracy: 0.8024\n",
      "Epoch 00013: val_loss improved from 0.46363 to 0.46266, saving model to NumberNetworkKFOLD1.h5\n",
      "197417/197417 [==============================] - 149s 756us/step - loss: 0.4637 - accuracy: 0.8024 - val_loss: 0.4627 - val_accuracy: 0.8028\n",
      "Epoch 14/20\n",
      "197400/197417 [============================>.] - ETA: 0s - loss: 0.4632 - accuracy: 0.8027\n",
      "Epoch 00014: val_loss improved from 0.46266 to 0.46266, saving model to NumberNetworkKFOLD1.h5\n",
      "197417/197417 [==============================] - 149s 755us/step - loss: 0.4632 - accuracy: 0.8027 - val_loss: 0.4627 - val_accuracy: 0.8024\n",
      "Epoch 15/20\n",
      "197365/197417 [============================>.] - ETA: 0s - loss: 0.4628 - accuracy: 0.8028\n",
      "Epoch 00015: val_loss improved from 0.46266 to 0.45993, saving model to NumberNetworkKFOLD1.h5\n",
      "197417/197417 [==============================] - 149s 753us/step - loss: 0.4628 - accuracy: 0.8028 - val_loss: 0.4599 - val_accuracy: 0.8047\n",
      "Epoch 16/20\n",
      "197412/197417 [============================>.] - ETA: 0s - loss: 0.4624 - accuracy: 0.8031\n",
      "Epoch 00016: val_loss did not improve from 0.45993\n",
      "197417/197417 [==============================] - 150s 758us/step - loss: 0.4624 - accuracy: 0.8031 - val_loss: 0.4636 - val_accuracy: 0.8029\n",
      "Epoch 17/20\n",
      "197388/197417 [============================>.] - ETA: 0s - loss: 0.4620 - accuracy: 0.8033\n",
      "Epoch 00017: val_loss did not improve from 0.45993\n",
      "197417/197417 [==============================] - 149s 754us/step - loss: 0.4620 - accuracy: 0.8033 - val_loss: 0.4619 - val_accuracy: 0.8035\n",
      "Epoch 18/20\n",
      "197372/197417 [============================>.] - ETA: 0s - loss: 0.4616 - accuracy: 0.8035\n",
      "Epoch 00018: val_loss improved from 0.45993 to 0.45928, saving model to NumberNetworkKFOLD1.h5\n",
      "197417/197417 [==============================] - 150s 758us/step - loss: 0.4616 - accuracy: 0.8035 - val_loss: 0.4593 - val_accuracy: 0.8051\n",
      "Epoch 19/20\n",
      "197380/197417 [============================>.] - ETA: 0s - loss: 0.4612 - accuracy: 0.8037\n",
      "Epoch 00019: val_loss did not improve from 0.45928\n",
      "197417/197417 [==============================] - 149s 756us/step - loss: 0.4612 - accuracy: 0.8037 - val_loss: 0.4646 - val_accuracy: 0.8022\n",
      "Epoch 20/20\n",
      "197405/197417 [============================>.] - ETA: 0s - loss: 0.4609 - accuracy: 0.8039\n",
      "Epoch 00020: val_loss improved from 0.45928 to 0.45734, saving model to NumberNetworkKFOLD1.h5\n",
      "197417/197417 [==============================] - 149s 757us/step - loss: 0.4609 - accuracy: 0.8039 - val_loss: 0.4573 - val_accuracy: 0.8058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-09 04:20:21,619 INFO] Testing on fold 1 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45699/45699 [==============================] - 24s 520us/step - loss: 0.4572 - accuracy: 0.8056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-09 04:20:45,658 INFO] Score for fold 1: loss of 0.45716723799705505; accuracy of 80.56027889251709%\n",
      "[2020-07-09 04:20:45,659 INFO] Calculating inference for fold 1 ...\n",
      "[2020-07-09 04:21:00,186 INFO] Writing fit history to output/NumberNetworkKFOLD.h5\n",
      "[2020-07-09 04:21:00,273 INFO] Building model for fold 2 from share/reference_number.py...\n",
      "[2020-07-09 04:21:03,656 INFO] Compiling for fold 2 ...\n",
      "[2020-07-09 04:21:03,663 INFO] Training for fold 2 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "197388/197417 [============================>.] - ETA: 0s - loss: 0.5400 - accuracy: 0.7605\n",
      "Epoch 00001: val_loss improved from inf to 0.49244, saving model to NumberNetworkKFOLD2.h5\n",
      "197417/197417 [==============================] - 149s 755us/step - loss: 0.5400 - accuracy: 0.7605 - val_loss: 0.4924 - val_accuracy: 0.7862\n",
      "Epoch 2/20\n",
      "197369/197417 [============================>.] - ETA: 0s - loss: 0.4873 - accuracy: 0.7895\n",
      "Epoch 00002: val_loss improved from 0.49244 to 0.47939, saving model to NumberNetworkKFOLD2.h5\n",
      "197417/197417 [==============================] - 149s 756us/step - loss: 0.4873 - accuracy: 0.7895 - val_loss: 0.4794 - val_accuracy: 0.7937\n",
      "Epoch 3/20\n",
      "197366/197417 [============================>.] - ETA: 0s - loss: 0.4786 - accuracy: 0.7943\n",
      "Epoch 00003: val_loss improved from 0.47939 to 0.47083, saving model to NumberNetworkKFOLD2.h5\n",
      "197417/197417 [==============================] - 149s 753us/step - loss: 0.4786 - accuracy: 0.7943 - val_loss: 0.4708 - val_accuracy: 0.7990\n",
      "Epoch 4/20\n",
      "197407/197417 [============================>.] - ETA: 0s - loss: 0.4747 - accuracy: 0.7963\n",
      "Epoch 00004: val_loss did not improve from 0.47083\n",
      "197417/197417 [==============================] - 149s 753us/step - loss: 0.4747 - accuracy: 0.7963 - val_loss: 0.4714 - val_accuracy: 0.7987\n",
      "Epoch 5/20\n",
      "197395/197417 [============================>.] - ETA: 0s - loss: 0.4721 - accuracy: 0.7977\n",
      "Epoch 00005: val_loss improved from 0.47083 to 0.46702, saving model to NumberNetworkKFOLD2.h5\n",
      "197417/197417 [==============================] - 149s 755us/step - loss: 0.4721 - accuracy: 0.7977 - val_loss: 0.4670 - val_accuracy: 0.8008\n",
      "Epoch 6/20\n",
      "197372/197417 [============================>.] - ETA: 0s - loss: 0.4701 - accuracy: 0.7986\n",
      "Epoch 00006: val_loss did not improve from 0.46702\n",
      "197417/197417 [==============================] - 149s 753us/step - loss: 0.4701 - accuracy: 0.7986 - val_loss: 0.4689 - val_accuracy: 0.7996\n",
      "Epoch 7/20\n",
      "197401/197417 [============================>.] - ETA: 0s - loss: 0.4685 - accuracy: 0.7992\n",
      "Epoch 00007: val_loss did not improve from 0.46702\n",
      "197417/197417 [==============================] - 149s 755us/step - loss: 0.4685 - accuracy: 0.7992 - val_loss: 0.4721 - val_accuracy: 0.7971\n",
      "Epoch 8/20\n",
      "197386/197417 [============================>.] - ETA: 0s - loss: 0.4672 - accuracy: 0.8000\n",
      "Epoch 00008: val_loss improved from 0.46702 to 0.46421, saving model to NumberNetworkKFOLD2.h5\n",
      "197417/197417 [==============================] - 149s 755us/step - loss: 0.4672 - accuracy: 0.8000 - val_loss: 0.4642 - val_accuracy: 0.8022\n",
      "Epoch 9/20\n",
      "197387/197417 [============================>.] - ETA: 0s - loss: 0.4662 - accuracy: 0.8005\n",
      "Epoch 00009: val_loss improved from 0.46421 to 0.46277, saving model to NumberNetworkKFOLD2.h5\n",
      "197417/197417 [==============================] - 149s 753us/step - loss: 0.4662 - accuracy: 0.8005 - val_loss: 0.4628 - val_accuracy: 0.8031\n",
      "Epoch 10/20\n",
      "197352/197417 [============================>.] - ETA: 0s - loss: 0.4654 - accuracy: 0.8011\n",
      "Epoch 00010: val_loss improved from 0.46277 to 0.46119, saving model to NumberNetworkKFOLD2.h5\n",
      "197417/197417 [==============================] - 149s 753us/step - loss: 0.4654 - accuracy: 0.8011 - val_loss: 0.4612 - val_accuracy: 0.8042\n",
      "Epoch 11/20\n",
      "197373/197417 [============================>.] - ETA: 0s - loss: 0.4646 - accuracy: 0.8017\n",
      "Epoch 00011: val_loss did not improve from 0.46119\n",
      "197417/197417 [==============================] - 149s 754us/step - loss: 0.4646 - accuracy: 0.8016 - val_loss: 0.4636 - val_accuracy: 0.8023\n",
      "Epoch 12/20\n",
      "197398/197417 [============================>.] - ETA: 0s - loss: 0.4640 - accuracy: 0.8022\n",
      "Epoch 00012: val_loss did not improve from 0.46119\n",
      "197417/197417 [==============================] - 149s 754us/step - loss: 0.4640 - accuracy: 0.8022 - val_loss: 0.4649 - val_accuracy: 0.8024\n",
      "Epoch 13/20\n",
      "197365/197417 [============================>.] - ETA: 0s - loss: 0.4634 - accuracy: 0.8025\n",
      "Epoch 00013: val_loss improved from 0.46119 to 0.46000, saving model to NumberNetworkKFOLD2.h5\n",
      "197417/197417 [==============================] - 150s 758us/step - loss: 0.4634 - accuracy: 0.8025 - val_loss: 0.4600 - val_accuracy: 0.8050\n",
      "Epoch 14/20\n",
      "197404/197417 [============================>.] - ETA: 0s - loss: 0.4628 - accuracy: 0.8030\n",
      "Epoch 00014: val_loss did not improve from 0.46000\n",
      "197417/197417 [==============================] - 150s 758us/step - loss: 0.4628 - accuracy: 0.8030 - val_loss: 0.4657 - val_accuracy: 0.8015\n",
      "Epoch 15/20\n",
      "197392/197417 [============================>.] - ETA: 0s - loss: 0.4623 - accuracy: 0.8034\n",
      "Epoch 00015: val_loss improved from 0.46000 to 0.45989, saving model to NumberNetworkKFOLD2.h5\n",
      "197417/197417 [==============================] - 149s 757us/step - loss: 0.4623 - accuracy: 0.8034 - val_loss: 0.4599 - val_accuracy: 0.8051\n",
      "Epoch 16/20\n",
      "197403/197417 [============================>.] - ETA: 0s - loss: 0.4618 - accuracy: 0.8038\n",
      "Epoch 00016: val_loss did not improve from 0.45989\n",
      "197417/197417 [==============================] - 150s 757us/step - loss: 0.4618 - accuracy: 0.8038 - val_loss: 0.4609 - val_accuracy: 0.8046\n",
      "Epoch 17/20\n",
      "197390/197417 [============================>.] - ETA: 0s - loss: 0.4614 - accuracy: 0.8041\n",
      "Epoch 00017: val_loss did not improve from 0.45989\n",
      "197417/197417 [==============================] - 149s 757us/step - loss: 0.4614 - accuracy: 0.8041 - val_loss: 0.4612 - val_accuracy: 0.8036\n",
      "Epoch 18/20\n",
      "197353/197417 [============================>.] - ETA: 0s - loss: 0.4610 - accuracy: 0.8043\n",
      "Epoch 00018: val_loss did not improve from 0.45989\n",
      "197417/197417 [==============================] - 149s 755us/step - loss: 0.4610 - accuracy: 0.8043 - val_loss: 0.4608 - val_accuracy: 0.8045\n",
      "Epoch 19/20\n",
      "197367/197417 [============================>.] - ETA: 0s - loss: 0.4607 - accuracy: 0.8045\n",
      "Epoch 00019: val_loss improved from 0.45989 to 0.45956, saving model to NumberNetworkKFOLD2.h5\n",
      "197417/197417 [==============================] - 149s 756us/step - loss: 0.4607 - accuracy: 0.8045 - val_loss: 0.4596 - val_accuracy: 0.8052\n",
      "Epoch 20/20\n",
      "197388/197417 [============================>.] - ETA: 0s - loss: 0.4603 - accuracy: 0.8048\n",
      "Epoch 00020: val_loss improved from 0.45956 to 0.45782, saving model to NumberNetworkKFOLD2.h5\n",
      "197417/197417 [==============================] - 150s 758us/step - loss: 0.4603 - accuracy: 0.8048 - val_loss: 0.4578 - val_accuracy: 0.8060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-09 05:10:49,557 INFO] Testing on fold 2 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45699/45699 [==============================] - 30s 664us/step - loss: 0.4595 - accuracy: 0.8050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-09 05:11:20,203 INFO] Score for fold 2: loss of 0.4595009386539459; accuracy of 80.50221800804138%\n",
      "[2020-07-09 05:11:20,204 INFO] Calculating inference for fold 2 ...\n",
      "[2020-07-09 05:11:35,633 INFO] Writing fit history to output/NumberNetworkKFOLD.h5\n",
      "[2020-07-09 05:11:35,720 INFO] Building model for fold 3 from share/reference_number.py...\n",
      "[2020-07-09 05:11:39,197 INFO] Compiling for fold 3 ...\n",
      "[2020-07-09 05:11:39,205 INFO] Training for fold 3 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "197374/197417 [============================>.] - ETA: 0s - loss: 0.5384 - accuracy: 0.7614\n",
      "Epoch 00001: val_loss improved from inf to 0.49049, saving model to NumberNetworkKFOLD3.h5\n",
      "197417/197417 [==============================] - 161s 814us/step - loss: 0.5384 - accuracy: 0.7615 - val_loss: 0.4905 - val_accuracy: 0.7867\n",
      "Epoch 2/20\n",
      "197376/197417 [============================>.] - ETA: 0s - loss: 0.4896 - accuracy: 0.7882\n",
      "Epoch 00002: val_loss improved from 0.49049 to 0.48002, saving model to NumberNetworkKFOLD3.h5\n",
      "197417/197417 [==============================] - 160s 812us/step - loss: 0.4896 - accuracy: 0.7882 - val_loss: 0.4800 - val_accuracy: 0.7943\n",
      "Epoch 3/20\n",
      "197354/197417 [============================>.] - ETA: 0s - loss: 0.4809 - accuracy: 0.7929\n",
      "Epoch 00003: val_loss improved from 0.48002 to 0.47614, saving model to NumberNetworkKFOLD3.h5\n",
      "197417/197417 [==============================] - 158s 803us/step - loss: 0.4809 - accuracy: 0.7929 - val_loss: 0.4761 - val_accuracy: 0.7962\n",
      "Epoch 4/20\n",
      "197402/197417 [============================>.] - ETA: 0s - loss: 0.4769 - accuracy: 0.7952\n",
      "Epoch 00004: val_loss improved from 0.47614 to 0.47574, saving model to NumberNetworkKFOLD3.h5\n",
      "197417/197417 [==============================] - 151s 764us/step - loss: 0.4769 - accuracy: 0.7952 - val_loss: 0.4757 - val_accuracy: 0.7974\n",
      "Epoch 5/20\n",
      "197366/197417 [============================>.] - ETA: 0s - loss: 0.4743 - accuracy: 0.7966\n",
      "Epoch 00005: val_loss improved from 0.47574 to 0.47253, saving model to NumberNetworkKFOLD3.h5\n",
      "197417/197417 [==============================] - 147s 747us/step - loss: 0.4743 - accuracy: 0.7966 - val_loss: 0.4725 - val_accuracy: 0.7979\n",
      "Epoch 6/20\n",
      "197410/197417 [============================>.] - ETA: 0s - loss: 0.4721 - accuracy: 0.7980\n",
      "Epoch 00006: val_loss improved from 0.47253 to 0.46934, saving model to NumberNetworkKFOLD3.h5\n",
      "197417/197417 [==============================] - 149s 753us/step - loss: 0.4721 - accuracy: 0.7980 - val_loss: 0.4693 - val_accuracy: 0.8001\n",
      "Epoch 7/20\n",
      "197397/197417 [============================>.] - ETA: 0s - loss: 0.4702 - accuracy: 0.7992\n",
      "Epoch 00007: val_loss improved from 0.46934 to 0.46731, saving model to NumberNetworkKFOLD3.h5\n",
      "197417/197417 [==============================] - 148s 751us/step - loss: 0.4702 - accuracy: 0.7992 - val_loss: 0.4673 - val_accuracy: 0.8014\n",
      "Epoch 8/20\n",
      "197353/197417 [============================>.] - ETA: 0s - loss: 0.4688 - accuracy: 0.7999\n",
      "Epoch 00008: val_loss improved from 0.46731 to 0.46550, saving model to NumberNetworkKFOLD3.h5\n",
      "197417/197417 [==============================] - 148s 749us/step - loss: 0.4688 - accuracy: 0.7999 - val_loss: 0.4655 - val_accuracy: 0.8023\n",
      "Epoch 9/20\n",
      "197407/197417 [============================>.] - ETA: 0s - loss: 0.4678 - accuracy: 0.8005\n",
      "Epoch 00009: val_loss did not improve from 0.46550\n",
      "197417/197417 [==============================] - 148s 750us/step - loss: 0.4678 - accuracy: 0.8005 - val_loss: 0.4711 - val_accuracy: 0.7992\n",
      "Epoch 10/20\n",
      "197417/197417 [==============================] - ETA: 0s - loss: 0.4668 - accuracy: 0.8010\n",
      "Epoch 00010: val_loss did not improve from 0.46550\n",
      "197417/197417 [==============================] - 148s 750us/step - loss: 0.4668 - accuracy: 0.8010 - val_loss: 0.4688 - val_accuracy: 0.8009\n",
      "Epoch 11/20\n",
      "197390/197417 [============================>.] - ETA: 0s - loss: 0.4661 - accuracy: 0.8013\n",
      "Epoch 00011: val_loss improved from 0.46550 to 0.46288, saving model to NumberNetworkKFOLD3.h5\n",
      "197417/197417 [==============================] - 148s 752us/step - loss: 0.4661 - accuracy: 0.8013 - val_loss: 0.4629 - val_accuracy: 0.8037\n",
      "Epoch 12/20\n",
      "197364/197417 [============================>.] - ETA: 0s - loss: 0.4654 - accuracy: 0.8018\n",
      "Epoch 00012: val_loss did not improve from 0.46288\n",
      "197417/197417 [==============================] - 149s 756us/step - loss: 0.4654 - accuracy: 0.8018 - val_loss: 0.4632 - val_accuracy: 0.8025\n",
      "Epoch 13/20\n",
      "197387/197417 [============================>.] - ETA: 0s - loss: 0.4647 - accuracy: 0.8022\n",
      "Epoch 00013: val_loss improved from 0.46288 to 0.46250, saving model to NumberNetworkKFOLD3.h5\n",
      "197417/197417 [==============================] - 148s 751us/step - loss: 0.4647 - accuracy: 0.8022 - val_loss: 0.4625 - val_accuracy: 0.8034\n",
      "Epoch 14/20\n",
      "197348/197417 [============================>.] - ETA: 0s - loss: 0.4642 - accuracy: 0.8024\n",
      "Epoch 00014: val_loss improved from 0.46250 to 0.46204, saving model to NumberNetworkKFOLD3.h5\n",
      "197417/197417 [==============================] - 149s 753us/step - loss: 0.4642 - accuracy: 0.8024 - val_loss: 0.4620 - val_accuracy: 0.8039\n",
      "Epoch 15/20\n",
      "197349/197417 [============================>.] - ETA: 0s - loss: 0.4637 - accuracy: 0.8027\n",
      "Epoch 00015: val_loss improved from 0.46204 to 0.46149, saving model to NumberNetworkKFOLD3.h5\n",
      "197417/197417 [==============================] - 149s 753us/step - loss: 0.4637 - accuracy: 0.8027 - val_loss: 0.4615 - val_accuracy: 0.8044\n",
      "Epoch 16/20\n",
      "197379/197417 [============================>.] - ETA: 0s - loss: 0.4632 - accuracy: 0.8030\n",
      "Epoch 00016: val_loss did not improve from 0.46149\n",
      "197417/197417 [==============================] - 148s 749us/step - loss: 0.4632 - accuracy: 0.8030 - val_loss: 0.4661 - val_accuracy: 0.8007\n",
      "Epoch 17/20\n",
      "197396/197417 [============================>.] - ETA: 0s - loss: 0.4628 - accuracy: 0.8032\n",
      "Epoch 00017: val_loss improved from 0.46149 to 0.46071, saving model to NumberNetworkKFOLD3.h5\n",
      "197417/197417 [==============================] - 149s 754us/step - loss: 0.4628 - accuracy: 0.8032 - val_loss: 0.4607 - val_accuracy: 0.8045\n",
      "Epoch 18/20\n",
      "197356/197417 [============================>.] - ETA: 0s - loss: 0.4624 - accuracy: 0.8034\n",
      "Epoch 00018: val_loss did not improve from 0.46071\n",
      "197417/197417 [==============================] - 148s 751us/step - loss: 0.4624 - accuracy: 0.8034 - val_loss: 0.4763 - val_accuracy: 0.7960\n",
      "Epoch 19/20\n",
      "197400/197417 [============================>.] - ETA: 0s - loss: 0.4621 - accuracy: 0.8037\n",
      "Epoch 00019: val_loss improved from 0.46071 to 0.45914, saving model to NumberNetworkKFOLD3.h5\n",
      "197417/197417 [==============================] - 148s 748us/step - loss: 0.4621 - accuracy: 0.8037 - val_loss: 0.4591 - val_accuracy: 0.8052\n",
      "Epoch 20/20\n",
      "197383/197417 [============================>.] - ETA: 0s - loss: 0.4618 - accuracy: 0.8038\n",
      "Epoch 00020: val_loss did not improve from 0.45914\n",
      "197417/197417 [==============================] - 148s 749us/step - loss: 0.4618 - accuracy: 0.8038 - val_loss: 0.4619 - val_accuracy: 0.8049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-09 06:01:45,483 INFO] Testing on fold 3 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45699/45699 [==============================] - 24s 528us/step - loss: 0.4637 - accuracy: 0.8036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-09 06:02:09,845 INFO] Score for fold 3: loss of 0.4636576771736145; accuracy of 80.36224246025085%\n",
      "[2020-07-09 06:02:09,845 INFO] Calculating inference for fold 3 ...\n",
      "[2020-07-09 06:02:23,627 INFO] Writing fit history to output/NumberNetworkKFOLD.h5\n",
      "[2020-07-09 06:02:23,717 INFO] Building model for fold 4 from share/reference_number.py...\n",
      "[2020-07-09 06:02:27,456 INFO] Compiling for fold 4 ...\n",
      "[2020-07-09 06:02:27,462 INFO] Training for fold 4 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "197371/197417 [============================>.] - ETA: 0s - loss: 0.5418 - accuracy: 0.7601\n",
      "Epoch 00001: val_loss improved from inf to 0.50759, saving model to NumberNetworkKFOLD4.h5\n",
      "197417/197417 [==============================] - 150s 761us/step - loss: 0.5418 - accuracy: 0.7601 - val_loss: 0.5076 - val_accuracy: 0.7758\n",
      "Epoch 2/20\n",
      "197359/197417 [============================>.] - ETA: 0s - loss: 0.4912 - accuracy: 0.7875\n",
      "Epoch 00002: val_loss improved from 0.50759 to 0.49833, saving model to NumberNetworkKFOLD4.h5\n",
      "197417/197417 [==============================] - 147s 746us/step - loss: 0.4912 - accuracy: 0.7875 - val_loss: 0.4983 - val_accuracy: 0.7825\n",
      "Epoch 3/20\n",
      "197393/197417 [============================>.] - ETA: 0s - loss: 0.4819 - accuracy: 0.7926\n",
      "Epoch 00003: val_loss improved from 0.49833 to 0.47466, saving model to NumberNetworkKFOLD4.h5\n",
      "197417/197417 [==============================] - 147s 745us/step - loss: 0.4819 - accuracy: 0.7926 - val_loss: 0.4747 - val_accuracy: 0.7964\n",
      "Epoch 4/20\n",
      "197358/197417 [============================>.] - ETA: 0s - loss: 0.4772 - accuracy: 0.7952\n",
      "Epoch 00004: val_loss improved from 0.47466 to 0.47090, saving model to NumberNetworkKFOLD4.h5\n",
      "197417/197417 [==============================] - 149s 752us/step - loss: 0.4772 - accuracy: 0.7952 - val_loss: 0.4709 - val_accuracy: 0.7987\n",
      "Epoch 5/20\n",
      "197353/197417 [============================>.] - ETA: 0s - loss: 0.4744 - accuracy: 0.7967\n",
      "Epoch 00005: val_loss did not improve from 0.47090\n",
      "197417/197417 [==============================] - 148s 752us/step - loss: 0.4744 - accuracy: 0.7967 - val_loss: 0.4781 - val_accuracy: 0.7954\n",
      "Epoch 6/20\n",
      "197389/197417 [============================>.] - ETA: 0s - loss: 0.4726 - accuracy: 0.7975\n",
      "Epoch 00006: val_loss did not improve from 0.47090\n",
      "197417/197417 [==============================] - 148s 749us/step - loss: 0.4726 - accuracy: 0.7975 - val_loss: 0.4766 - val_accuracy: 0.7963\n",
      "Epoch 7/20\n",
      "197362/197417 [============================>.] - ETA: 0s - loss: 0.4712 - accuracy: 0.7982\n",
      "Epoch 00007: val_loss improved from 0.47090 to 0.46556, saving model to NumberNetworkKFOLD4.h5\n",
      "197417/197417 [==============================] - 148s 748us/step - loss: 0.4712 - accuracy: 0.7982 - val_loss: 0.4656 - val_accuracy: 0.8012\n",
      "Epoch 8/20\n",
      "197407/197417 [============================>.] - ETA: 0s - loss: 0.4701 - accuracy: 0.7988\n",
      "Epoch 00008: val_loss did not improve from 0.46556\n",
      "197417/197417 [==============================] - 147s 745us/step - loss: 0.4701 - accuracy: 0.7988 - val_loss: 0.4861 - val_accuracy: 0.7896\n",
      "Epoch 9/20\n",
      "197348/197417 [============================>.] - ETA: 0s - loss: 0.4691 - accuracy: 0.7993\n",
      "Epoch 00009: val_loss did not improve from 0.46556\n",
      "197417/197417 [==============================] - 147s 746us/step - loss: 0.4691 - accuracy: 0.7993 - val_loss: 0.4692 - val_accuracy: 0.8003\n",
      "Epoch 10/20\n",
      "197415/197417 [============================>.] - ETA: 0s - loss: 0.4682 - accuracy: 0.7998\n",
      "Epoch 00010: val_loss did not improve from 0.46556\n",
      "197417/197417 [==============================] - 148s 749us/step - loss: 0.4682 - accuracy: 0.7998 - val_loss: 0.4732 - val_accuracy: 0.7974\n",
      "Epoch 11/20\n",
      "197378/197417 [============================>.] - ETA: 0s - loss: 0.4673 - accuracy: 0.8003\n",
      "Epoch 00011: val_loss did not improve from 0.46556\n",
      "197417/197417 [==============================] - 147s 745us/step - loss: 0.4673 - accuracy: 0.8003 - val_loss: 0.4673 - val_accuracy: 0.8001\n",
      "Epoch 12/20\n",
      "197365/197417 [============================>.] - ETA: 0s - loss: 0.4666 - accuracy: 0.8008\n",
      "Epoch 00012: val_loss did not improve from 0.46556\n",
      "197417/197417 [==============================] - 148s 747us/step - loss: 0.4666 - accuracy: 0.8008 - val_loss: 0.4676 - val_accuracy: 0.8010\n",
      "Epoch 13/20\n",
      "197400/197417 [============================>.] - ETA: 0s - loss: 0.4658 - accuracy: 0.8013\n",
      "Epoch 00013: val_loss did not improve from 0.46556\n",
      "197417/197417 [==============================] - 147s 746us/step - loss: 0.4658 - accuracy: 0.8013 - val_loss: 0.4671 - val_accuracy: 0.8006\n",
      "Epoch 14/20\n",
      "197416/197417 [============================>.] - ETA: 0s - loss: 0.4651 - accuracy: 0.8017\n",
      "Epoch 00014: val_loss did not improve from 0.46556\n",
      "197417/197417 [==============================] - 147s 744us/step - loss: 0.4651 - accuracy: 0.8017 - val_loss: 0.4657 - val_accuracy: 0.8018\n",
      "Epoch 15/20\n",
      "197380/197417 [============================>.] - ETA: 0s - loss: 0.4645 - accuracy: 0.8020\n",
      "Epoch 00015: val_loss improved from 0.46556 to 0.46448, saving model to NumberNetworkKFOLD4.h5\n",
      "197417/197417 [==============================] - 148s 749us/step - loss: 0.4645 - accuracy: 0.8020 - val_loss: 0.4645 - val_accuracy: 0.8022\n",
      "Epoch 16/20\n",
      "197363/197417 [============================>.] - ETA: 0s - loss: 0.4639 - accuracy: 0.8023\n",
      "Epoch 00016: val_loss improved from 0.46448 to 0.46099, saving model to NumberNetworkKFOLD4.h5\n",
      "197417/197417 [==============================] - 148s 748us/step - loss: 0.4639 - accuracy: 0.8023 - val_loss: 0.4610 - val_accuracy: 0.8040\n",
      "Epoch 17/20\n",
      "197378/197417 [============================>.] - ETA: 0s - loss: 0.4635 - accuracy: 0.8025\n",
      "Epoch 00017: val_loss did not improve from 0.46099\n",
      "197417/197417 [==============================] - 147s 746us/step - loss: 0.4635 - accuracy: 0.8025 - val_loss: 0.4635 - val_accuracy: 0.8030\n",
      "Epoch 18/20\n",
      "197390/197417 [============================>.] - ETA: 0s - loss: 0.4631 - accuracy: 0.8028\n",
      "Epoch 00018: val_loss did not improve from 0.46099\n",
      "197417/197417 [==============================] - 147s 745us/step - loss: 0.4631 - accuracy: 0.8028 - val_loss: 0.4612 - val_accuracy: 0.8034\n",
      "Epoch 19/20\n",
      "197379/197417 [============================>.] - ETA: 0s - loss: 0.4627 - accuracy: 0.8029\n",
      "Epoch 00019: val_loss did not improve from 0.46099\n",
      "197417/197417 [==============================] - 147s 746us/step - loss: 0.4627 - accuracy: 0.8029 - val_loss: 0.4629 - val_accuracy: 0.8031\n",
      "Epoch 20/20\n",
      "197400/197417 [============================>.] - ETA: 0s - loss: 0.4623 - accuracy: 0.8030\n",
      "Epoch 00020: val_loss improved from 0.46099 to 0.45889, saving model to NumberNetworkKFOLD4.h5\n",
      "197417/197417 [==============================] - 148s 748us/step - loss: 0.4623 - accuracy: 0.8030 - val_loss: 0.4589 - val_accuracy: 0.8048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-09 06:51:48,497 INFO] Testing on fold 4 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45699/45699 [==============================] - 24s 530us/step - loss: 0.4593 - accuracy: 0.8048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-09 06:52:13,104 INFO] Score for fold 4: loss of 0.4593290388584137; accuracy of 80.47602772712708%\n",
      "[2020-07-09 06:52:13,105 INFO] Calculating inference for fold 4 ...\n",
      "[2020-07-09 06:52:26,818 INFO] Writing fit history to output/NumberNetworkKFOLD.h5\n",
      "[2020-07-09 06:53:30,228 INFO] Building model for fold 5 from share/reference_number.py...\n",
      "[2020-07-09 06:53:35,046 INFO] Compiling for fold 5 ...\n",
      "[2020-07-09 06:53:35,053 INFO] Training for fold 5 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "197389/197417 [============================>.] - ETA: 0s - loss: 0.5376 - accuracy: 0.7623\n",
      "Epoch 00001: val_loss improved from inf to 0.49117, saving model to NumberNetworkKFOLD5.h5\n",
      "197417/197417 [==============================] - 151s 766us/step - loss: 0.5376 - accuracy: 0.7623 - val_loss: 0.4912 - val_accuracy: 0.7911\n",
      "Epoch 2/20\n",
      "197394/197417 [============================>.] - ETA: 0s - loss: 0.4915 - accuracy: 0.7879\n",
      "Epoch 00002: val_loss improved from 0.49117 to 0.47728, saving model to NumberNetworkKFOLD5.h5\n",
      "197417/197417 [==============================] - 148s 748us/step - loss: 0.4915 - accuracy: 0.7879 - val_loss: 0.4773 - val_accuracy: 0.7961\n",
      "Epoch 3/20\n",
      "197402/197417 [============================>.] - ETA: 0s - loss: 0.4818 - accuracy: 0.7928\n",
      "Epoch 00003: val_loss did not improve from 0.47728\n",
      "197417/197417 [==============================] - 148s 749us/step - loss: 0.4818 - accuracy: 0.7928 - val_loss: 0.4809 - val_accuracy: 0.7924\n",
      "Epoch 4/20\n",
      "197375/197417 [============================>.] - ETA: 0s - loss: 0.4769 - accuracy: 0.7954\n",
      "Epoch 00004: val_loss improved from 0.47728 to 0.47432, saving model to NumberNetworkKFOLD5.h5\n",
      "197417/197417 [==============================] - 148s 750us/step - loss: 0.4769 - accuracy: 0.7954 - val_loss: 0.4743 - val_accuracy: 0.7969\n",
      "Epoch 5/20\n",
      "197386/197417 [============================>.] - ETA: 0s - loss: 0.4736 - accuracy: 0.7971\n",
      "Epoch 00005: val_loss did not improve from 0.47432\n",
      "197417/197417 [==============================] - 149s 752us/step - loss: 0.4736 - accuracy: 0.7971 - val_loss: 0.4775 - val_accuracy: 0.7935\n",
      "Epoch 6/20\n",
      "197352/197417 [============================>.] - ETA: 0s - loss: 0.4714 - accuracy: 0.7982\n",
      "Epoch 00006: val_loss improved from 0.47432 to 0.47387, saving model to NumberNetworkKFOLD5.h5\n",
      "197417/197417 [==============================] - 148s 749us/step - loss: 0.4714 - accuracy: 0.7982 - val_loss: 0.4739 - val_accuracy: 0.7967\n",
      "Epoch 7/20\n",
      "197352/197417 [============================>.] - ETA: 0s - loss: 0.4699 - accuracy: 0.7991\n",
      "Epoch 00007: val_loss improved from 0.47387 to 0.47294, saving model to NumberNetworkKFOLD5.h5\n",
      "197417/197417 [==============================] - 149s 755us/step - loss: 0.4699 - accuracy: 0.7991 - val_loss: 0.4729 - val_accuracy: 0.7971\n",
      "Epoch 8/20\n",
      "197413/197417 [============================>.] - ETA: 0s - loss: 0.4687 - accuracy: 0.7999\n",
      "Epoch 00008: val_loss improved from 0.47294 to 0.46597, saving model to NumberNetworkKFOLD5.h5\n",
      "197417/197417 [==============================] - 149s 754us/step - loss: 0.4687 - accuracy: 0.7999 - val_loss: 0.4660 - val_accuracy: 0.8019\n",
      "Epoch 9/20\n",
      "197380/197417 [============================>.] - ETA: 0s - loss: 0.4677 - accuracy: 0.8005\n",
      "Epoch 00009: val_loss did not improve from 0.46597\n",
      "197417/197417 [==============================] - 148s 751us/step - loss: 0.4677 - accuracy: 0.8005 - val_loss: 0.4660 - val_accuracy: 0.8017\n",
      "Epoch 10/20\n",
      "197360/197417 [============================>.] - ETA: 0s - loss: 0.4668 - accuracy: 0.8012\n",
      "Epoch 00010: val_loss improved from 0.46597 to 0.46363, saving model to NumberNetworkKFOLD5.h5\n",
      "197417/197417 [==============================] - 150s 760us/step - loss: 0.4668 - accuracy: 0.8012 - val_loss: 0.4636 - val_accuracy: 0.8031\n",
      "Epoch 11/20\n",
      "197377/197417 [============================>.] - ETA: 0s - loss: 0.4659 - accuracy: 0.8018\n",
      "Epoch 00011: val_loss improved from 0.46363 to 0.46304, saving model to NumberNetworkKFOLD5.h5\n",
      "197417/197417 [==============================] - 148s 751us/step - loss: 0.4659 - accuracy: 0.8018 - val_loss: 0.4630 - val_accuracy: 0.8028\n",
      "Epoch 12/20\n",
      "197401/197417 [============================>.] - ETA: 0s - loss: 0.4652 - accuracy: 0.8022\n",
      "Epoch 00012: val_loss did not improve from 0.46304\n",
      "197417/197417 [==============================] - 149s 754us/step - loss: 0.4652 - accuracy: 0.8022 - val_loss: 0.4634 - val_accuracy: 0.8030\n",
      "Epoch 13/20\n",
      "197407/197417 [============================>.] - ETA: 0s - loss: 0.4645 - accuracy: 0.8025\n",
      "Epoch 00013: val_loss did not improve from 0.46304\n",
      "197417/197417 [==============================] - 148s 752us/step - loss: 0.4645 - accuracy: 0.8025 - val_loss: 0.4658 - val_accuracy: 0.8015\n",
      "Epoch 14/20\n",
      "197370/197417 [============================>.] - ETA: 0s - loss: 0.4639 - accuracy: 0.8028\n",
      "Epoch 00014: val_loss improved from 0.46304 to 0.46297, saving model to NumberNetworkKFOLD5.h5\n",
      "197417/197417 [==============================] - 149s 754us/step - loss: 0.4639 - accuracy: 0.8028 - val_loss: 0.4630 - val_accuracy: 0.8037\n",
      "Epoch 15/20\n",
      "197406/197417 [============================>.] - ETA: 0s - loss: 0.4634 - accuracy: 0.8031\n",
      "Epoch 00015: val_loss improved from 0.46297 to 0.45964, saving model to NumberNetworkKFOLD5.h5\n",
      "197417/197417 [==============================] - 149s 753us/step - loss: 0.4634 - accuracy: 0.8031 - val_loss: 0.4596 - val_accuracy: 0.8051\n",
      "Epoch 16/20\n",
      "197401/197417 [============================>.] - ETA: 0s - loss: 0.4628 - accuracy: 0.8033\n",
      "Epoch 00016: val_loss did not improve from 0.45964\n",
      "197417/197417 [==============================] - 148s 749us/step - loss: 0.4629 - accuracy: 0.8033 - val_loss: 0.4648 - val_accuracy: 0.8026\n",
      "Epoch 17/20\n",
      "197363/197417 [============================>.] - ETA: 0s - loss: 0.4624 - accuracy: 0.8036\n",
      "Epoch 00017: val_loss did not improve from 0.45964\n",
      "197417/197417 [==============================] - 148s 750us/step - loss: 0.4624 - accuracy: 0.8036 - val_loss: 0.4613 - val_accuracy: 0.8043\n",
      "Epoch 18/20\n",
      "197367/197417 [============================>.] - ETA: 0s - loss: 0.4620 - accuracy: 0.8037\n",
      "Epoch 00018: val_loss did not improve from 0.45964\n",
      "197417/197417 [==============================] - 149s 753us/step - loss: 0.4620 - accuracy: 0.8037 - val_loss: 0.4601 - val_accuracy: 0.8052\n",
      "Epoch 19/20\n",
      "197413/197417 [============================>.] - ETA: 0s - loss: 0.4616 - accuracy: 0.8039\n",
      "Epoch 00019: val_loss did not improve from 0.45964\n",
      "197417/197417 [==============================] - 148s 749us/step - loss: 0.4616 - accuracy: 0.8039 - val_loss: 0.4601 - val_accuracy: 0.8050\n",
      "Epoch 20/20\n",
      "197355/197417 [============================>.] - ETA: 0s - loss: 0.4612 - accuracy: 0.8042\n",
      "Epoch 00020: val_loss did not improve from 0.45964\n",
      "197417/197417 [==============================] - 148s 752us/step - loss: 0.4612 - accuracy: 0.8042 - val_loss: 0.4599 - val_accuracy: 0.8048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-09 07:43:15,836 INFO] Testing on fold 5 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45699/45699 [==============================] - 24s 531us/step - loss: 0.4602 - accuracy: 0.8051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-09 07:43:40,782 INFO] Score for fold 5: loss of 0.4601914882659912; accuracy of 80.50960302352905%\n",
      "[2020-07-09 07:43:40,783 INFO] Calculating inference for fold 5 ...\n",
      "[2020-07-09 07:43:56,189 INFO] Writing fit history to output/NumberNetworkKFOLD.h5\n",
      "[2020-07-09 07:44:05,067 INFO] Building model for fold 6 from share/reference_number.py...\n",
      "[2020-07-09 07:44:12,642 INFO] Compiling for fold 6 ...\n",
      "[2020-07-09 07:44:12,649 INFO] Training for fold 6 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "197404/197417 [============================>.] - ETA: 0s - loss: 0.5395 - accuracy: 0.7607\n",
      "Epoch 00001: val_loss improved from inf to 0.52507, saving model to NumberNetworkKFOLD6.h5\n",
      "197417/197417 [==============================] - 148s 752us/step - loss: 0.5395 - accuracy: 0.7607 - val_loss: 0.5251 - val_accuracy: 0.7706\n",
      "Epoch 2/20\n",
      "197389/197417 [============================>.] - ETA: 0s - loss: 0.4912 - accuracy: 0.7873\n",
      "Epoch 00002: val_loss improved from 0.52507 to 0.49044, saving model to NumberNetworkKFOLD6.h5\n",
      "197417/197417 [==============================] - 148s 751us/step - loss: 0.4912 - accuracy: 0.7873 - val_loss: 0.4904 - val_accuracy: 0.7888\n",
      "Epoch 3/20\n",
      "197406/197417 [============================>.] - ETA: 0s - loss: 0.4821 - accuracy: 0.7924\n",
      "Epoch 00003: val_loss improved from 0.49044 to 0.47464, saving model to NumberNetworkKFOLD6.h5\n",
      "197417/197417 [==============================] - 149s 752us/step - loss: 0.4821 - accuracy: 0.7924 - val_loss: 0.4746 - val_accuracy: 0.7964\n",
      "Epoch 4/20\n",
      "197386/197417 [============================>.] - ETA: 0s - loss: 0.4768 - accuracy: 0.7949\n",
      "Epoch 00004: val_loss did not improve from 0.47464\n",
      "197417/197417 [==============================] - 148s 752us/step - loss: 0.4768 - accuracy: 0.7949 - val_loss: 0.4760 - val_accuracy: 0.7957\n",
      "Epoch 5/20\n",
      "197407/197417 [============================>.] - ETA: 0s - loss: 0.4731 - accuracy: 0.7968\n",
      "Epoch 00005: val_loss improved from 0.47464 to 0.46996, saving model to NumberNetworkKFOLD6.h5\n",
      "197417/197417 [==============================] - 150s 761us/step - loss: 0.4731 - accuracy: 0.7968 - val_loss: 0.4700 - val_accuracy: 0.7991\n",
      "Epoch 6/20\n",
      "197355/197417 [============================>.] - ETA: 0s - loss: 0.4708 - accuracy: 0.7980\n",
      "Epoch 00006: val_loss improved from 0.46996 to 0.46868, saving model to NumberNetworkKFOLD6.h5\n",
      "197417/197417 [==============================] - 148s 751us/step - loss: 0.4708 - accuracy: 0.7980 - val_loss: 0.4687 - val_accuracy: 0.7995\n",
      "Epoch 7/20\n",
      "197381/197417 [============================>.] - ETA: 0s - loss: 0.4692 - accuracy: 0.7988\n",
      "Epoch 00007: val_loss improved from 0.46868 to 0.46559, saving model to NumberNetworkKFOLD6.h5\n",
      "197417/197417 [==============================] - 149s 754us/step - loss: 0.4692 - accuracy: 0.7988 - val_loss: 0.4656 - val_accuracy: 0.8010\n",
      "Epoch 8/20\n",
      "197378/197417 [============================>.] - ETA: 0s - loss: 0.4680 - accuracy: 0.7994\n",
      "Epoch 00008: val_loss improved from 0.46559 to 0.46491, saving model to NumberNetworkKFOLD6.h5\n",
      "197417/197417 [==============================] - 149s 754us/step - loss: 0.4680 - accuracy: 0.7994 - val_loss: 0.4649 - val_accuracy: 0.8008\n",
      "Epoch 9/20\n",
      "197396/197417 [============================>.] - ETA: 0s - loss: 0.4669 - accuracy: 0.7999\n",
      "Epoch 00009: val_loss did not improve from 0.46491\n",
      "197417/197417 [==============================] - 149s 755us/step - loss: 0.4669 - accuracy: 0.7999 - val_loss: 0.4665 - val_accuracy: 0.8008\n",
      "Epoch 10/20\n",
      "197405/197417 [============================>.] - ETA: 0s - loss: 0.4659 - accuracy: 0.8004\n",
      "Epoch 00010: val_loss improved from 0.46491 to 0.46086, saving model to NumberNetworkKFOLD6.h5\n",
      "197417/197417 [==============================] - 149s 754us/step - loss: 0.4659 - accuracy: 0.8004 - val_loss: 0.4609 - val_accuracy: 0.8033\n",
      "Epoch 11/20\n",
      "197362/197417 [============================>.] - ETA: 0s - loss: 0.4647 - accuracy: 0.8010\n",
      "Epoch 00011: val_loss did not improve from 0.46086\n",
      "197417/197417 [==============================] - 149s 755us/step - loss: 0.4647 - accuracy: 0.8010 - val_loss: 0.4613 - val_accuracy: 0.8027\n",
      "Epoch 12/20\n",
      "197407/197417 [============================>.] - ETA: 0s - loss: 0.4637 - accuracy: 0.8015\n",
      "Epoch 00012: val_loss did not improve from 0.46086\n",
      "197417/197417 [==============================] - 149s 756us/step - loss: 0.4637 - accuracy: 0.8015 - val_loss: 0.4644 - val_accuracy: 0.8014\n",
      "Epoch 13/20\n",
      "197380/197417 [============================>.] - ETA: 0s - loss: 0.4628 - accuracy: 0.8020\n",
      "Epoch 00013: val_loss did not improve from 0.46086\n",
      "197417/197417 [==============================] - 149s 755us/step - loss: 0.4628 - accuracy: 0.8020 - val_loss: 0.4625 - val_accuracy: 0.8023\n",
      "Epoch 14/20\n",
      "197347/197417 [============================>.] - ETA: 0s - loss: 0.4619 - accuracy: 0.8026\n",
      "Epoch 00014: val_loss improved from 0.46086 to 0.45858, saving model to NumberNetworkKFOLD6.h5\n",
      "197417/197417 [==============================] - 149s 753us/step - loss: 0.4619 - accuracy: 0.8026 - val_loss: 0.4586 - val_accuracy: 0.8045\n",
      "Epoch 15/20\n",
      "197369/197417 [============================>.] - ETA: 0s - loss: 0.4613 - accuracy: 0.8029\n",
      "Epoch 00015: val_loss did not improve from 0.45858\n",
      "197417/197417 [==============================] - 149s 753us/step - loss: 0.4613 - accuracy: 0.8029 - val_loss: 0.4601 - val_accuracy: 0.8044\n",
      "Epoch 16/20\n",
      "197388/197417 [============================>.] - ETA: 0s - loss: 0.4608 - accuracy: 0.8032\n",
      "Epoch 00016: val_loss improved from 0.45858 to 0.45736, saving model to NumberNetworkKFOLD6.h5\n",
      "197417/197417 [==============================] - 149s 755us/step - loss: 0.4608 - accuracy: 0.8032 - val_loss: 0.4574 - val_accuracy: 0.8049\n",
      "Epoch 17/20\n",
      "197381/197417 [============================>.] - ETA: 0s - loss: 0.4604 - accuracy: 0.8034\n",
      "Epoch 00017: val_loss did not improve from 0.45736\n",
      "197417/197417 [==============================] - 149s 755us/step - loss: 0.4604 - accuracy: 0.8034 - val_loss: 0.4636 - val_accuracy: 0.8020\n",
      "Epoch 18/20\n",
      "197396/197417 [============================>.] - ETA: 0s - loss: 0.4601 - accuracy: 0.8036\n",
      "Epoch 00018: val_loss did not improve from 0.45736\n",
      "197417/197417 [==============================] - 149s 753us/step - loss: 0.4601 - accuracy: 0.8036 - val_loss: 0.4589 - val_accuracy: 0.8048\n",
      "Epoch 19/20\n",
      "197387/197417 [============================>.] - ETA: 0s - loss: 0.4598 - accuracy: 0.8038\n",
      "Epoch 00019: val_loss did not improve from 0.45736\n",
      "197417/197417 [==============================] - 149s 754us/step - loss: 0.4598 - accuracy: 0.8038 - val_loss: 0.4581 - val_accuracy: 0.8047\n",
      "Epoch 20/20\n",
      "197385/197417 [============================>.] - ETA: 0s - loss: 0.4595 - accuracy: 0.8040\n",
      "Epoch 00020: val_loss improved from 0.45736 to 0.45707, saving model to NumberNetworkKFOLD6.h5\n",
      "197417/197417 [==============================] - 149s 754us/step - loss: 0.4595 - accuracy: 0.8040 - val_loss: 0.4571 - val_accuracy: 0.8059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-09 08:33:53,507 INFO] Testing on fold 6 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45699/45699 [==============================] - 24s 526us/step - loss: 0.4581 - accuracy: 0.8053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-09 08:34:17,768 INFO] Score for fold 6: loss of 0.4581122398376465; accuracy of 80.52593469619751%\n",
      "[2020-07-09 08:34:17,769 INFO] Calculating inference for fold 6 ...\n",
      "[2020-07-09 08:34:31,306 INFO] Writing fit history to output/NumberNetworkKFOLD.h5\n",
      "[2020-07-09 08:34:31,569 INFO] Building model for fold 7 from share/reference_number.py...\n",
      "[2020-07-09 08:34:34,899 INFO] Compiling for fold 7 ...\n",
      "[2020-07-09 08:34:34,906 INFO] Training for fold 7 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "197417/197417 [==============================] - ETA: 0s - loss: 0.5419 - accuracy: 0.7596\n",
      "Epoch 00001: val_loss improved from inf to 0.49930, saving model to NumberNetworkKFOLD7.h5\n",
      "197417/197417 [==============================] - 149s 755us/step - loss: 0.5419 - accuracy: 0.7596 - val_loss: 0.4993 - val_accuracy: 0.7841\n",
      "Epoch 2/20\n",
      "197359/197417 [============================>.] - ETA: 0s - loss: 0.4935 - accuracy: 0.7866\n",
      "Epoch 00002: val_loss did not improve from 0.49930\n",
      "197417/197417 [==============================] - 148s 751us/step - loss: 0.4935 - accuracy: 0.7866 - val_loss: 0.5022 - val_accuracy: 0.7834\n",
      "Epoch 3/20\n",
      "197366/197417 [============================>.] - ETA: 0s - loss: 0.4832 - accuracy: 0.7920\n",
      "Epoch 00003: val_loss improved from 0.49930 to 0.49397, saving model to NumberNetworkKFOLD7.h5\n",
      "197417/197417 [==============================] - 150s 759us/step - loss: 0.4832 - accuracy: 0.7920 - val_loss: 0.4940 - val_accuracy: 0.7853\n",
      "Epoch 4/20\n",
      "197361/197417 [============================>.] - ETA: 0s - loss: 0.4782 - accuracy: 0.7945\n",
      "Epoch 00004: val_loss improved from 0.49397 to 0.47344, saving model to NumberNetworkKFOLD7.h5\n",
      "197417/197417 [==============================] - 148s 748us/step - loss: 0.4782 - accuracy: 0.7945 - val_loss: 0.4734 - val_accuracy: 0.7971\n",
      "Epoch 5/20\n",
      "197355/197417 [============================>.] - ETA: 0s - loss: 0.4741 - accuracy: 0.7967\n",
      "Epoch 00005: val_loss improved from 0.47344 to 0.47226, saving model to NumberNetworkKFOLD7.h5\n",
      "197417/197417 [==============================] - 148s 750us/step - loss: 0.4741 - accuracy: 0.7967 - val_loss: 0.4723 - val_accuracy: 0.7971\n",
      "Epoch 6/20\n",
      "197362/197417 [============================>.] - ETA: 0s - loss: 0.4713 - accuracy: 0.7984\n",
      "Epoch 00006: val_loss improved from 0.47226 to 0.46826, saving model to NumberNetworkKFOLD7.h5\n",
      "197417/197417 [==============================] - 148s 752us/step - loss: 0.4713 - accuracy: 0.7984 - val_loss: 0.4683 - val_accuracy: 0.7996\n",
      "Epoch 7/20\n",
      "197386/197417 [============================>.] - ETA: 0s - loss: 0.4694 - accuracy: 0.7995\n",
      "Epoch 00007: val_loss improved from 0.46826 to 0.46630, saving model to NumberNetworkKFOLD7.h5\n",
      "197417/197417 [==============================] - 148s 751us/step - loss: 0.4694 - accuracy: 0.7995 - val_loss: 0.4663 - val_accuracy: 0.8013\n",
      "Epoch 8/20\n",
      "197368/197417 [============================>.] - ETA: 0s - loss: 0.4680 - accuracy: 0.8002\n",
      "Epoch 00008: val_loss did not improve from 0.46630\n",
      "197417/197417 [==============================] - 148s 750us/step - loss: 0.4680 - accuracy: 0.8002 - val_loss: 0.4732 - val_accuracy: 0.7986\n",
      "Epoch 9/20\n",
      "197362/197417 [============================>.] - ETA: 0s - loss: 0.4669 - accuracy: 0.8008\n",
      "Epoch 00009: val_loss improved from 0.46630 to 0.46503, saving model to NumberNetworkKFOLD7.h5\n",
      "197417/197417 [==============================] - 148s 751us/step - loss: 0.4669 - accuracy: 0.8008 - val_loss: 0.4650 - val_accuracy: 0.8017\n",
      "Epoch 10/20\n",
      "197363/197417 [============================>.] - ETA: 0s - loss: 0.4661 - accuracy: 0.8012\n",
      "Epoch 00010: val_loss improved from 0.46503 to 0.46361, saving model to NumberNetworkKFOLD7.h5\n",
      "197417/197417 [==============================] - 149s 754us/step - loss: 0.4661 - accuracy: 0.8012 - val_loss: 0.4636 - val_accuracy: 0.8030\n",
      "Epoch 11/20\n",
      "197362/197417 [============================>.] - ETA: 0s - loss: 0.4653 - accuracy: 0.8018\n",
      "Epoch 00011: val_loss improved from 0.46361 to 0.46178, saving model to NumberNetworkKFOLD7.h5\n",
      "197417/197417 [==============================] - 148s 752us/step - loss: 0.4653 - accuracy: 0.8018 - val_loss: 0.4618 - val_accuracy: 0.8035\n",
      "Epoch 12/20\n",
      "197346/197417 [============================>.] - ETA: 0s - loss: 0.4645 - accuracy: 0.8021\n",
      "Epoch 00012: val_loss did not improve from 0.46178\n",
      "197417/197417 [==============================] - 148s 751us/step - loss: 0.4645 - accuracy: 0.8021 - val_loss: 0.4641 - val_accuracy: 0.8024\n",
      "Epoch 13/20\n",
      "197375/197417 [============================>.] - ETA: 0s - loss: 0.4638 - accuracy: 0.8025\n",
      "Epoch 00013: val_loss did not improve from 0.46178\n",
      "197417/197417 [==============================] - 148s 752us/step - loss: 0.4638 - accuracy: 0.8025 - val_loss: 0.4621 - val_accuracy: 0.8031\n",
      "Epoch 14/20\n",
      "197349/197417 [============================>.] - ETA: 0s - loss: 0.4632 - accuracy: 0.8028\n",
      "Epoch 00014: val_loss did not improve from 0.46178\n",
      "197417/197417 [==============================] - 149s 753us/step - loss: 0.4632 - accuracy: 0.8028 - val_loss: 0.4686 - val_accuracy: 0.8019\n",
      "Epoch 15/20\n",
      "197356/197417 [============================>.] - ETA: 0s - loss: 0.4626 - accuracy: 0.8031\n",
      "Epoch 00015: val_loss did not improve from 0.46178\n",
      "197417/197417 [==============================] - 149s 755us/step - loss: 0.4626 - accuracy: 0.8031 - val_loss: 0.4640 - val_accuracy: 0.8015\n",
      "Epoch 16/20\n",
      "197385/197417 [============================>.] - ETA: 0s - loss: 0.4621 - accuracy: 0.8035\n",
      "Epoch 00016: val_loss improved from 0.46178 to 0.45994, saving model to NumberNetworkKFOLD7.h5\n",
      "197417/197417 [==============================] - 150s 759us/step - loss: 0.4621 - accuracy: 0.8035 - val_loss: 0.4599 - val_accuracy: 0.8048\n",
      "Epoch 17/20\n",
      "197372/197417 [============================>.] - ETA: 0s - loss: 0.4616 - accuracy: 0.8038\n",
      "Epoch 00017: val_loss did not improve from 0.45994\n",
      "197417/197417 [==============================] - 149s 753us/step - loss: 0.4616 - accuracy: 0.8038 - val_loss: 0.4613 - val_accuracy: 0.8040\n",
      "Epoch 18/20\n",
      "197403/197417 [============================>.] - ETA: 0s - loss: 0.4612 - accuracy: 0.8040\n",
      "Epoch 00018: val_loss did not improve from 0.45994\n",
      "197417/197417 [==============================] - 149s 753us/step - loss: 0.4612 - accuracy: 0.8040 - val_loss: 0.4638 - val_accuracy: 0.8035\n",
      "Epoch 19/20\n",
      "197399/197417 [============================>.] - ETA: 0s - loss: 0.4608 - accuracy: 0.8043\n",
      "Epoch 00019: val_loss improved from 0.45994 to 0.45989, saving model to NumberNetworkKFOLD7.h5\n",
      "197417/197417 [==============================] - 148s 752us/step - loss: 0.4608 - accuracy: 0.8043 - val_loss: 0.4599 - val_accuracy: 0.8051\n",
      "Epoch 20/20\n",
      "197405/197417 [============================>.] - ETA: 0s - loss: 0.4604 - accuracy: 0.8045\n",
      "Epoch 00020: val_loss improved from 0.45989 to 0.45953, saving model to NumberNetworkKFOLD7.h5\n",
      "197417/197417 [==============================] - 149s 753us/step - loss: 0.4604 - accuracy: 0.8045 - val_loss: 0.4595 - val_accuracy: 0.8049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-09 09:25:17,180 INFO] Testing on fold 7 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45699/45699 [==============================] - 24s 536us/step - loss: 0.4614 - accuracy: 0.8036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-09 09:25:42,135 INFO] Score for fold 7: loss of 0.4613904058933258; accuracy of 80.3605854511261%\n",
      "[2020-07-09 09:25:42,136 INFO] Calculating inference for fold 7 ...\n",
      "[2020-07-09 09:25:55,930 INFO] Writing fit history to output/NumberNetworkKFOLD.h5\n",
      "[2020-07-09 09:27:55,351 INFO] Building model for fold 8 from share/reference_number.py...\n",
      "[2020-07-09 09:28:03,394 INFO] Compiling for fold 8 ...\n",
      "[2020-07-09 09:28:03,407 INFO] Training for fold 8 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "197390/197417 [============================>.] - ETA: 0s - loss: 0.5425 - accuracy: 0.7588\n",
      "Epoch 00001: val_loss improved from inf to 0.49961, saving model to NumberNetworkKFOLD8.h5\n",
      "197417/197417 [==============================] - 148s 750us/step - loss: 0.5424 - accuracy: 0.7588 - val_loss: 0.4996 - val_accuracy: 0.7807\n",
      "Epoch 2/20\n",
      "197349/197417 [============================>.] - ETA: 0s - loss: 0.4912 - accuracy: 0.7874\n",
      "Epoch 00002: val_loss improved from 0.49961 to 0.49497, saving model to NumberNetworkKFOLD8.h5\n",
      "197417/197417 [==============================] - 147s 747us/step - loss: 0.4912 - accuracy: 0.7874 - val_loss: 0.4950 - val_accuracy: 0.7849\n",
      "Epoch 3/20\n",
      "197349/197417 [============================>.] - ETA: 0s - loss: 0.4822 - accuracy: 0.7925\n",
      "Epoch 00003: val_loss improved from 0.49497 to 0.47480, saving model to NumberNetworkKFOLD8.h5\n",
      "197417/197417 [==============================] - 148s 747us/step - loss: 0.4822 - accuracy: 0.7925 - val_loss: 0.4748 - val_accuracy: 0.7971\n",
      "Epoch 4/20\n",
      "197350/197417 [============================>.] - ETA: 0s - loss: 0.4777 - accuracy: 0.7949\n",
      "Epoch 00004: val_loss improved from 0.47480 to 0.47285, saving model to NumberNetworkKFOLD8.h5\n",
      "197417/197417 [==============================] - 148s 748us/step - loss: 0.4777 - accuracy: 0.7949 - val_loss: 0.4728 - val_accuracy: 0.7982\n",
      "Epoch 5/20\n",
      "197392/197417 [============================>.] - ETA: 0s - loss: 0.4742 - accuracy: 0.7967\n",
      "Epoch 00005: val_loss did not improve from 0.47285\n",
      "197417/197417 [==============================] - 147s 745us/step - loss: 0.4742 - accuracy: 0.7967 - val_loss: 0.4747 - val_accuracy: 0.7968\n",
      "Epoch 6/20\n",
      "197411/197417 [============================>.] - ETA: 0s - loss: 0.4719 - accuracy: 0.7978\n",
      "Epoch 00006: val_loss did not improve from 0.47285\n",
      "197417/197417 [==============================] - 148s 752us/step - loss: 0.4719 - accuracy: 0.7978 - val_loss: 0.4858 - val_accuracy: 0.7892\n",
      "Epoch 7/20\n",
      "197409/197417 [============================>.] - ETA: 0s - loss: 0.4702 - accuracy: 0.7988\n",
      "Epoch 00007: val_loss did not improve from 0.47285\n",
      "197417/197417 [==============================] - 147s 747us/step - loss: 0.4702 - accuracy: 0.7988 - val_loss: 0.4735 - val_accuracy: 0.7964\n",
      "Epoch 8/20\n",
      "197403/197417 [============================>.] - ETA: 0s - loss: 0.4688 - accuracy: 0.7996\n",
      "Epoch 00008: val_loss improved from 0.47285 to 0.46638, saving model to NumberNetworkKFOLD8.h5\n",
      "197417/197417 [==============================] - 148s 748us/step - loss: 0.4688 - accuracy: 0.7996 - val_loss: 0.4664 - val_accuracy: 0.8008\n",
      "Epoch 9/20\n",
      "197354/197417 [============================>.] - ETA: 0s - loss: 0.4678 - accuracy: 0.8002\n",
      "Epoch 00009: val_loss improved from 0.46638 to 0.46292, saving model to NumberNetworkKFOLD8.h5\n",
      "197417/197417 [==============================] - 147s 747us/step - loss: 0.4678 - accuracy: 0.8002 - val_loss: 0.4629 - val_accuracy: 0.8031\n",
      "Epoch 10/20\n",
      "197395/197417 [============================>.] - ETA: 0s - loss: 0.4669 - accuracy: 0.8006\n",
      "Epoch 00010: val_loss did not improve from 0.46292\n",
      "197417/197417 [==============================] - 148s 750us/step - loss: 0.4669 - accuracy: 0.8006 - val_loss: 0.4683 - val_accuracy: 0.8004\n",
      "Epoch 11/20\n",
      "197416/197417 [============================>.] - ETA: 0s - loss: 0.4660 - accuracy: 0.8011\n",
      "Epoch 00011: val_loss did not improve from 0.46292\n",
      "197417/197417 [==============================] - 147s 744us/step - loss: 0.4660 - accuracy: 0.8011 - val_loss: 0.4665 - val_accuracy: 0.7999\n",
      "Epoch 12/20\n",
      "197373/197417 [============================>.] - ETA: 0s - loss: 0.4654 - accuracy: 0.8016\n",
      "Epoch 00012: val_loss did not improve from 0.46292\n",
      "197417/197417 [==============================] - 148s 752us/step - loss: 0.4654 - accuracy: 0.8016 - val_loss: 0.4649 - val_accuracy: 0.8019\n",
      "Epoch 13/20\n",
      "197363/197417 [============================>.] - ETA: 0s - loss: 0.4648 - accuracy: 0.8020\n",
      "Epoch 00013: val_loss improved from 0.46292 to 0.46261, saving model to NumberNetworkKFOLD8.h5\n",
      "197417/197417 [==============================] - 147s 746us/step - loss: 0.4648 - accuracy: 0.8020 - val_loss: 0.4626 - val_accuracy: 0.8038\n",
      "Epoch 14/20\n",
      "197368/197417 [============================>.] - ETA: 0s - loss: 0.4641 - accuracy: 0.8025\n",
      "Epoch 00014: val_loss did not improve from 0.46261\n",
      "197417/197417 [==============================] - 147s 747us/step - loss: 0.4641 - accuracy: 0.8025 - val_loss: 0.4641 - val_accuracy: 0.8025\n",
      "Epoch 15/20\n",
      "197382/197417 [============================>.] - ETA: 0s - loss: 0.4636 - accuracy: 0.8029\n",
      "Epoch 00015: val_loss improved from 0.46261 to 0.46165, saving model to NumberNetworkKFOLD8.h5\n",
      "197417/197417 [==============================] - 147s 746us/step - loss: 0.4636 - accuracy: 0.8029 - val_loss: 0.4616 - val_accuracy: 0.8046\n",
      "Epoch 16/20\n",
      "197346/197417 [============================>.] - ETA: 0s - loss: 0.4631 - accuracy: 0.8032\n",
      "Epoch 00016: val_loss improved from 0.46165 to 0.46101, saving model to NumberNetworkKFOLD8.h5\n",
      "197417/197417 [==============================] - 148s 748us/step - loss: 0.4631 - accuracy: 0.8032 - val_loss: 0.4610 - val_accuracy: 0.8045\n",
      "Epoch 17/20\n",
      "197380/197417 [============================>.] - ETA: 0s - loss: 0.4627 - accuracy: 0.8033\n",
      "Epoch 00017: val_loss improved from 0.46101 to 0.45955, saving model to NumberNetworkKFOLD8.h5\n",
      "197417/197417 [==============================] - 148s 749us/step - loss: 0.4627 - accuracy: 0.8033 - val_loss: 0.4595 - val_accuracy: 0.8052\n",
      "Epoch 18/20\n",
      "197375/197417 [============================>.] - ETA: 0s - loss: 0.4624 - accuracy: 0.8035\n",
      "Epoch 00018: val_loss did not improve from 0.45955\n",
      "197417/197417 [==============================] - 148s 751us/step - loss: 0.4624 - accuracy: 0.8035 - val_loss: 0.4659 - val_accuracy: 0.8027\n",
      "Epoch 19/20\n",
      "197401/197417 [============================>.] - ETA: 0s - loss: 0.4621 - accuracy: 0.8038\n",
      "Epoch 00019: val_loss did not improve from 0.45955\n",
      "197417/197417 [==============================] - 148s 750us/step - loss: 0.4621 - accuracy: 0.8038 - val_loss: 0.4651 - val_accuracy: 0.8022\n",
      "Epoch 20/20\n",
      "197348/197417 [============================>.] - ETA: 0s - loss: 0.4617 - accuracy: 0.8039\n",
      "Epoch 00020: val_loss did not improve from 0.45955\n",
      "197417/197417 [==============================] - 148s 750us/step - loss: 0.4617 - accuracy: 0.8039 - val_loss: 0.4665 - val_accuracy: 0.8013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-09 10:17:29,463 INFO] Testing on fold 8 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45699/45699 [==============================] - 24s 524us/step - loss: 0.4662 - accuracy: 0.8011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-09 10:17:53,893 INFO] Score for fold 8: loss of 0.46615877747535706; accuracy of 80.10989427566528%\n",
      "[2020-07-09 10:17:53,894 INFO] Calculating inference for fold 8 ...\n",
      "[2020-07-09 10:18:09,019 INFO] Writing fit history to output/NumberNetworkKFOLD.h5\n",
      "[2020-07-09 10:18:13,043 INFO] Building model for fold 9 from share/reference_number.py...\n",
      "[2020-07-09 10:18:17,940 INFO] Compiling for fold 9 ...\n",
      "[2020-07-09 10:18:17,977 INFO] Training for fold 9 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "197414/197417 [============================>.] - ETA: 0s - loss: 0.5387 - accuracy: 0.7613\n",
      "Epoch 00001: val_loss improved from inf to 0.52633, saving model to NumberNetworkKFOLD9.h5\n",
      "197417/197417 [==============================] - 147s 744us/step - loss: 0.5387 - accuracy: 0.7613 - val_loss: 0.5263 - val_accuracy: 0.7680\n",
      "Epoch 2/20\n",
      "197363/197417 [============================>.] - ETA: 0s - loss: 0.4895 - accuracy: 0.7882\n",
      "Epoch 00002: val_loss improved from 0.52633 to 0.48499, saving model to NumberNetworkKFOLD9.h5\n",
      "197417/197417 [==============================] - 147s 743us/step - loss: 0.4895 - accuracy: 0.7882 - val_loss: 0.4850 - val_accuracy: 0.7920\n",
      "Epoch 3/20\n",
      "197393/197417 [============================>.] - ETA: 0s - loss: 0.4802 - accuracy: 0.7932\n",
      "Epoch 00003: val_loss improved from 0.48499 to 0.47953, saving model to NumberNetworkKFOLD9.h5\n",
      "197417/197417 [==============================] - 147s 745us/step - loss: 0.4802 - accuracy: 0.7932 - val_loss: 0.4795 - val_accuracy: 0.7930\n",
      "Epoch 4/20\n",
      "197412/197417 [============================>.] - ETA: 0s - loss: 0.4757 - accuracy: 0.7957\n",
      "Epoch 00004: val_loss improved from 0.47953 to 0.47746, saving model to NumberNetworkKFOLD9.h5\n",
      "197417/197417 [==============================] - 148s 751us/step - loss: 0.4757 - accuracy: 0.7957 - val_loss: 0.4775 - val_accuracy: 0.7958\n",
      "Epoch 5/20\n",
      "197371/197417 [============================>.] - ETA: 0s - loss: 0.4725 - accuracy: 0.7973\n",
      "Epoch 00005: val_loss improved from 0.47746 to 0.46667, saving model to NumberNetworkKFOLD9.h5\n",
      "197417/197417 [==============================] - 149s 754us/step - loss: 0.4725 - accuracy: 0.7973 - val_loss: 0.4667 - val_accuracy: 0.8010\n",
      "Epoch 6/20\n",
      "197353/197417 [============================>.] - ETA: 0s - loss: 0.4702 - accuracy: 0.7983\n",
      "Epoch 00006: val_loss did not improve from 0.46667\n",
      "197417/197417 [==============================] - 149s 753us/step - loss: 0.4702 - accuracy: 0.7983 - val_loss: 0.4687 - val_accuracy: 0.7992\n",
      "Epoch 7/20\n",
      "197351/197417 [============================>.] - ETA: 0s - loss: 0.4685 - accuracy: 0.7992\n",
      "Epoch 00007: val_loss did not improve from 0.46667\n",
      "197417/197417 [==============================] - 148s 749us/step - loss: 0.4685 - accuracy: 0.7992 - val_loss: 0.4705 - val_accuracy: 0.7990\n",
      "Epoch 8/20\n",
      "197384/197417 [============================>.] - ETA: 0s - loss: 0.4672 - accuracy: 0.8000\n",
      "Epoch 00008: val_loss improved from 0.46667 to 0.46488, saving model to NumberNetworkKFOLD9.h5\n",
      "197417/197417 [==============================] - 148s 751us/step - loss: 0.4672 - accuracy: 0.8000 - val_loss: 0.4649 - val_accuracy: 0.8011\n",
      "Epoch 9/20\n",
      "197366/197417 [============================>.] - ETA: 0s - loss: 0.4661 - accuracy: 0.8005\n",
      "Epoch 00009: val_loss did not improve from 0.46488\n",
      "197417/197417 [==============================] - 148s 747us/step - loss: 0.4661 - accuracy: 0.8005 - val_loss: 0.4659 - val_accuracy: 0.8005\n",
      "Epoch 10/20\n",
      "197367/197417 [============================>.] - ETA: 0s - loss: 0.4652 - accuracy: 0.8011\n",
      "Epoch 00010: val_loss improved from 0.46488 to 0.46312, saving model to NumberNetworkKFOLD9.h5\n",
      "197417/197417 [==============================] - 148s 750us/step - loss: 0.4652 - accuracy: 0.8011 - val_loss: 0.4631 - val_accuracy: 0.8030\n",
      "Epoch 11/20\n",
      "197354/197417 [============================>.] - ETA: 0s - loss: 0.4644 - accuracy: 0.8015\n",
      "Epoch 00011: val_loss improved from 0.46312 to 0.46040, saving model to NumberNetworkKFOLD9.h5\n",
      "197417/197417 [==============================] - 147s 743us/step - loss: 0.4644 - accuracy: 0.8015 - val_loss: 0.4604 - val_accuracy: 0.8037\n",
      "Epoch 12/20\n",
      "197382/197417 [============================>.] - ETA: 0s - loss: 0.4637 - accuracy: 0.8019\n",
      "Epoch 00012: val_loss did not improve from 0.46040\n",
      "197417/197417 [==============================] - 149s 757us/step - loss: 0.4637 - accuracy: 0.8019 - val_loss: 0.4630 - val_accuracy: 0.8021\n",
      "Epoch 13/20\n",
      "197401/197417 [============================>.] - ETA: 0s - loss: 0.4630 - accuracy: 0.8023\n",
      "Epoch 00013: val_loss improved from 0.46040 to 0.45988, saving model to NumberNetworkKFOLD9.h5\n",
      "197417/197417 [==============================] - 148s 752us/step - loss: 0.4630 - accuracy: 0.8023 - val_loss: 0.4599 - val_accuracy: 0.8040\n",
      "Epoch 14/20\n",
      "197385/197417 [============================>.] - ETA: 0s - loss: 0.4625 - accuracy: 0.8026\n",
      "Epoch 00014: val_loss improved from 0.45988 to 0.45838, saving model to NumberNetworkKFOLD9.h5\n",
      "197417/197417 [==============================] - 149s 755us/step - loss: 0.4625 - accuracy: 0.8026 - val_loss: 0.4584 - val_accuracy: 0.8050\n",
      "Epoch 15/20\n",
      "197348/197417 [============================>.] - ETA: 0s - loss: 0.4619 - accuracy: 0.8028\n",
      "Epoch 00015: val_loss did not improve from 0.45838\n",
      "197417/197417 [==============================] - 148s 752us/step - loss: 0.4619 - accuracy: 0.8028 - val_loss: 0.4619 - val_accuracy: 0.8035\n",
      "Epoch 16/20\n",
      "197395/197417 [============================>.] - ETA: 0s - loss: 0.4615 - accuracy: 0.8031\n",
      "Epoch 00016: val_loss did not improve from 0.45838\n",
      "197417/197417 [==============================] - 148s 749us/step - loss: 0.4615 - accuracy: 0.8031 - val_loss: 0.4711 - val_accuracy: 0.7974\n",
      "Epoch 17/20\n",
      "197351/197417 [============================>.] - ETA: 0s - loss: 0.4610 - accuracy: 0.8033\n",
      "Epoch 00017: val_loss did not improve from 0.45838\n",
      "197417/197417 [==============================] - 148s 751us/step - loss: 0.4610 - accuracy: 0.8033 - val_loss: 0.4585 - val_accuracy: 0.8047\n",
      "Epoch 18/20\n",
      "197369/197417 [============================>.] - ETA: 0s - loss: 0.4606 - accuracy: 0.8036\n",
      "Epoch 00018: val_loss improved from 0.45838 to 0.45758, saving model to NumberNetworkKFOLD9.h5\n",
      "197417/197417 [==============================] - 148s 748us/step - loss: 0.4606 - accuracy: 0.8036 - val_loss: 0.4576 - val_accuracy: 0.8053\n",
      "Epoch 19/20\n",
      "197403/197417 [============================>.] - ETA: 0s - loss: 0.4602 - accuracy: 0.8040\n",
      "Epoch 00019: val_loss did not improve from 0.45758\n",
      "197417/197417 [==============================] - 147s 744us/step - loss: 0.4602 - accuracy: 0.8040 - val_loss: 0.4620 - val_accuracy: 0.8028\n",
      "Epoch 20/20\n",
      "197369/197417 [============================>.] - ETA: 0s - loss: 0.4598 - accuracy: 0.8044\n",
      "Epoch 00020: val_loss did not improve from 0.45758\n",
      "197417/197417 [==============================] - 147s 745us/step - loss: 0.4598 - accuracy: 0.8044 - val_loss: 0.4602 - val_accuracy: 0.8043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-09 11:07:39,946 INFO] Testing on fold 9 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45699/45699 [==============================] - 24s 519us/step - loss: 0.4599 - accuracy: 0.8041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-09 11:08:03,974 INFO] Score for fold 9: loss of 0.4598506689071655; accuracy of 80.40633201599121%\n",
      "[2020-07-09 11:08:03,974 INFO] Calculating inference for fold 9 ...\n",
      "[2020-07-09 11:08:17,407 INFO] Writing fit history to output/NumberNetworkKFOLD.h5\n",
      "[2020-07-09 11:08:17,667 INFO] Building model for fold 10 from share/reference_number.py...\n",
      "[2020-07-09 11:08:21,430 INFO] Compiling for fold 10 ...\n",
      "[2020-07-09 11:08:21,437 INFO] Training for fold 10 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "197384/197417 [============================>.] - ETA: 0s - loss: 0.5416 - accuracy: 0.7597\n",
      "Epoch 00001: val_loss improved from inf to 0.60296, saving model to NumberNetworkKFOLD10.h5\n",
      "197417/197417 [==============================] - 150s 761us/step - loss: 0.5416 - accuracy: 0.7597 - val_loss: 0.6030 - val_accuracy: 0.7327\n",
      "Epoch 2/20\n",
      "197397/197417 [============================>.] - ETA: 0s - loss: 0.4897 - accuracy: 0.7878\n",
      "Epoch 00002: val_loss improved from 0.60296 to 0.48807, saving model to NumberNetworkKFOLD10.h5\n",
      "197417/197417 [==============================] - 150s 760us/step - loss: 0.4897 - accuracy: 0.7878 - val_loss: 0.4881 - val_accuracy: 0.7884\n",
      "Epoch 3/20\n",
      "197414/197417 [============================>.] - ETA: 0s - loss: 0.4807 - accuracy: 0.7930\n",
      "Epoch 00003: val_loss improved from 0.48807 to 0.47099, saving model to NumberNetworkKFOLD10.h5\n",
      "197417/197417 [==============================] - 147s 746us/step - loss: 0.4807 - accuracy: 0.7930 - val_loss: 0.4710 - val_accuracy: 0.7983\n",
      "Epoch 4/20\n",
      "197374/197417 [============================>.] - ETA: 0s - loss: 0.4766 - accuracy: 0.7956\n",
      "Epoch 00004: val_loss did not improve from 0.47099\n",
      "197417/197417 [==============================] - 148s 750us/step - loss: 0.4766 - accuracy: 0.7956 - val_loss: 0.4922 - val_accuracy: 0.7859\n",
      "Epoch 5/20\n",
      "197396/197417 [============================>.] - ETA: 0s - loss: 0.4732 - accuracy: 0.7974\n",
      "Epoch 00005: val_loss improved from 0.47099 to 0.46666, saving model to NumberNetworkKFOLD10.h5\n",
      "197417/197417 [==============================] - 148s 748us/step - loss: 0.4732 - accuracy: 0.7974 - val_loss: 0.4667 - val_accuracy: 0.8015\n",
      "Epoch 6/20\n",
      "197372/197417 [============================>.] - ETA: 0s - loss: 0.4705 - accuracy: 0.7990\n",
      "Epoch 00006: val_loss did not improve from 0.46666\n",
      "197417/197417 [==============================] - 148s 750us/step - loss: 0.4705 - accuracy: 0.7990 - val_loss: 0.4687 - val_accuracy: 0.7991\n",
      "Epoch 7/20\n",
      "197353/197417 [============================>.] - ETA: 0s - loss: 0.4687 - accuracy: 0.7998\n",
      "Epoch 00007: val_loss did not improve from 0.46666\n",
      "197417/197417 [==============================] - 148s 749us/step - loss: 0.4687 - accuracy: 0.7998 - val_loss: 0.4721 - val_accuracy: 0.7970\n",
      "Epoch 8/20\n",
      "197390/197417 [============================>.] - ETA: 0s - loss: 0.4673 - accuracy: 0.8005\n",
      "Epoch 00008: val_loss did not improve from 0.46666\n",
      "197417/197417 [==============================] - 147s 747us/step - loss: 0.4673 - accuracy: 0.8005 - val_loss: 0.4769 - val_accuracy: 0.7947\n",
      "Epoch 9/20\n",
      "197354/197417 [============================>.] - ETA: 0s - loss: 0.4662 - accuracy: 0.8010\n",
      "Epoch 00009: val_loss did not improve from 0.46666\n",
      "197417/197417 [==============================] - 147s 745us/step - loss: 0.4662 - accuracy: 0.8010 - val_loss: 0.4674 - val_accuracy: 0.8009\n",
      "Epoch 10/20\n",
      "197383/197417 [============================>.] - ETA: 0s - loss: 0.4652 - accuracy: 0.8015\n",
      "Epoch 00010: val_loss improved from 0.46666 to 0.46461, saving model to NumberNetworkKFOLD10.h5\n",
      "197417/197417 [==============================] - 147s 744us/step - loss: 0.4652 - accuracy: 0.8015 - val_loss: 0.4646 - val_accuracy: 0.8016\n",
      "Epoch 11/20\n",
      "197400/197417 [============================>.] - ETA: 0s - loss: 0.4644 - accuracy: 0.8019\n",
      "Epoch 00011: val_loss improved from 0.46461 to 0.46164, saving model to NumberNetworkKFOLD10.h5\n",
      "197417/197417 [==============================] - 149s 752us/step - loss: 0.4644 - accuracy: 0.8019 - val_loss: 0.4616 - val_accuracy: 0.8028\n",
      "Epoch 12/20\n",
      "197393/197417 [============================>.] - ETA: 0s - loss: 0.4637 - accuracy: 0.8023\n",
      "Epoch 00012: val_loss improved from 0.46164 to 0.45927, saving model to NumberNetworkKFOLD10.h5\n",
      "197417/197417 [==============================] - 150s 760us/step - loss: 0.4637 - accuracy: 0.8023 - val_loss: 0.4593 - val_accuracy: 0.8048\n",
      "Epoch 13/20\n",
      "197389/197417 [============================>.] - ETA: 0s - loss: 0.4630 - accuracy: 0.8026\n",
      "Epoch 00013: val_loss did not improve from 0.45927\n",
      "197417/197417 [==============================] - 154s 782us/step - loss: 0.4630 - accuracy: 0.8026 - val_loss: 0.4617 - val_accuracy: 0.8035\n",
      "Epoch 14/20\n",
      "197379/197417 [============================>.] - ETA: 0s - loss: 0.4625 - accuracy: 0.8028\n",
      "Epoch 00014: val_loss improved from 0.45927 to 0.45894, saving model to NumberNetworkKFOLD10.h5\n",
      "197417/197417 [==============================] - 155s 787us/step - loss: 0.4625 - accuracy: 0.8028 - val_loss: 0.4589 - val_accuracy: 0.8045\n",
      "Epoch 15/20\n",
      "197365/197417 [============================>.] - ETA: 0s - loss: 0.4620 - accuracy: 0.8030\n",
      "Epoch 00015: val_loss improved from 0.45894 to 0.45874, saving model to NumberNetworkKFOLD10.h5\n",
      "197417/197417 [==============================] - 157s 794us/step - loss: 0.4620 - accuracy: 0.8030 - val_loss: 0.4587 - val_accuracy: 0.8048\n",
      "Epoch 16/20\n",
      "197398/197417 [============================>.] - ETA: 0s - loss: 0.4616 - accuracy: 0.8032\n",
      "Epoch 00016: val_loss did not improve from 0.45874\n",
      "197417/197417 [==============================] - 153s 777us/step - loss: 0.4616 - accuracy: 0.8032 - val_loss: 0.4591 - val_accuracy: 0.8044\n",
      "Epoch 17/20\n",
      "197397/197417 [============================>.] - ETA: 0s - loss: 0.4612 - accuracy: 0.8033\n",
      "Epoch 00017: val_loss did not improve from 0.45874\n",
      "197417/197417 [==============================] - 153s 776us/step - loss: 0.4612 - accuracy: 0.8033 - val_loss: 0.4641 - val_accuracy: 0.8011\n",
      "Epoch 18/20\n",
      "197415/197417 [============================>.] - ETA: 0s - loss: 0.4608 - accuracy: 0.8035\n",
      "Epoch 00018: val_loss did not improve from 0.45874\n",
      "197417/197417 [==============================] - 157s 793us/step - loss: 0.4608 - accuracy: 0.8035 - val_loss: 0.4592 - val_accuracy: 0.8043\n",
      "Epoch 19/20\n",
      "197394/197417 [============================>.] - ETA: 0s - loss: 0.4605 - accuracy: 0.8037\n",
      "Epoch 00019: val_loss did not improve from 0.45874\n",
      "197417/197417 [==============================] - 169s 856us/step - loss: 0.4605 - accuracy: 0.8037 - val_loss: 0.4608 - val_accuracy: 0.8034\n",
      "Epoch 20/20\n",
      "197411/197417 [============================>.] - ETA: 0s - loss: 0.4602 - accuracy: 0.8039\n",
      "Epoch 00020: val_loss did not improve from 0.45874\n",
      "197417/197417 [==============================] - 166s 842us/step - loss: 0.4602 - accuracy: 0.8039 - val_loss: 0.4595 - val_accuracy: 0.8041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-09 11:59:13,593 INFO] Testing on fold 10 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45699/45699 [==============================] - 26s 564us/step - loss: 0.4595 - accuracy: 0.8043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-09 11:59:39,840 INFO] Score for fold 10: loss of 0.45954078435897827; accuracy of 80.42944669723511%\n",
      "[2020-07-09 11:59:39,841 INFO] Calculating inference for fold 10 ...\n",
      "[2020-07-09 11:59:54,542 INFO] Writing fit history to output/NumberNetworkKFOLD.h5\n",
      "[2020-07-09 11:59:54,631 INFO] Done training!\n"
     ]
    }
   ],
   "source": [
    "fold_no = 0\n",
    "with h5.File(f'output/{args.name}.h5', 'w'):\n",
    "    logging.info(f'output/{args.name}.h5 created/emptied')\n",
    "\n",
    "for train, test in splits:\n",
    "    fold_no += 1\n",
    "    logging.info(f'Building model for fold {fold_no} from {path}...')\n",
    "    model, compile_args, fit_args, params = _build_model(path, data_x, data_y)\n",
    "    compile_args['metrics']=['accuracy']\n",
    "    fit_args['batch_size']=args.batch_size\n",
    "    fit_args['validation_split'] = 0.1\n",
    "    fit_args['epochs'] = args.epochs\n",
    "    fit_args['callbacks'] = [keras.callbacks.TerminateOnNaN(),\n",
    "                             keras.callbacks.ModelCheckpoint(args.name + str(fold_no) + '.h5', save_best_only=True,verbose=1)]\n",
    "                             #keras.callbacks.CSVLogger('output/'+args.name+str(fold_no)+'.csv')]\n",
    "    logging.info(f'Compiling for fold {fold_no} ...')\n",
    "    model.compile(**compile_args)\n",
    "\n",
    "    logging.info(f'Training for fold {fold_no} ...')\n",
    "    history = model.fit(data_x[train], data_y[train], **fit_args)\n",
    "    \n",
    "    logging.info(f'Testing on fold {fold_no} ...')\n",
    "    scores = model.evaluate(data_x[test], data_y[test])\n",
    "    \n",
    "    logging.info(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1] * 100}%')\n",
    "    acc_per_fold.append(scores[1]*100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "    \n",
    "    logging.info(f'Calculating inference for fold {fold_no} ...')\n",
    "    y_pred = model.predict(data_x[test])\n",
    "    #preds.append(y_pred)\n",
    "    #reals.append(data_y[test])\n",
    "    \n",
    "    for i, label in enumerate(labels):\n",
    "        fpr[f'{label}_{fold_no}'], tpr[f'{label}_{fold_no}'], threshold = roc_curve(data_y[test][:,i], y_pred[:,i])\n",
    "        auc1[f'{label}_{fold_no}'] = auc(fpr[f'{label}_{fold_no}'], tpr[f'{label}_{fold_no}'])\n",
    "        \n",
    "    logging.info(f'Writing fit history to output/{args.name}.h5')\n",
    "    with h5.File(f'output/{args.name}.h5', 'a') as hfile:\n",
    "        for key, val in history.history.items():\n",
    "            hfile.create_dataset(key+'_'+str(fold_no), data=np.array(val))\n",
    "        for label in labels:\n",
    "            hfile.create_dataset(f'{label}_{fold_no}_fpr', data=fpr[f'{label}_{fold_no}'])\n",
    "            hfile.create_dataset(f'{label}_{fold_no}_tpr', data=tpr[f'{label}_{fold_no}'])\n",
    "            hfile.create_dataset(f'{label}_{fold_no}_auc', data=auc1[f'{label}_{fold_no}'])\n",
    "    models.append(model)\n",
    "\n",
    "logging.info('Done training!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['1particle_10_auc', '1particle_10_fpr', '1particle_10_tpr', '1particle_1_auc', '1particle_1_fpr', '1particle_1_tpr', '1particle_2_auc', '1particle_2_fpr', '1particle_2_tpr', '1particle_3_auc', '1particle_3_fpr', '1particle_3_tpr', '1particle_4_auc', '1particle_4_fpr', '1particle_4_tpr', '1particle_5_auc', '1particle_5_fpr', '1particle_5_tpr', '1particle_6_auc', '1particle_6_fpr', '1particle_6_tpr', '1particle_7_auc', '1particle_7_fpr', '1particle_7_tpr', '1particle_8_auc', '1particle_8_fpr', '1particle_8_tpr', '1particle_9_auc', '1particle_9_fpr', '1particle_9_tpr', '2particle_10_auc', '2particle_10_fpr', '2particle_10_tpr', '2particle_1_auc', '2particle_1_fpr', '2particle_1_tpr', '2particle_2_auc', '2particle_2_fpr', '2particle_2_tpr', '2particle_3_auc', '2particle_3_fpr', '2particle_3_tpr', '2particle_4_auc', '2particle_4_fpr', '2particle_4_tpr', '2particle_5_auc', '2particle_5_fpr', '2particle_5_tpr', '2particle_6_auc', '2particle_6_fpr', '2particle_6_tpr', '2particle_7_auc', '2particle_7_fpr', '2particle_7_tpr', '2particle_8_auc', '2particle_8_fpr', '2particle_8_tpr', '2particle_9_auc', '2particle_9_fpr', '2particle_9_tpr', '3particle_10_auc', '3particle_10_fpr', '3particle_10_tpr', '3particle_1_auc', '3particle_1_fpr', '3particle_1_tpr', '3particle_2_auc', '3particle_2_fpr', '3particle_2_tpr', '3particle_3_auc', '3particle_3_fpr', '3particle_3_tpr', '3particle_4_auc', '3particle_4_fpr', '3particle_4_tpr', '3particle_5_auc', '3particle_5_fpr', '3particle_5_tpr', '3particle_6_auc', '3particle_6_fpr', '3particle_6_tpr', '3particle_7_auc', '3particle_7_fpr', '3particle_7_tpr', '3particle_8_auc', '3particle_8_fpr', '3particle_8_tpr', '3particle_9_auc', '3particle_9_fpr', '3particle_9_tpr', 'accuracy_1', 'accuracy_10', 'accuracy_2', 'accuracy_3', 'accuracy_4', 'accuracy_5', 'accuracy_6', 'accuracy_7', 'accuracy_8', 'accuracy_9', 'loss_1', 'loss_10', 'loss_2', 'loss_3', 'loss_4', 'loss_5', 'loss_6', 'loss_7', 'loss_8', 'loss_9', 'val_accuracy_1', 'val_accuracy_10', 'val_accuracy_2', 'val_accuracy_3', 'val_accuracy_4', 'val_accuracy_5', 'val_accuracy_6', 'val_accuracy_7', 'val_accuracy_8', 'val_accuracy_9', 'val_loss_1', 'val_loss_10', 'val_loss_2', 'val_loss_3', 'val_loss_4', 'val_loss_5', 'val_loss_6', 'val_loss_7', 'val_loss_8', 'val_loss_9']>\n"
     ]
    }
   ],
   "source": [
    "with h5.File('output/NumberNetworkKFOLD.h5', 'r') as f:\n",
    "    print(f.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-09 12:10:01,216 INFO] Loading data from data/test.h5\n"
     ]
    }
   ],
   "source": [
    "logging.info(f'Loading data from data/test.h5')\n",
    "\n",
    "with h5.File('data/test.h5', 'r') as data:\n",
    "    data_x = data['input'][()]\n",
    "    data_y = data['target'][()]\n",
    "\n",
    "labels = ['1particle', '2particle', '3particle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LG complete\n",
      "0 fold complete\n",
      "1 fold complete\n",
      "2 fold complete\n",
      "3 fold complete\n",
      "4 fold complete\n",
      "5 fold complete\n",
      "6 fold complete\n",
      "7 fold complete\n",
      "8 fold complete\n",
      "9 fold complete\n"
     ]
    }
   ],
   "source": [
    "folds = 10\n",
    "fpr_LG = [0]*len(labels)\n",
    "tpr_LG = [0]*len(labels)\n",
    "auc_LG = [0]*len(labels)\n",
    "\n",
    "fpr_list = [[0]*(folds) for i in range(len(labels))]\n",
    "tpr_list = [[0]*(folds) for i in range(len(labels))]\n",
    "auc_list = [[0]*(folds) for i in range(len(labels))]\n",
    "\n",
    "model, compile_args, fit_args, params = _build_model(path, data_x, data_y)\n",
    "compile_args['metrics']=['accuracy']\n",
    "model.compile(**compile_args)\n",
    "model.load_weights('modelWeights/LGNumberNetworkModel.h5')\n",
    "\n",
    "#scores = model.evaluate(data_x[:5000], data_y[:5000])\n",
    "y_pred = model.predict(data_x)\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    fpr_LG[i], tpr_LG[i], threshold = roc_curve(data_y[:][:,i], y_pred[:,i])\n",
    "    auc_LG[i] = auc(fpr_LG[i], tpr_LG[i])\n",
    "\n",
    "print(f'LG complete')\n",
    "\n",
    "for i in range(folds):\n",
    "    \n",
    "    model, compile_args, fit_args, params = _build_model(path, data_x, data_y)\n",
    "    compile_args['metrics']=['accuracy']\n",
    "    model.compile(**compile_args)\n",
    "    model.load_weights(f'modelWeights/NumberNetworkKFOLD{i+1}.h5')\n",
    "    y_pred = model.predict(data_x)\n",
    "\n",
    "    for j, label in enumerate(labels):\n",
    "        fpr_list[j][i], tpr_list[j][i], threshold = roc_curve(data_y[:][:,j], y_pred[:,j])\n",
    "        auc_list[j][i] = auc(fpr_list[j][i], tpr_list[j][i])\n",
    "        \n",
    "    print(f'{i} fold complete')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def kfoldRoc(infile, labels, name=\"\", outdir=\"\", fprl=None, tprl=None, aucl=None):\n",
    "\n",
    "    folds = 10\n",
    "    npoints = 200\n",
    "    base_fpr = np.exp(np.linspace(math.log(0.0005), 0., npoints))\n",
    "    colors = [\"r\", \"g\", \"b\"]\n",
    "    avg_tpr = {}\n",
    "    plus_tpr = {}\n",
    "    minus_tpr = {}\n",
    "\n",
    "    if (fprl==None):\n",
    "        fprl = [[0]*(folds) for i in range(len(labels))]\n",
    "        tprl = [[0]*(folds) for i in range(len(labels))]\n",
    "        aucl = [[0]*(folds) for i in range(len(labels))]\n",
    "        with h5.File(infile, 'r') as hfile:\n",
    "            for i, label in enumerate(labels):\n",
    "                for j in range(folds):\n",
    "                    fprl[i][j] = hfile[f'{label}_{j+1}_fpr'][()]\n",
    "                    tprl[i][j] = hfile[f'{label}_{j+1}_tpr'][()]\n",
    "                    aucl[i][j] = hfile[f'{label}_{j+1}_auc'][()]\n",
    "    fpr_list = np.array(fprl)\n",
    "    tpr_list = np.array(tprl)\n",
    "    auc_list = np.array(aucl)\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    for i, particle in enumerate(labels):\n",
    "        tpr_array = np.array([])\n",
    "        for j in range(folds):\n",
    "            tpr_interpolated = np.interp(base_fpr, fpr_list[i][j], tpr_list[i][j])\n",
    "            tpr_interpolated = tpr_interpolated.reshape((1,npoints))\n",
    "            tpr_array = np.concatenate([tpr_array, tpr_interpolated], axis=0) if tpr_array.size else tpr_interpolated\n",
    "        mean_tpr = np.mean(tpr_array, axis=0)\n",
    "        rms_tpr = np.std(tpr_array, axis=0)\n",
    "        plus_tpr[particle] = np.minimum(mean_tpr+rms_tpr, np.ones(npoints))\n",
    "        minus_tpr[particle] = np.maximum(mean_tpr-rms_tpr,np.zeros(npoints))\n",
    "        avg_tpr[particle] = mean_tpr\n",
    "\n",
    "        plt.plot(base_fpr, avg_tpr[particle], color=colors[i], linestyle='--',\n",
    "                 label=f'{i+1} particle (AUC = {np.mean(auc_list[i][()]):.2f} (+- {np.std(auc_list[i][()]):.4f}))')\n",
    "        plt.fill_between(base_fpr, minus_tpr[particle], plus_tpr[particle], color=colors[i], alpha=0.25)\n",
    "\n",
    "        plt.plot(fpr_LG[i], tpr_LG[i], color=colors[i], label=f'{i+1} particle LG (AUC = {auc_LG[i]:.2f})')\n",
    "\n",
    "    #plt.plot([0, 1], [0, 1], lw=1, color='navy', linestyle='--')\n",
    "    #plt.semilogx()\n",
    "    plt.ylabel(\"TPR\")\n",
    "    plt.xlabel(\"FPR\")\n",
    "    plt.xlim([0, 1.05])\n",
    "    plt.ylim(0,1.05)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1))\n",
    "    plt.grid(True)\n",
    "    plt.figtext(0.25, 0.90,f'{name}',fontweight='bold', wrap=True, horizontalalignment='right', fontsize=10)\n",
    "    #plt.figtext(0.35, 0.90,'preliminary', style='italic', wrap=True, horizontalalignment='center', fontsize=14) \n",
    "    plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "    plt.savefig(f'{outdir}{name}_ROC.pdf')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-09 12:22:26,518 DEBUG] Assigning font /b'F1' = 'C:\\\\Users\\\\alexc\\\\Anaconda3\\\\envs\\\\EPE_ML_TF2\\\\lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSans.ttf'\n",
      "[2020-07-09 12:22:26,636 DEBUG] Assigning font /b'F2' = 'C:\\\\Users\\\\alexc\\\\Anaconda3\\\\envs\\\\EPE_ML_TF2\\\\lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSans-Bold.ttf'\n",
      "[2020-07-09 12:22:26,638 DEBUG] Embedding font C:\\Users\\alexc\\Anaconda3\\envs\\EPE_ML_TF2\\lib\\site-packages\\matplotlib\\mpl-data\\fonts\\ttf\\DejaVuSans-Bold.ttf.\n",
      "[2020-07-09 12:22:26,638 DEBUG] Writing TrueType font.\n",
      "[2020-07-09 12:22:26,649 DEBUG] Embedding font C:\\Users\\alexc\\Anaconda3\\envs\\EPE_ML_TF2\\lib\\site-packages\\matplotlib\\mpl-data\\fonts\\ttf\\DejaVuSans.ttf.\n",
      "[2020-07-09 12:22:26,650 DEBUG] Writing TrueType font.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "kfoldRoc(f'output/{args.name}.h5', labels, \"kfold\", \"output/\", fpr_list, tpr_list, auc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learningCurves(infile, outdir=\"\"):\n",
    "\n",
    "    folds = 10\n",
    "    losses = [[0]*(folds) for i in range(2)]\n",
    "\n",
    "    with h5.File(infile, 'r') as hfile:\n",
    "        for i in range(folds):\n",
    "            losses[0][i] = hfile[f'loss_{i+1}'][()]\n",
    "            losses[1][i] = hfile[f'val_loss_{i+1}'][()]\n",
    "\n",
    "    for i in range(len(losses)):\n",
    "        for j in range(folds):\n",
    "            plt.plot(losses[i][j], label= ('val_' if i else '') + f'loss for {j} fold')\n",
    "\n",
    "    #plt.plot([0, 1], [0, 1], lw=1, color='navy', linestyle='--')\n",
    "    #plt.semilogx()\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.xlim([-0.05, 20])\n",
    "    plt.ylim(0.2,.60)\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.figtext(0.25, 0.90,'loss',fontweight='bold', wrap=True, horizontalalignment='right', fontsize=10)\n",
    "    #plt.figtext(0.35, 0.90,'preliminary', style='italic', wrap=True, horizontalalignment='center', fontsize=14) \n",
    "    plt.savefig(f'{outdir}loss.pdf')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-09 12:30:30,165 DEBUG] Assigning font /b'F1' = 'C:\\\\Users\\\\alexc\\\\Anaconda3\\\\envs\\\\EPE_ML_TF2\\\\lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSans.ttf'\n",
      "[2020-07-09 12:30:30,236 DEBUG] Assigning font /b'F2' = 'C:\\\\Users\\\\alexc\\\\Anaconda3\\\\envs\\\\EPE_ML_TF2\\\\lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSans-Bold.ttf'\n",
      "[2020-07-09 12:30:30,237 DEBUG] Embedding font C:\\Users\\alexc\\Anaconda3\\envs\\EPE_ML_TF2\\lib\\site-packages\\matplotlib\\mpl-data\\fonts\\ttf\\DejaVuSans-Bold.ttf.\n",
      "[2020-07-09 12:30:30,238 DEBUG] Writing TrueType font.\n",
      "[2020-07-09 12:30:30,248 DEBUG] Embedding font C:\\Users\\alexc\\Anaconda3\\envs\\EPE_ML_TF2\\lib\\site-packages\\matplotlib\\mpl-data\\fonts\\ttf\\DejaVuSans.ttf.\n",
      "[2020-07-09 12:30:30,248 DEBUG] Writing TrueType font.\n"
     ]
    }
   ],
   "source": [
    "learningCurves(f'output/{args.name}.h5', \"output/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Average scores---\n",
      "Score per fold\n",
      "Fold 1 - Loss: 0.0009 - Accuracy: 100.00%\n",
      "Fold 2 - Loss: 0.0009 - Accuracy: 100.00%\n",
      "Fold 3 - Loss: 0.0009 - Accuracy: 100.00%\n",
      "Fold 4 - Loss: 0.0009 - Accuracy: 100.00%\n",
      "Fold 5 - Loss: 0.0009 - Accuracy: 100.00%\n",
      "Fold 6 - Loss: 0.0008 - Accuracy: 100.00%\n",
      "Fold 7 - Loss: 0.0008 - Accuracy: 100.00%\n",
      "Fold 8 - Loss: 0.0008 - Accuracy: 100.00%\n",
      "Fold 9 - Loss: 0.0009 - Accuracy: 100.00%\n",
      "Fold 10 - Loss: 0.0009 - Accuracy: 100.00%\n",
      "--------------------\n",
      "Average scores for all folds:\n",
      "Accuracy: 100.00 (+- 0.0000)\n",
      "Loss: 0.0009 (+- 0.0000)\n",
      "---Average AUC------\n",
      "Fold 1 - 1particle - AUC: nan\n",
      "Fold 2 - 1particle - AUC: nan\n",
      "Fold 3 - 1particle - AUC: nan\n",
      "Fold 4 - 1particle - AUC: nan\n",
      "Fold 5 - 1particle - AUC: nan\n",
      "Fold 6 - 1particle - AUC: nan\n",
      "Fold 7 - 1particle - AUC: nan\n",
      "Fold 8 - 1particle - AUC: nan\n",
      "Fold 1 - 2particle - AUC: nan\n",
      "Fold 2 - 2particle - AUC: nan\n",
      "Fold 3 - 2particle - AUC: nan\n",
      "Fold 4 - 2particle - AUC: nan\n",
      "Fold 5 - 2particle - AUC: nan\n",
      "Fold 6 - 2particle - AUC: nan\n",
      "Fold 7 - 2particle - AUC: nan\n",
      "Fold 8 - 2particle - AUC: nan\n",
      "Fold 1 - 3particle - AUC: nan\n",
      "Fold 2 - 3particle - AUC: nan\n",
      "Fold 3 - 3particle - AUC: nan\n",
      "Fold 4 - 3particle - AUC: nan\n",
      "Fold 5 - 3particle - AUC: nan\n",
      "Fold 6 - 3particle - AUC: nan\n",
      "Fold 7 - 3particle - AUC: nan\n",
      "Fold 8 - 3particle - AUC: nan\n",
      "--------------------\n",
      "Average AUC for all folds:\n",
      "1particle - AUC: nan (+- nan)\n",
      "2particle - AUC: nan (+- nan)\n",
      "3particle - AUC: nan (+- nan)\n"
     ]
    }
   ],
   "source": [
    "print('---Average scores---')\n",
    "print('Score per fold')\n",
    "for i in range(0,len(acc_per_fold)):\n",
    "    print(f'Fold {i+1} - Loss: {loss_per_fold[i]:.4f} - Accuracy: {acc_per_fold[i]:.2f}%')\n",
    "print('--------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'Accuracy: {np.mean(acc_per_fold):.2f} (+- {np.std(acc_per_fold):.4f})')\n",
    "print(f'Loss: {np.mean(loss_per_fold):.4f} (+- {np.std(loss_per_fold):.4f})')\n",
    "print('---Average AUC------')\n",
    "for label in labels:\n",
    "    for i in range(fold_no-1):\n",
    "        print(f'Fold {i+1} - {label} - AUC: {auc1[label][i]*100:.2f}')\n",
    "        \n",
    "print('--------------------')\n",
    "print('Average AUC for all folds:')\n",
    "for label in labels:\n",
    "    print(f'{label} - AUC: {np.mean(auc1[label]):.2f} (+- {np.std(auc1[label]):.4f})')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('EPE_ML_TF2': conda)",
   "language": "python",
   "name": "python361064bitepemltf2conda8b97cfd37faf40f9a7f0d8196617388c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
