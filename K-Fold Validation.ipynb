{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "sys.path.append('scripts')\n",
    "sys.path.append('share')\n",
    "sys.path.append('python')\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py as h5\n",
    "import matplotlib.pyplot as plt\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "import tensorflow\n",
    "import tensorflow.keras as keras\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from run_training import _build_model, _find_py_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name '_find_py_file' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8bec63568d91>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m )\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_find_py_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name '_find_py_file' is not defined"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=1, format='[%(asctime)s %(levelname)s] %(message)s')\n",
    "Option = namedtuple(\"MyStruct\", \"input model name folds batch_size epochs\")\n",
    "                    #structure learning_rate regularizer epochs\")\n",
    "args = Option(\n",
    "    input='test1.h5',\n",
    "    model='share/reference_number.py',\n",
    "    name='NumberNetworkKFOLD',\n",
    "    folds=10,\n",
    "    batch_size=60,\n",
    "    epochs=20,\n",
    "    #learning_rate=0.0001,\n",
    "    #regularizer=0.0001,\n",
    ")\n",
    "\n",
    "path = _find_py_file(args.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold Validation\n",
    "## Load and Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[2020-07-08 01:48:01,675 INFO] Loading data from test1.h5\n"
    }
   ],
   "source": [
    "logging.info(f'Loading data from {args.input}')\n",
    "\n",
    "with h5.File(args.input, 'r') as data:\n",
    "    data_x = data['input'][()]\n",
    "    data_y = data['target'][()]\n",
    "\n",
    "labels = ['1particle', '2particle', '3particle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[2020-07-08 01:48:11,313 INFO] Building model from share/reference_number.py\n"
    }
   ],
   "source": [
    "logging.info('Building model from %s', path)\n",
    "model, compile_args, fit_args, params = _build_model(path, data_x, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model_1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_2 (InputLayer)            [(None, 60)]         0                                            \n__________________________________________________________________________________________________\noffset_and_scale_1 (OffsetAndSc (None, 60)           0           input_2[0][0]                    \n__________________________________________________________________________________________________\ndense_3 (Dense)                 (None, 25)           1525        offset_and_scale_1[0][0]         \n__________________________________________________________________________________________________\nactivation (Activation)         multiple             0           dense_3[0][0]                    \n                                                                 dense_4[0][0]                    \n                                                                 dense_5[0][0]                    \n__________________________________________________________________________________________________\ndense_4 (Dense)                 (None, 20)           520         activation[3][0]                 \n__________________________________________________________________________________________________\ndense_5 (Dense)                 (None, 3)            63          activation[4][0]                 \n==================================================================================================\nTotal params: 2,108\nTrainable params: 2,108\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "image/png": "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\n",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR ITERATIVE TESTING QUICKER\n",
    "data_x = data_x[:5000]\n",
    "data_y = data_y[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "#histories = []\n",
    "#preds = []\n",
    "#reals = []\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "auc1 = {}\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "#K-Fold Split Indices\n",
    "kfold = KFold(n_splits=args.folds)\n",
    "splits = kfold.split(data_x,data_y)\n",
    "\n",
    "#dont forget to shuffle\n",
    "data = np.concatenate([data_x, data_y], axis=1)\n",
    "rng = np.random.default_rng(seed=42)\n",
    "rng.shuffle(data)\n",
    "data_x = data[:, 0:data_x.shape[1]]\n",
    "data_y = data[:, data_x.shape[1]:data.shape[1]]\n",
    "\n",
    "#\n",
    "# To Do: Barrel and Endcap Layer Seperation\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "oss: 0.7447 - accuracy: 0.7317\nEpoch 00003: val_loss improved from 0.78250 to 0.77060, saving model to NumberNetworkKFOLD8.h5\n68/68 [==============================] - 0s 4ms/step - loss: 0.7448 - accuracy: 0.7311 - val_loss: 0.7706 - val_accuracy: 0.7111\nEpoch 4/20\n57/68 [========================>.....] - ETA: 0s - loss: 0.7360 - accuracy: 0.7284\nEpoch 00004: val_loss improved from 0.77060 to 0.75850, saving model to NumberNetworkKFOLD8.h5\n68/68 [==============================] - 0s 4ms/step - loss: 0.7317 - accuracy: 0.7311 - val_loss: 0.7585 - val_accuracy: 0.7111\nEpoch 5/20\n62/68 [==========================>...] - ETA: 0s - loss: 0.7162 - accuracy: 0.7298\nEpoch 00005: val_loss improved from 0.75850 to 0.73119, saving model to NumberNetworkKFOLD8.h5\n68/68 [==============================] - 0s 3ms/step - loss: 0.7133 - accuracy: 0.7311 - val_loss: 0.7312 - val_accuracy: 0.7111\nEpoch 6/20\n58/68 [========================>.....] - ETA: 0s - loss: 0.6814 - accuracy: 0.7333\nEpoch 00006: val_loss improved from 0.73119 to 0.68831, saving model to NumberNetworkKFOLD8.h5\n68/68 [==============================] - 0s 4ms/step - loss: 0.6824 - accuracy: 0.7311 - val_loss: 0.6883 - val_accuracy: 0.7111\nEpoch 7/20\n63/68 [==========================>...] - ETA: 0s - loss: 0.6427 - accuracy: 0.7280\nEpoch 00007: val_loss improved from 0.68831 to 0.63552, saving model to NumberNetworkKFOLD8.h5\n68/68 [==============================] - 0s 3ms/step - loss: 0.6339 - accuracy: 0.7323 - val_loss: 0.6355 - val_accuracy: 0.7111\nEpoch 8/20\n58/68 [========================>.....] - ETA: 0s - loss: 0.5759 - accuracy: 0.7422\nEpoch 00008: val_loss improved from 0.63552 to 0.56004, saving model to NumberNetworkKFOLD8.h5\n68/68 [==============================] - 0s 4ms/step - loss: 0.5735 - accuracy: 0.7420 - val_loss: 0.5600 - val_accuracy: 0.7489\nEpoch 9/20\n68/68 [==============================] - ETA: 0s - loss: 0.5168 - accuracy: 0.7756\nEpoch 00009: val_loss improved from 0.56004 to 0.51030, saving model to NumberNetworkKFOLD8.h5\n68/68 [==============================] - 0s 4ms/step - loss: 0.5168 - accuracy: 0.7756 - val_loss: 0.5103 - val_accuracy: 0.7822\nEpoch 10/20\n61/68 [=========================>....] - ETA: 0s - loss: 0.4779 - accuracy: 0.8030\nEpoch 00010: val_loss improved from 0.51030 to 0.47985, saving model to NumberNetworkKFOLD8.h5\n68/68 [==============================] - 0s 3ms/step - loss: 0.4775 - accuracy: 0.8057 - val_loss: 0.4799 - val_accuracy: 0.8089\nEpoch 11/20\n62/68 [==========================>...] - ETA: 0s - loss: 0.4579 - accuracy: 0.8269\nEpoch 00011: val_loss improved from 0.47985 to 0.46368, saving model to NumberNetworkKFOLD8.h5\n68/68 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.8289 - val_loss: 0.4637 - val_accuracy: 0.8244\nEpoch 12/20\n60/68 [=========================>....] - ETA: 0s - loss: 0.4291 - accuracy: 0.8406\nEpoch 00012: val_loss improved from 0.46368 to 0.46102, saving model to NumberNetworkKFOLD8.h5\n68/68 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.8360 - val_loss: 0.4610 - val_accuracy: 0.8422\nEpoch 13/20\n57/68 [========================>.....] - ETA: 0s - loss: 0.4296 - accuracy: 0.8363\nEpoch 00013: val_loss improved from 0.46102 to 0.44509, saving model to NumberNetworkKFOLD8.h5\n68/68 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.8390 - val_loss: 0.4451 - val_accuracy: 0.8400\nEpoch 14/20\n62/68 [==========================>...] - ETA: 0s - loss: 0.4174 - accuracy: 0.8409\nEpoch 00014: val_loss improved from 0.44509 to 0.44073, saving model to NumberNetworkKFOLD8.h5\n68/68 [==============================] - 0s 3ms/step - loss: 0.4203 - accuracy: 0.8407 - val_loss: 0.4407 - val_accuracy: 0.8467\nEpoch 15/20\n59/68 [=========================>....] - ETA: 0s - loss: 0.4167 - accuracy: 0.8449\nEpoch 00015: val_loss improved from 0.44073 to 0.43735, saving model to NumberNetworkKFOLD8.h5\n68/68 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8449 - val_loss: 0.4373 - val_accuracy: 0.8467\nEpoch 16/20\n64/68 [===========================>..] - ETA: 0s - loss: 0.4085 - accuracy: 0.8456\nEpoch 00016: val_loss improved from 0.43735 to 0.43508, saving model to NumberNetworkKFOLD8.h5\n68/68 [==============================] - 0s 3ms/step - loss: 0.4114 - accuracy: 0.8444 - val_loss: 0.4351 - val_accuracy: 0.8467\nEpoch 17/20\n59/68 [=========================>....] - ETA: 0s - loss: 0.4076 - accuracy: 0.8452\nEpoch 00017: val_loss improved from 0.43508 to 0.43462, saving model to NumberNetworkKFOLD8.h5\n68/68 [==============================] - 0s 4ms/step - loss: 0.4088 - accuracy: 0.8459 - val_loss: 0.4346 - val_accuracy: 0.8400\nEpoch 18/20\n60/68 [=========================>....] - ETA: 0s - loss: 0.4043 - accuracy: 0.8458\nEpoch 00018: val_loss improved from 0.43462 to 0.43278, saving model to NumberNetworkKFOLD8.h5\n68/68 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.8464 - val_loss: 0.4328 - val_accuracy: 0.8400\nEpoch 19/20\n61/68 [=========================>....] - ETA: 0s - loss: 0.3970 - accuracy: 0.8541\nEpoch 00019: val_loss did not improve from 0.43278\n68/68 [==============================] - 0s 3ms/step - loss: 0.4039 - accuracy: 0.8509 - val_loss: 0.4335 - val_accuracy: 0.8444\nEpoch 20/20\n54/68 [======================>.......] - ETA: 0s - loss: 0.4005 - accuracy: 0.8469\nEpoch 00020: val_loss improved from 0.43278 to 0.42970, saving model to NumberNetworkKFOLD8.h5\n68/68 [==============================] - 0s 4ms/step - loss: 0.4021 - accuracy: 0.8481 - val_loss: 0.4297 - val_accuracy: 0.8378\n[2020-07-08 01:49:33,626 INFO] Validating on fold 8 ...\n16/16 [==============================] - 0s 2ms/step - loss: 0.3776 - accuracy: 0.8540\n[2020-07-08 01:49:33,699 INFO] Score for fold 8: loss of 0.3775510787963867; accuracy of 85.39999723434448%\n[2020-07-08 01:49:33,700 INFO] Calculating inference for fold 8 ...\n[2020-07-08 01:49:33,773 INFO] Writing fit history to output/NumberNetworkKFOLD.h5\n[2020-07-08 01:49:33,783 INFO] Building model for fold 9 from share/reference_number.py...\n[2020-07-08 01:49:33,820 INFO] Compiling for fold 9 ...\n[2020-07-08 01:49:33,829 INFO] Training for fold 9 ...\nEpoch 1/20\n59/68 [=========================>....] - ETA: 0s - loss: 0.8797 - accuracy: 0.6271\nEpoch 00001: val_loss improved from inf to 0.79029, saving model to NumberNetworkKFOLD9.h5\n68/68 [==============================] - 0s 5ms/step - loss: 0.8648 - accuracy: 0.6398 - val_loss: 0.7903 - val_accuracy: 0.7111\nEpoch 2/20\n62/68 [==========================>...] - ETA: 0s - loss: 0.7523 - accuracy: 0.7336\nEpoch 00002: val_loss improved from 0.79029 to 0.78470, saving model to NumberNetworkKFOLD9.h5\n68/68 [==============================] - 0s 3ms/step - loss: 0.7552 - accuracy: 0.7323 - val_loss: 0.7847 - val_accuracy: 0.7111\nEpoch 3/20\n57/68 [========================>.....] - ETA: 0s - loss: 0.7452 - accuracy: 0.7336\nEpoch 00003: val_loss improved from 0.78470 to 0.77554, saving model to NumberNetworkKFOLD9.h5\n68/68 [==============================] - 0s 4ms/step - loss: 0.7476 - accuracy: 0.7323 - val_loss: 0.7755 - val_accuracy: 0.7111\nEpoch 4/20\n61/68 [=========================>....] - ETA: 0s - loss: 0.7399 - accuracy: 0.7322\nEpoch 00004: val_loss improved from 0.77554 to 0.76483, saving model to NumberNetworkKFOLD9.h5\n68/68 [==============================] - 0s 4ms/step - loss: 0.7385 - accuracy: 0.7323 - val_loss: 0.7648 - val_accuracy: 0.7111\nEpoch 5/20\n58/68 [========================>.....] - ETA: 0s - loss: 0.7241 - accuracy: 0.7348\nEpoch 00005: val_loss improved from 0.76483 to 0.74932, saving model to NumberNetworkKFOLD9.h5\n68/68 [==============================] - 0s 4ms/step - loss: 0.7268 - accuracy: 0.7323 - val_loss: 0.7493 - val_accuracy: 0.7111\nEpoch 6/20\n61/68 [=========================>....] - ETA: 0s - loss: 0.7066 - accuracy: 0.7342\nEpoch 00006: val_loss improved from 0.74932 to 0.72640, saving model to NumberNetworkKFOLD9.h5\n68/68 [==============================] - 0s 4ms/step - loss: 0.7088 - accuracy: 0.7323 - val_loss: 0.7264 - val_accuracy: 0.7111\nEpoch 7/20\n59/68 [=========================>....] - ETA: 0s - loss: 0.6849 - accuracy: 0.7328\nEpoch 00007: val_loss improved from 0.72640 to 0.69328, saving model to NumberNetworkKFOLD9.h5\n68/68 [==============================] - 0s 4ms/step - loss: 0.6836 - accuracy: 0.7323 - val_loss: 0.6933 - val_accuracy: 0.7111\nEpoch 8/20\n60/68 [=========================>....] - ETA: 0s - loss: 0.6439 - accuracy: 0.7344\nEpoch 00008: val_loss improved from 0.69328 to 0.64138, saving model to NumberNetworkKFOLD9.h5\n68/68 [==============================] - 0s 4ms/step - loss: 0.6434 - accuracy: 0.7331 - val_loss: 0.6414 - val_accuracy: 0.7200\nEpoch 9/20\n58/68 [========================>.....] - ETA: 0s - loss: 0.5915 - accuracy: 0.7572\nEpoch 00009: val_loss improved from 0.64138 to 0.57490, saving model to NumberNetworkKFOLD9.h5\n68/68 [==============================] - 0s 4ms/step - loss: 0.5870 - accuracy: 0.7617 - val_loss: 0.5749 - val_accuracy: 0.7711\nEpoch 10/20\n61/68 [=========================>....] - ETA: 0s - loss: 0.5288 - accuracy: 0.7940\nEpoch 00010: val_loss improved from 0.57490 to 0.51463, saving model to NumberNetworkKFOLD9.h5\n68/68 [==============================] - 0s 4ms/step - loss: 0.5262 - accuracy: 0.7951 - val_loss: 0.5146 - val_accuracy: 0.7822\nEpoch 11/20\n59/68 [=========================>....] - ETA: 0s - loss: 0.4841 - accuracy: 0.8136\nEpoch 00011: val_loss improved from 0.51463 to 0.47890, saving model to NumberNetworkKFOLD9.h5\n68/68 [==============================] - 0s 4ms/step - loss: 0.4811 - accuracy: 0.8143 - val_loss: 0.4789 - val_accuracy: 0.8044\nEpoch 12/20\n60/68 [=========================>....] - ETA: 0s - loss: 0.4532 - accuracy: 0.8267\nEpoch 00012: val_loss improved from 0.47890 to 0.45828, saving model to NumberNetworkKFOLD9.h5\n68/68 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.8281 - val_loss: 0.4583 - val_accuracy: 0.8222\nEpoch 13/20\n58/68 [========================>.....] - ETA: 0s - loss: 0.4342 - accuracy: 0.8353\nEpoch 00013: val_loss improved from 0.45828 to 0.44769, saving model to NumberNetworkKFOLD9.h5\n68/68 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.8348 - val_loss: 0.4477 - val_accuracy: 0.8333\nEpoch 14/20\n59/68 [=========================>....] - ETA: 0s - loss: 0.4251 - accuracy: 0.8387\nEpoch 00014: val_loss improved from 0.44769 to 0.44411, saving model to NumberNetworkKFOLD9.h5\n68/68 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.8390 - val_loss: 0.4441 - val_accuracy: 0.8267\nEpoch 15/20\n61/68 [=========================>....] - ETA: 0s - loss: 0.4180 - accuracy: 0.8404\nEpoch 00015: val_loss improved from 0.44411 to 0.43917, saving model to NumberNetworkKFOLD9.h5\n68/68 [==============================] - 0s 4ms/step - loss: 0.4178 - accuracy: 0.8415 - val_loss: 0.4392 - val_accuracy: 0.8400\nEpoch 16/20\n58/68 [========================>.....] - ETA: 0s - loss: 0.4173 - accuracy: 0.8414\nEpoch 00016: val_loss improved from 0.43917 to 0.43848, saving model to NumberNetworkKFOLD9.h5\n68/68 [==============================] - 0s 4ms/step - loss: 0.4125 - accuracy: 0.8440 - val_loss: 0.4385 - val_accuracy: 0.8400\nEpoch 17/20\n62/68 [==========================>...] - ETA: 0s - loss: 0.4069 - accuracy: 0.8481\nEpoch 00017: val_loss improved from 0.43848 to 0.43647, saving model to NumberNetworkKFOLD9.h5\n68/68 [==============================] - 0s 3ms/step - loss: 0.4077 - accuracy: 0.8469 - val_loss: 0.4365 - val_accuracy: 0.8400\nEpoch 18/20\n59/68 [=========================>....] - ETA: 0s - loss: 0.4059 - accuracy: 0.8441\nEpoch 00018: val_loss improved from 0.43647 to 0.43383, saving model to NumberNetworkKFOLD9.h5\n68/68 [==============================] - 0s 4ms/step - loss: 0.4053 - accuracy: 0.8457 - val_loss: 0.4338 - val_accuracy: 0.8511\nEpoch 19/20\n62/68 [==========================>...] - ETA: 0s - loss: 0.4034 - accuracy: 0.8503\nEpoch 00019: val_loss improved from 0.43383 to 0.43362, saving model to NumberNetworkKFOLD9.h5\n68/68 [==============================] - 0s 4ms/step - loss: 0.4033 - accuracy: 0.8494 - val_loss: 0.4336 - val_accuracy: 0.8356\nEpoch 20/20\n60/68 [=========================>....] - ETA: 0s - loss: 0.4011 - accuracy: 0.8503\nEpoch 00020: val_loss improved from 0.43362 to 0.43146, saving model to NumberNetworkKFOLD9.h5\n68/68 [==============================] - 0s 4ms/step - loss: 0.4000 - accuracy: 0.8521 - val_loss: 0.4315 - val_accuracy: 0.8467\n[2020-07-08 01:49:39,472 INFO] Validating on fold 9 ...\n16/16 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8660\n[2020-07-08 01:49:39,549 INFO] Score for fold 9: loss of 0.36269471049308777; accuracy of 86.59999966621399%\n[2020-07-08 01:49:39,550 INFO] Calculating inference for fold 9 ...\n[2020-07-08 01:49:39,628 INFO] Writing fit history to output/NumberNetworkKFOLD.h5\n[2020-07-08 01:49:39,641 INFO] Building model for fold 10 from share/reference_number.py...\n[2020-07-08 01:49:39,683 INFO] Compiling for fold 10 ...\n[2020-07-08 01:49:39,691 INFO] Training for fold 10 ...\nEpoch 1/20\n60/68 [=========================>....] - ETA: 0s - loss: 0.7948 - accuracy: 0.7069\nEpoch 00001: val_loss improved from inf to 0.73415, saving model to NumberNetworkKFOLD10.h5\n68/68 [==============================] - 0s 5ms/step - loss: 0.7918 - accuracy: 0.7099 - val_loss: 0.7341 - val_accuracy: 0.7444\nEpoch 2/20\n62/68 [==========================>...] - ETA: 0s - loss: 0.7570 - accuracy: 0.7306\nEpoch 00002: val_loss improved from 0.73415 to 0.72595, saving model to NumberNetworkKFOLD10.h5\n68/68 [==============================] - 0s 3ms/step - loss: 0.7581 - accuracy: 0.7296 - val_loss: 0.7259 - val_accuracy: 0.7444\nEpoch 3/20\n58/68 [========================>.....] - ETA: 0s - loss: 0.7478 - accuracy: 0.7307\nEpoch 00003: val_loss improved from 0.72595 to 0.71413, saving model to NumberNetworkKFOLD10.h5\n68/68 [==============================] - 0s 4ms/step - loss: 0.7491 - accuracy: 0.7296 - val_loss: 0.7141 - val_accuracy: 0.7444\nEpoch 4/20\n61/68 [=========================>....] - ETA: 0s - loss: 0.7342 - accuracy: 0.7311\nEpoch 00004: val_loss improved from 0.71413 to 0.69537, saving model to NumberNetworkKFOLD10.h5\n68/68 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.7296 - val_loss: 0.6954 - val_accuracy: 0.7444\nEpoch 5/20\n59/68 [=========================>....] - ETA: 0s - loss: 0.7237 - accuracy: 0.7251\nEpoch 00005: val_loss improved from 0.69537 to 0.66423, saving model to NumberNetworkKFOLD10.h5\n68/68 [==============================] - 0s 4ms/step - loss: 0.7149 - accuracy: 0.7296 - val_loss: 0.6642 - val_accuracy: 0.7444\nEpoch 6/20\n68/68 [==============================] - ETA: 0s - loss: 0.6796 - accuracy: 0.7296\nEpoch 00006: val_loss improved from 0.66423 to 0.61378, saving model to NumberNetworkKFOLD10.h5\n68/68 [==============================] - 0s 4ms/step - loss: 0.6796 - accuracy: 0.7296 - val_loss: 0.6138 - val_accuracy: 0.7444\nEpoch 7/20\n62/68 [==========================>...] - ETA: 0s - loss: 0.6284 - accuracy: 0.7309\nEpoch 00007: val_loss improved from 0.61378 to 0.54252, saving model to NumberNetworkKFOLD10.h5\n68/68 [==============================] - 0s 4ms/step - loss: 0.6230 - accuracy: 0.7341 - val_loss: 0.5425 - val_accuracy: 0.7689\nEpoch 8/20\n59/68 [=========================>....] - ETA: 0s - loss: 0.5634 - accuracy: 0.7681\nEpoch 00008: val_loss improved from 0.54252 to 0.47320, saving model to NumberNetworkKFOLD10.h5\n68/68 [==============================] - 0s 4ms/step - loss: 0.5554 - accuracy: 0.7704 - val_loss: 0.4732 - val_accuracy: 0.8222\nEpoch 9/20\n58/68 [========================>.....] - ETA: 0s - loss: 0.5050 - accuracy: 0.7983\nEpoch 00009: val_loss improved from 0.47320 to 0.42539, saving model to NumberNetworkKFOLD10.h5\n68/68 [==============================] - 0s 4ms/step - loss: 0.5009 - accuracy: 0.8010 - val_loss: 0.4254 - val_accuracy: 0.8333\nEpoch 10/20\n47/68 [===================>..........] - ETA: 0s - loss: 0.4789 - accuracy: 0.8138\nEpoch 00010: val_loss improved from 0.42539 to 0.39650, saving model to NumberNetworkKFOLD10.h5\n68/68 [==============================] - 0s 4ms/step - loss: 0.4658 - accuracy: 0.8202 - val_loss: 0.3965 - val_accuracy: 0.8511\nEpoch 11/20\n60/68 [=========================>....] - ETA: 0s - loss: 0.4465 - accuracy: 0.8269\nEpoch 00011: val_loss improved from 0.39650 to 0.37846, saving model to NumberNetworkKFOLD10.h5\n68/68 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.8291 - val_loss: 0.3785 - val_accuracy: 0.8622\nEpoch 12/20\n59/68 [=========================>....] - ETA: 0s - loss: 0.4317 - accuracy: 0.8379\nEpoch 00012: val_loss improved from 0.37846 to 0.36740, saving model to NumberNetworkKFOLD10.h5\n68/68 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.8378 - val_loss: 0.3674 - val_accuracy: 0.8578\nEpoch 13/20\n60/68 [=========================>....] - ETA: 0s - loss: 0.4217 - accuracy: 0.8419\nEpoch 00013: val_loss improved from 0.36740 to 0.35872, saving model to NumberNetworkKFOLD10.h5\n68/68 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.8402 - val_loss: 0.3587 - val_accuracy: 0.8711\nEpoch 14/20\n59/68 [=========================>....] - ETA: 0s - loss: 0.4201 - accuracy: 0.8401\nEpoch 00014: val_loss improved from 0.35872 to 0.35281, saving model to NumberNetworkKFOLD10.h5\n68/68 [==============================] - 0s 4ms/step - loss: 0.4171 - accuracy: 0.8427 - val_loss: 0.3528 - val_accuracy: 0.8778\nEpoch 15/20\n60/68 [=========================>....] - ETA: 0s - loss: 0.4074 - accuracy: 0.8469\nEpoch 00015: val_loss improved from 0.35281 to 0.35254, saving model to NumberNetworkKFOLD10.h5\n68/68 [==============================] - 0s 3ms/step - loss: 0.4117 - accuracy: 0.8442 - val_loss: 0.3525 - val_accuracy: 0.8778\nEpoch 16/20\n57/68 [========================>.....] - ETA: 0s - loss: 0.4116 - accuracy: 0.8430\nEpoch 00016: val_loss improved from 0.35254 to 0.34571, saving model to NumberNetworkKFOLD10.h5\n68/68 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.8427 - val_loss: 0.3457 - val_accuracy: 0.8756\nEpoch 17/20\n60/68 [=========================>....] - ETA: 0s - loss: 0.4115 - accuracy: 0.8453\nEpoch 00017: val_loss improved from 0.34571 to 0.34210, saving model to NumberNetworkKFOLD10.h5\n68/68 [==============================] - 0s 4ms/step - loss: 0.4060 - accuracy: 0.8459 - val_loss: 0.3421 - val_accuracy: 0.8778\nEpoch 18/20\n60/68 [=========================>....] - ETA: 0s - loss: 0.4033 - accuracy: 0.8481\nEpoch 00018: val_loss improved from 0.34210 to 0.33819, saving model to NumberNetworkKFOLD10.h5\n68/68 [==============================] - 0s 4ms/step - loss: 0.4034 - accuracy: 0.8477 - val_loss: 0.3382 - val_accuracy: 0.8756\nEpoch 19/20\n58/68 [========================>.....] - ETA: 0s - loss: 0.3956 - accuracy: 0.8526\nEpoch 00019: val_loss did not improve from 0.33819\n68/68 [==============================] - 0s 3ms/step - loss: 0.4016 - accuracy: 0.8491 - val_loss: 0.3384 - val_accuracy: 0.8800\nEpoch 20/20\n61/68 [=========================>....] - ETA: 0s - loss: 0.3953 - accuracy: 0.8525\nEpoch 00020: val_loss improved from 0.33819 to 0.33356, saving model to NumberNetworkKFOLD10.h5\n68/68 [==============================] - 0s 3ms/step - loss: 0.3991 - accuracy: 0.8501 - val_loss: 0.3336 - val_accuracy: 0.8756\n[2020-07-08 01:49:45,503 INFO] Validating on fold 10 ...\n16/16 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.8400\n[2020-07-08 01:49:45,578 INFO] Score for fold 10: loss of 0.4139702022075653; accuracy of 83.99999737739563%\n[2020-07-08 01:49:45,579 INFO] Calculating inference for fold 10 ...\n[2020-07-08 01:49:45,656 INFO] Writing fit history to output/NumberNetworkKFOLD.h5\n[2020-07-08 01:49:45,764 INFO] Done training!\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\"\\nfpr_dict = {}\\ntpr_dict = {}\\nfor i,label in enumerate(labels):\\n    #print(f'{label}_{k+1}')\\n    fpr_dict[label] = np.array([])\\n    tpr_dict[label] = np.array([])\\n    for k in range(fold_no):\\n        #print(k)\\n        fpr_dict[label] = np.concatenate([fpr_dict[label], fpr[label+f'_{k+1}']], axis=0)\\n        tpr_dict[label] = np.concatenate([tpr_dict[label], tpr[label+f'_{k+1}']], axis=0)\\n\""
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "fold_no = 0\n",
    "with h5.File(f'output/{args.name}.h5', 'w'):\n",
    "    logging.info(f'output/{args.name}.h5 created/emptied')\n",
    "\n",
    "for train, test in splits:\n",
    "    fold_no += 1\n",
    "    logging.info(f'Building model for fold {fold_no} from {path}...')\n",
    "    model, compile_args, fit_args, params = _build_model(path, data_x, data_y)\n",
    "    compile_args['metrics']=['accuracy']\n",
    "    fit_args['batch_size']=args.batch_size\n",
    "    fit_args['validation_split'] = 0.1\n",
    "    fit_args['epochs'] = args.epochs\n",
    "    fit_args['callbacks'] = [keras.callbacks.TerminateOnNaN(),\n",
    "                             keras.callbacks.ModelCheckpoint(args.name + str(fold_no) + '.h5', save_best_only=True,verbose=1)]\n",
    "                             #keras.callbacks.CSVLogger('output/'+args.name+str(fold_no)+'.csv')]\n",
    "    logging.info(f'Compiling for fold {fold_no} ...')\n",
    "    model.compile(**compile_args)\n",
    "\n",
    "    logging.info(f'Training for fold {fold_no} ...')\n",
    "    history = model.fit(data_x[train], data_y[train], **fit_args)\n",
    "    \n",
    "    logging.info(f'Validating on fold {fold_no} ...')\n",
    "    scores = model.evaluate(data_x[test], data_y[test])\n",
    "    \n",
    "    logging.info(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1] * 100}%')\n",
    "    acc_per_fold.append(scores[1]*100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "    \n",
    "    logging.info(f'Calculating inference for fold {fold_no} ...')\n",
    "    y_pred = model.predict(data_x[test])\n",
    "    #preds.append(y_pred)\n",
    "    #reals.append(data_y[test])\n",
    "    \n",
    "    for i, label in enumerate(labels):\n",
    "        #print(f'{label}_{k+1}')\n",
    "        #thisfpr, thistpr, threshold = roc_curve(data_y[test][:,i], y_pred[:,i])\n",
    "        #fpr[label] = np.concatenate([fpr[label], thisfpr], axis=0)\n",
    "        #tpr[label] = np.concatenate([tpr[label], thistpr], axis=0)\n",
    "        fpr[f'{label}_{fold_no}'], tpr[f'{label}_{fold_no}'], threshold = roc_curve(data_y[test][:,i], y_pred[:,i])\n",
    "        auc1[f'{label}_{fold_no}'] = auc(fpr[f'{label}_{fold_no}'], tpr[f'{label}_{fold_no}'])\n",
    "        \n",
    "    logging.info(f'Writing fit history to output/{args.name}.h5')\n",
    "    with h5.File(f'output/{args.name}.h5', 'a') as hfile:\n",
    "        for key, val in history.history.items():\n",
    "            hfile.create_dataset(key+'_'+str(fold_no), data=np.array(val))\n",
    "        for label in labels:\n",
    "            hfile.create_dataset(f'{label}_{fold_no}_fpr', data=fpr[f'{label}_{fold_no}'])\n",
    "            hfile.create_dataset(f'{label}_{fold_no}_tpr', data=tpr[f'{label}_{fold_no}'])\n",
    "            hfile.create_dataset(f'{label}_{fold_no}_auc', data=auc1[f'{label}_{fold_no}'])\n",
    "    models.append(model)\n",
    "\n",
    "logging.info('Done training!')\n",
    "\n",
    "'''\n",
    "fpr_dict = {}\n",
    "tpr_dict = {}\n",
    "for i,label in enumerate(labels):\n",
    "    #print(f'{label}_{k+1}')\n",
    "    fpr_dict[label] = np.array([])\n",
    "    tpr_dict[label] = np.array([])\n",
    "    for k in range(fold_no):\n",
    "        #print(k)\n",
    "        fpr_dict[label] = np.concatenate([fpr_dict[label], fpr[label+f'_{k+1}']], axis=0)\n",
    "        tpr_dict[label] = np.concatenate([tpr_dict[label], tpr[label+f'_{k+1}']], axis=0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<KeysViewHDF5 ['1particle_10_auc', '1particle_10_fpr', '1particle_10_tpr', '1particle_1_auc', '1particle_1_fpr', '1particle_1_tpr', '1particle_2_auc', '1particle_2_fpr', '1particle_2_tpr', '1particle_3_auc', '1particle_3_fpr', '1particle_3_tpr', '1particle_4_auc', '1particle_4_fpr', '1particle_4_tpr', '1particle_5_auc', '1particle_5_fpr', '1particle_5_tpr', '1particle_6_auc', '1particle_6_fpr', '1particle_6_tpr', '1particle_7_auc', '1particle_7_fpr', '1particle_7_tpr', '1particle_8_auc', '1particle_8_fpr', '1particle_8_tpr', '1particle_9_auc', '1particle_9_fpr', '1particle_9_tpr', '2particle_10_auc', '2particle_10_fpr', '2particle_10_tpr', '2particle_1_auc', '2particle_1_fpr', '2particle_1_tpr', '2particle_2_auc', '2particle_2_fpr', '2particle_2_tpr', '2particle_3_auc', '2particle_3_fpr', '2particle_3_tpr', '2particle_4_auc', '2particle_4_fpr', '2particle_4_tpr', '2particle_5_auc', '2particle_5_fpr', '2particle_5_tpr', '2particle_6_auc', '2particle_6_fpr', '2particle_6_tpr', '2particle_7_auc', '2particle_7_fpr', '2particle_7_tpr', '2particle_8_auc', '2particle_8_fpr', '2particle_8_tpr', '2particle_9_auc', '2particle_9_fpr', '2particle_9_tpr', '3particle_10_auc', '3particle_10_fpr', '3particle_10_tpr', '3particle_1_auc', '3particle_1_fpr', '3particle_1_tpr', '3particle_2_auc', '3particle_2_fpr', '3particle_2_tpr', '3particle_3_auc', '3particle_3_fpr', '3particle_3_tpr', '3particle_4_auc', '3particle_4_fpr', '3particle_4_tpr', '3particle_5_auc', '3particle_5_fpr', '3particle_5_tpr', '3particle_6_auc', '3particle_6_fpr', '3particle_6_tpr', '3particle_7_auc', '3particle_7_fpr', '3particle_7_tpr', '3particle_8_auc', '3particle_8_fpr', '3particle_8_tpr', '3particle_9_auc', '3particle_9_fpr', '3particle_9_tpr', 'accuracy_1', 'accuracy_10', 'accuracy_2', 'accuracy_3', 'accuracy_4', 'accuracy_5', 'accuracy_6', 'accuracy_7', 'accuracy_8', 'accuracy_9', 'loss_1', 'loss_10', 'loss_2', 'loss_3', 'loss_4', 'loss_5', 'loss_6', 'loss_7', 'loss_8', 'loss_9', 'val_accuracy_1', 'val_accuracy_10', 'val_accuracy_2', 'val_accuracy_3', 'val_accuracy_4', 'val_accuracy_5', 'val_accuracy_6', 'val_accuracy_7', 'val_accuracy_8', 'val_accuracy_9', 'val_loss_1', 'val_loss_10', 'val_loss_2', 'val_loss_3', 'val_loss_4', 'val_loss_5', 'val_loss_6', 'val_loss_7', 'val_loss_8', 'val_loss_9']>\n"
    }
   ],
   "source": [
    "with h5.File('output/NumberNetworkKFOLD.h5', 'r') as f:\n",
    "    print(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfoldRoc(infile, labels, name=\"\", outdir=\"\"):\n",
    "\n",
    "    folds = 10\n",
    "    npoints = 200\n",
    "    base_fpr = np.exp(np.linspace(math.log(0.0005), 0., npoints))\n",
    "    avg_tpr = {}\n",
    "    plus_tpr = {}\n",
    "    minus_tpr = {}\n",
    "\n",
    "    fpr_list = [[0]*(folds) for i in range(len(labels))]\n",
    "    tpr_list = [[0]*(folds) for i in range(len(labels))]\n",
    "    auc_list = [[0]*(folds) for i in range(len(labels))]\n",
    "    with h5.File(infile, 'r') as hfile:\n",
    "        for i, label in enumerate(labels):\n",
    "            for j in range(folds):\n",
    "                fpr_list[i][j] = hfile[f'{label}_{j+1}_fpr'][()]\n",
    "                tpr_list[i][j] = hfile[f'{label}_{j+1}_tpr'][()]\n",
    "                auc_list[i][j] = hfile[f'{label}_{j+1}_auc'][()]\n",
    "\n",
    "    fpr_list = np.array(fpr_list)\n",
    "    tpr_list = np.array(tpr_list)\n",
    "    auc_list = np.array(auc_list)\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    for i, particle in enumerate(labels):\n",
    "        tpr_array = np.array([])\n",
    "        for j in range(folds):\n",
    "            tpr_interpolated = np.interp(base_fpr, fpr_list[i][j], tpr_list[i][j])\n",
    "            tpr_interpolated = tpr_interpolated.reshape((1,npoints))\n",
    "            tpr_array = np.concatenate([tpr_array, tpr_interpolated], axis=0) if tpr_array.size else tpr_interpolated\n",
    "        mean_tpr = np.mean(tpr_array, axis=0)\n",
    "        rms_tpr = np.std(tpr_array, axis=0)\n",
    "        plus_tpr[particle] = np.minimum(mean_tpr+rms_tpr, np.ones(npoints))\n",
    "        minus_tpr[particle] = np.maximum(mean_tpr-rms_tpr,np.zeros(npoints))\n",
    "        avg_tpr[particle] = mean_tpr\n",
    "\n",
    "        plt.plot(base_fpr, avg_tpr[particle], label=f'{i+1} particle (AUC = {np.mean(auc_list[i][()]):.2f} (+- {np.std(auc_list[i][()]):.4f}))')\n",
    "        plt.fill_between(base_fpr, minus_tpr[particle], plus_tpr[particle], alpha=0.3)\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], lw=1, color='navy', linestyle='--')\n",
    "    plt.semilogx()\n",
    "    plt.ylabel(\"TPR\")\n",
    "    plt.xlabel(\"FPR\")\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim(0.001,1.05)\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.figtext(0.25, 0.90,f'{name}',fontweight='bold', wrap=True, horizontalalignment='right', fontsize=10)\n",
    "    #plt.figtext(0.35, 0.90,'preliminary', style='italic', wrap=True, horizontalalignment='center', fontsize=14) \n",
    "    plt.savefig(f'{outdir}{name}_ROC.pdf')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-acae5fe5bfd2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'1particle'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'2particle'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'3particle'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mkfoldRoc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'output/{args.name}.h5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"kfold\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"output/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "labels = ['1particle', '2particle', '3particle']\n",
    "kfoldRoc(f'output/{args.name}.h5', labels, \"kfold\", \"output/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learningCurves(infile, outdir=\"\"):\n",
    "\n",
    "    folds = 10\n",
    "    losses = [[0]*(folds) for i in range(2)]\n",
    "\n",
    "    with h5.File(infile, 'r') as hfile:\n",
    "        for i in range(folds):\n",
    "            losses[0][i] = hfile[f'loss_{i+1}'][()]\n",
    "            losses[1][i] = hfile[f'val_loss_{i+1}'][()]\n",
    "\n",
    "    for i in range(len(losses)):\n",
    "        for j in range(folds):\n",
    "            plt.plot(losses[i][j], label= ('val_' if i else '') + f'loss for {j} fold')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], lw=1, color='navy', linestyle='--')\n",
    "    plt.semilogx()\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.xlim([-0.05, 20])\n",
    "    plt.ylim(0.001,1.05)\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.figtext(0.25, 0.90,'loss',fontweight='bold', wrap=True, horizontalalignment='right', fontsize=10)\n",
    "    #plt.figtext(0.35, 0.90,'preliminary', style='italic', wrap=True, horizontalalignment='center', fontsize=14) \n",
    "    plt.savefig(f'{outdir}loss.pdf')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[2020-07-08 04:30:02,286 DEBUG] vmin 0.8631023914792423 vmax 20.0\n[2020-07-08 04:30:02,286 DEBUG] ticklocs array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03])\n[2020-07-08 04:30:02,292 DEBUG] vmin 0.8631023914792423 vmax 20.0\n[2020-07-08 04:30:02,293 DEBUG] ticklocs array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03])\n[2020-07-08 04:30:02,295 DEBUG] vmin 0.8631023914792423 vmax 20.0\n[2020-07-08 04:30:02,296 DEBUG] ticklocs array([2.e-02, 3.e-02, 4.e-02, 5.e-02, 6.e-02, 7.e-02, 8.e-02, 9.e-02,\n       2.e-01, 3.e-01, 4.e-01, 5.e-01, 6.e-01, 7.e-01, 8.e-01, 9.e-01,\n       2.e+00, 3.e+00, 4.e+00, 5.e+00, 6.e+00, 7.e+00, 8.e+00, 9.e+00,\n       2.e+01, 3.e+01, 4.e+01, 5.e+01, 6.e+01, 7.e+01, 8.e+01, 9.e+01,\n       2.e+02, 3.e+02, 4.e+02, 5.e+02, 6.e+02, 7.e+02, 8.e+02, 9.e+02,\n       2.e+03, 3.e+03, 4.e+03, 5.e+03, 6.e+03, 7.e+03, 8.e+03, 9.e+03])\n[2020-07-08 04:30:02,354 DEBUG] Assigning font /b'F1' = 'C:\\\\ProgramData\\\\Anaconda3\\\\envs\\\\MDNtraining_TF\\\\lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSans.ttf'\n[2020-07-08 04:30:02,362 DEBUG] vmin 0.8631023914792423 vmax 20.0\n[2020-07-08 04:30:02,364 DEBUG] ticklocs array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03])\n[2020-07-08 04:30:02,367 DEBUG] vmin 0.8631023914792423 vmax 20.0\n[2020-07-08 04:30:02,368 DEBUG] ticklocs array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03])\n[2020-07-08 04:30:02,370 DEBUG] vmin 0.8631023914792423 vmax 20.0\n[2020-07-08 04:30:02,371 DEBUG] ticklocs array([2.e-02, 3.e-02, 4.e-02, 5.e-02, 6.e-02, 7.e-02, 8.e-02, 9.e-02,\n       2.e-01, 3.e-01, 4.e-01, 5.e-01, 6.e-01, 7.e-01, 8.e-01, 9.e-01,\n       2.e+00, 3.e+00, 4.e+00, 5.e+00, 6.e+00, 7.e+00, 8.e+00, 9.e+00,\n       2.e+01, 3.e+01, 4.e+01, 5.e+01, 6.e+01, 7.e+01, 8.e+01, 9.e+01,\n       2.e+02, 3.e+02, 4.e+02, 5.e+02, 6.e+02, 7.e+02, 8.e+02, 9.e+02,\n       2.e+03, 3.e+03, 4.e+03, 5.e+03, 6.e+03, 7.e+03, 8.e+03, 9.e+03])\n[2020-07-08 04:30:02,462 DEBUG] Assigning font /b'F2' = 'C:\\\\ProgramData\\\\Anaconda3\\\\envs\\\\MDNtraining_TF\\\\lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSans-Bold.ttf'\n[2020-07-08 04:30:02,463 DEBUG] Embedding font C:\\ProgramData\\Anaconda3\\envs\\MDNtraining_TF\\lib\\site-packages\\matplotlib\\mpl-data\\fonts\\ttf\\DejaVuSans-Bold.ttf.\n[2020-07-08 04:30:02,464 DEBUG] Writing TrueType font.\n[2020-07-08 04:30:02,475 DEBUG] Embedding font C:\\ProgramData\\Anaconda3\\envs\\MDNtraining_TF\\lib\\site-packages\\matplotlib\\mpl-data\\fonts\\ttf\\DejaVuSans.ttf.\n[2020-07-08 04:30:02,476 DEBUG] Writing TrueType font.\n[2020-07-08 04:30:02,495 DEBUG] vmin 0.8631023914792423 vmax 20.0\n[2020-07-08 04:30:02,496 DEBUG] ticklocs array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03])\n[2020-07-08 04:30:02,499 DEBUG] vmin 0.8631023914792423 vmax 20.0\n[2020-07-08 04:30:02,500 DEBUG] ticklocs array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03])\n[2020-07-08 04:30:02,503 DEBUG] vmin 0.8631023914792423 vmax 20.0\n[2020-07-08 04:30:02,506 DEBUG] ticklocs array([2.e-02, 3.e-02, 4.e-02, 5.e-02, 6.e-02, 7.e-02, 8.e-02, 9.e-02,\n       2.e-01, 3.e-01, 4.e-01, 5.e-01, 6.e-01, 7.e-01, 8.e-01, 9.e-01,\n       2.e+00, 3.e+00, 4.e+00, 5.e+00, 6.e+00, 7.e+00, 8.e+00, 9.e+00,\n       2.e+01, 3.e+01, 4.e+01, 5.e+01, 6.e+01, 7.e+01, 8.e+01, 9.e+01,\n       2.e+02, 3.e+02, 4.e+02, 5.e+02, 6.e+02, 7.e+02, 8.e+02, 9.e+02,\n       2.e+03, 3.e+03, 4.e+03, 5.e+03, 6.e+03, 7.e+03, 8.e+03, 9.e+03])\n[2020-07-08 04:30:02,541 DEBUG] vmin 0.8631023914792423 vmax 20.0\n[2020-07-08 04:30:02,542 DEBUG] ticklocs array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03])\n[2020-07-08 04:30:02,546 DEBUG] vmin 0.8631023914792423 vmax 20.0\n[2020-07-08 04:30:02,547 DEBUG] ticklocs array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03])\n[2020-07-08 04:30:02,550 DEBUG] vmin 0.8631023914792423 vmax 20.0\n[2020-07-08 04:30:02,551 DEBUG] ticklocs array([2.e-02, 3.e-02, 4.e-02, 5.e-02, 6.e-02, 7.e-02, 8.e-02, 9.e-02,\n       2.e-01, 3.e-01, 4.e-01, 5.e-01, 6.e-01, 7.e-01, 8.e-01, 9.e-01,\n       2.e+00, 3.e+00, 4.e+00, 5.e+00, 6.e+00, 7.e+00, 8.e+00, 9.e+00,\n       2.e+01, 3.e+01, 4.e+01, 5.e+01, 6.e+01, 7.e+01, 8.e+01, 9.e+01,\n       2.e+02, 3.e+02, 4.e+02, 5.e+02, 6.e+02, 7.e+02, 8.e+02, 9.e+02,\n       2.e+03, 3.e+03, 4.e+03, 5.e+03, 6.e+03, 7.e+03, 8.e+03, 9.e+03])\n"
    }
   ],
   "source": [
    "learningCurves(f'output/{args.name}.h5', \"output/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "---Average scores---\nScore per fold\nFold 1 - Loss: 0.0009 - Accuracy: 100.00%\nFold 2 - Loss: 0.0009 - Accuracy: 100.00%\nFold 3 - Loss: 0.0009 - Accuracy: 100.00%\nFold 4 - Loss: 0.0009 - Accuracy: 100.00%\nFold 5 - Loss: 0.0009 - Accuracy: 100.00%\nFold 6 - Loss: 0.0008 - Accuracy: 100.00%\nFold 7 - Loss: 0.0008 - Accuracy: 100.00%\nFold 8 - Loss: 0.0008 - Accuracy: 100.00%\nFold 9 - Loss: 0.0009 - Accuracy: 100.00%\nFold 10 - Loss: 0.0009 - Accuracy: 100.00%\n--------------------\nAverage scores for all folds:\nAccuracy: 100.00 (+- 0.0000)\nLoss: 0.0009 (+- 0.0000)\n---Average AUC------\nFold 1 - 1particle - AUC: nan\nFold 2 - 1particle - AUC: nan\nFold 3 - 1particle - AUC: nan\nFold 4 - 1particle - AUC: nan\nFold 5 - 1particle - AUC: nan\nFold 6 - 1particle - AUC: nan\nFold 7 - 1particle - AUC: nan\nFold 8 - 1particle - AUC: nan\nFold 1 - 2particle - AUC: nan\nFold 2 - 2particle - AUC: nan\nFold 3 - 2particle - AUC: nan\nFold 4 - 2particle - AUC: nan\nFold 5 - 2particle - AUC: nan\nFold 6 - 2particle - AUC: nan\nFold 7 - 2particle - AUC: nan\nFold 8 - 2particle - AUC: nan\nFold 1 - 3particle - AUC: nan\nFold 2 - 3particle - AUC: nan\nFold 3 - 3particle - AUC: nan\nFold 4 - 3particle - AUC: nan\nFold 5 - 3particle - AUC: nan\nFold 6 - 3particle - AUC: nan\nFold 7 - 3particle - AUC: nan\nFold 8 - 3particle - AUC: nan\n--------------------\nAverage AUC for all folds:\n1particle - AUC: nan (+- nan)\n2particle - AUC: nan (+- nan)\n3particle - AUC: nan (+- nan)\n"
    }
   ],
   "source": [
    "print('---Average scores---')\n",
    "print('Score per fold')\n",
    "for i in range(0,len(acc_per_fold)):\n",
    "    print(f'Fold {i+1} - Loss: {loss_per_fold[i]:.4f} - Accuracy: {acc_per_fold[i]:.2f}%')\n",
    "print('--------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'Accuracy: {np.mean(acc_per_fold):.2f} (+- {np.std(acc_per_fold):.4f})')\n",
    "print(f'Loss: {np.mean(loss_per_fold):.4f} (+- {np.std(loss_per_fold):.4f})')\n",
    "print('---Average AUC------')\n",
    "for label in labels:\n",
    "    for i in range(fold_no-1):\n",
    "        print(f'Fold {i+1} - {label} - AUC: {auc1[label][i]*100:.2f}')\n",
    "        \n",
    "print('--------------------')\n",
    "print('Average AUC for all folds:')\n",
    "for label in labels:\n",
    "    print(f'{label} - AUC: {np.mean(auc1[label]):.2f} (+- {np.std(auc1[label]):.4f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_avgs = np.array([])\n",
    "for i in range(len(fpr_list[0])):\n",
    "    fold_vals = np.array([])\n",
    "    for k in range(fold_no-1):\n",
    "        fold_vals = fpr_list[k][i]\n",
    "    fpr_avgs = np.concatenate([fpr_avgs, [np.mean(fold_vals)]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5.File('roc_vals.h5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<KeysViewHDF5 ['auc', 'fpr', 'tpr']>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "f.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['1particle', '2particle', '3particle']>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['auc'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2206934,)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['fpr']['1particle'][()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_list = list(chunks(f['fpr']['1particle'][()], int(f['fpr']['1particle'][()].shape[0]/10))) \n",
    "#should have saved fpr for each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007662695786454886"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr_list[0][220000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fpr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr_list = list(chunks(f['tpr']['1particle'][()], int(f['tpr']['1particle'][()].shape[0]/10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr_avgs = np.array([])\n",
    "for i in range(len(tpr_list[0])):\n",
    "    fold_vals = np.array([])\n",
    "    for k in range(fold_no-1):\n",
    "        fold_vals = tpr_list[k][i]\n",
    "    tpr_avgs = np.concatenate([tpr_avgs, [np.mean(fold_vals)]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexc\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:4: UserWarning: Attempted to set non-positive left xlim on a log-scaled axis.\n",
      "Invalid limit will be ignored.\n",
      "  after removing the cwd from sys.path.\n",
      "[2020-07-06 11:01:05,825 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:05,825 DEBUG] ticklocs array([1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00,\n",
      "       1.e+01, 1.e+02])\n",
      "[2020-07-06 11:01:05,837 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:05,838 DEBUG] ticklocs array([1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00,\n",
      "       1.e+01, 1.e+02])\n",
      "[2020-07-06 11:01:05,841 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:05,842 DEBUG] ticklocs array([1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00,\n",
      "       1.e+01, 1.e+02])\n",
      "[2020-07-06 11:01:05,844 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:05,845 DEBUG] ticklocs array([2.e-07, 3.e-07, 4.e-07, 5.e-07, 6.e-07, 7.e-07, 8.e-07, 9.e-07,\n",
      "       2.e-06, 3.e-06, 4.e-06, 5.e-06, 6.e-06, 7.e-06, 8.e-06, 9.e-06,\n",
      "       2.e-05, 3.e-05, 4.e-05, 5.e-05, 6.e-05, 7.e-05, 8.e-05, 9.e-05,\n",
      "       2.e-04, 3.e-04, 4.e-04, 5.e-04, 6.e-04, 7.e-04, 8.e-04, 9.e-04,\n",
      "       2.e-03, 3.e-03, 4.e-03, 5.e-03, 6.e-03, 7.e-03, 8.e-03, 9.e-03,\n",
      "       2.e-02, 3.e-02, 4.e-02, 5.e-02, 6.e-02, 7.e-02, 8.e-02, 9.e-02,\n",
      "       2.e-01, 3.e-01, 4.e-01, 5.e-01, 6.e-01, 7.e-01, 8.e-01, 9.e-01,\n",
      "       2.e+00, 3.e+00, 4.e+00, 5.e+00, 6.e+00, 7.e+00, 8.e+00, 9.e+00,\n",
      "       2.e+01, 3.e+01, 4.e+01, 5.e+01, 6.e+01, 7.e+01, 8.e+01, 9.e+01,\n",
      "       2.e+02, 3.e+02, 4.e+02, 5.e+02, 6.e+02, 7.e+02, 8.e+02, 9.e+02])\n",
      "[2020-07-06 11:01:05,956 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:05,957 DEBUG] ticklocs array([1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00,\n",
      "       1.e+01, 1.e+02])\n",
      "[2020-07-06 11:01:05,958 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:05,959 DEBUG] ticklocs array([1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00,\n",
      "       1.e+01, 1.e+02])\n",
      "[2020-07-06 11:01:05,961 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:05,961 DEBUG] ticklocs array([2.e-07, 3.e-07, 4.e-07, 5.e-07, 6.e-07, 7.e-07, 8.e-07, 9.e-07,\n",
      "       2.e-06, 3.e-06, 4.e-06, 5.e-06, 6.e-06, 7.e-06, 8.e-06, 9.e-06,\n",
      "       2.e-05, 3.e-05, 4.e-05, 5.e-05, 6.e-05, 7.e-05, 8.e-05, 9.e-05,\n",
      "       2.e-04, 3.e-04, 4.e-04, 5.e-04, 6.e-04, 7.e-04, 8.e-04, 9.e-04,\n",
      "       2.e-03, 3.e-03, 4.e-03, 5.e-03, 6.e-03, 7.e-03, 8.e-03, 9.e-03,\n",
      "       2.e-02, 3.e-02, 4.e-02, 5.e-02, 6.e-02, 7.e-02, 8.e-02, 9.e-02,\n",
      "       2.e-01, 3.e-01, 4.e-01, 5.e-01, 6.e-01, 7.e-01, 8.e-01, 9.e-01,\n",
      "       2.e+00, 3.e+00, 4.e+00, 5.e+00, 6.e+00, 7.e+00, 8.e+00, 9.e+00,\n",
      "       2.e+01, 3.e+01, 4.e+01, 5.e+01, 6.e+01, 7.e+01, 8.e+01, 9.e+01,\n",
      "       2.e+02, 3.e+02, 4.e+02, 5.e+02, 6.e+02, 7.e+02, 8.e+02, 9.e+02])\n",
      "[2020-07-06 11:01:06,014 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:06,015 DEBUG] ticklocs array([1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00,\n",
      "       1.e+01, 1.e+02])\n",
      "[2020-07-06 11:01:06,017 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:06,018 DEBUG] ticklocs array([1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00,\n",
      "       1.e+01, 1.e+02])\n",
      "[2020-07-06 11:01:06,019 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:06,020 DEBUG] ticklocs array([2.e-07, 3.e-07, 4.e-07, 5.e-07, 6.e-07, 7.e-07, 8.e-07, 9.e-07,\n",
      "       2.e-06, 3.e-06, 4.e-06, 5.e-06, 6.e-06, 7.e-06, 8.e-06, 9.e-06,\n",
      "       2.e-05, 3.e-05, 4.e-05, 5.e-05, 6.e-05, 7.e-05, 8.e-05, 9.e-05,\n",
      "       2.e-04, 3.e-04, 4.e-04, 5.e-04, 6.e-04, 7.e-04, 8.e-04, 9.e-04,\n",
      "       2.e-03, 3.e-03, 4.e-03, 5.e-03, 6.e-03, 7.e-03, 8.e-03, 9.e-03,\n",
      "       2.e-02, 3.e-02, 4.e-02, 5.e-02, 6.e-02, 7.e-02, 8.e-02, 9.e-02,\n",
      "       2.e-01, 3.e-01, 4.e-01, 5.e-01, 6.e-01, 7.e-01, 8.e-01, 9.e-01,\n",
      "       2.e+00, 3.e+00, 4.e+00, 5.e+00, 6.e+00, 7.e+00, 8.e+00, 9.e+00,\n",
      "       2.e+01, 3.e+01, 4.e+01, 5.e+01, 6.e+01, 7.e+01, 8.e+01, 9.e+01,\n",
      "       2.e+02, 3.e+02, 4.e+02, 5.e+02, 6.e+02, 7.e+02, 8.e+02, 9.e+02])\n",
      "[2020-07-06 11:01:06,030 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:06,030 DEBUG] ticklocs array([1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00,\n",
      "       1.e+01, 1.e+02])\n",
      "[2020-07-06 11:01:06,032 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:06,032 DEBUG] ticklocs array([1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00,\n",
      "       1.e+01, 1.e+02])\n",
      "[2020-07-06 11:01:06,034 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:06,035 DEBUG] ticklocs array([2.e-07, 3.e-07, 4.e-07, 5.e-07, 6.e-07, 7.e-07, 8.e-07, 9.e-07,\n",
      "       2.e-06, 3.e-06, 4.e-06, 5.e-06, 6.e-06, 7.e-06, 8.e-06, 9.e-06,\n",
      "       2.e-05, 3.e-05, 4.e-05, 5.e-05, 6.e-05, 7.e-05, 8.e-05, 9.e-05,\n",
      "       2.e-04, 3.e-04, 4.e-04, 5.e-04, 6.e-04, 7.e-04, 8.e-04, 9.e-04,\n",
      "       2.e-03, 3.e-03, 4.e-03, 5.e-03, 6.e-03, 7.e-03, 8.e-03, 9.e-03,\n",
      "       2.e-02, 3.e-02, 4.e-02, 5.e-02, 6.e-02, 7.e-02, 8.e-02, 9.e-02,\n",
      "       2.e-01, 3.e-01, 4.e-01, 5.e-01, 6.e-01, 7.e-01, 8.e-01, 9.e-01,\n",
      "       2.e+00, 3.e+00, 4.e+00, 5.e+00, 6.e+00, 7.e+00, 8.e+00, 9.e+00,\n",
      "       2.e+01, 3.e+01, 4.e+01, 5.e+01, 6.e+01, 7.e+01, 8.e+01, 9.e+01,\n",
      "       2.e+02, 3.e+02, 4.e+02, 5.e+02, 6.e+02, 7.e+02, 8.e+02, 9.e+02])\n",
      "[2020-07-06 11:01:06,072 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:06,073 DEBUG] ticklocs array([1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00,\n",
      "       1.e+01, 1.e+02])\n",
      "[2020-07-06 11:01:06,076 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:06,076 DEBUG] ticklocs array([1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00,\n",
      "       1.e+01, 1.e+02])\n",
      "[2020-07-06 11:01:06,077 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:06,078 DEBUG] ticklocs array([2.e-07, 3.e-07, 4.e-07, 5.e-07, 6.e-07, 7.e-07, 8.e-07, 9.e-07,\n",
      "       2.e-06, 3.e-06, 4.e-06, 5.e-06, 6.e-06, 7.e-06, 8.e-06, 9.e-06,\n",
      "       2.e-05, 3.e-05, 4.e-05, 5.e-05, 6.e-05, 7.e-05, 8.e-05, 9.e-05,\n",
      "       2.e-04, 3.e-04, 4.e-04, 5.e-04, 6.e-04, 7.e-04, 8.e-04, 9.e-04,\n",
      "       2.e-03, 3.e-03, 4.e-03, 5.e-03, 6.e-03, 7.e-03, 8.e-03, 9.e-03,\n",
      "       2.e-02, 3.e-02, 4.e-02, 5.e-02, 6.e-02, 7.e-02, 8.e-02, 9.e-02,\n",
      "       2.e-01, 3.e-01, 4.e-01, 5.e-01, 6.e-01, 7.e-01, 8.e-01, 9.e-01,\n",
      "       2.e+00, 3.e+00, 4.e+00, 5.e+00, 6.e+00, 7.e+00, 8.e+00, 9.e+00,\n",
      "       2.e+01, 3.e+01, 4.e+01, 5.e+01, 6.e+01, 7.e+01, 8.e+01, 9.e+01,\n",
      "       2.e+02, 3.e+02, 4.e+02, 5.e+02, 6.e+02, 7.e+02, 8.e+02, 9.e+02])\n",
      "[2020-07-06 11:01:06,088 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:06,088 DEBUG] ticklocs array([1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00,\n",
      "       1.e+01, 1.e+02])\n",
      "[2020-07-06 11:01:06,090 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:06,091 DEBUG] ticklocs array([1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00,\n",
      "       1.e+01, 1.e+02])\n",
      "[2020-07-06 11:01:06,092 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:06,093 DEBUG] ticklocs array([2.e-07, 3.e-07, 4.e-07, 5.e-07, 6.e-07, 7.e-07, 8.e-07, 9.e-07,\n",
      "       2.e-06, 3.e-06, 4.e-06, 5.e-06, 6.e-06, 7.e-06, 8.e-06, 9.e-06,\n",
      "       2.e-05, 3.e-05, 4.e-05, 5.e-05, 6.e-05, 7.e-05, 8.e-05, 9.e-05,\n",
      "       2.e-04, 3.e-04, 4.e-04, 5.e-04, 6.e-04, 7.e-04, 8.e-04, 9.e-04,\n",
      "       2.e-03, 3.e-03, 4.e-03, 5.e-03, 6.e-03, 7.e-03, 8.e-03, 9.e-03,\n",
      "       2.e-02, 3.e-02, 4.e-02, 5.e-02, 6.e-02, 7.e-02, 8.e-02, 9.e-02,\n",
      "       2.e-01, 3.e-01, 4.e-01, 5.e-01, 6.e-01, 7.e-01, 8.e-01, 9.e-01,\n",
      "       2.e+00, 3.e+00, 4.e+00, 5.e+00, 6.e+00, 7.e+00, 8.e+00, 9.e+00,\n",
      "       2.e+01, 3.e+01, 4.e+01, 5.e+01, 6.e+01, 7.e+01, 8.e+01, 9.e+01,\n",
      "       2.e+02, 3.e+02, 4.e+02, 5.e+02, 6.e+02, 7.e+02, 8.e+02, 9.e+02])\n",
      "[2020-07-06 11:01:06,130 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:06,131 DEBUG] ticklocs array([1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00,\n",
      "       1.e+01, 1.e+02])\n",
      "[2020-07-06 11:01:06,134 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:06,134 DEBUG] ticklocs array([1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00,\n",
      "       1.e+01, 1.e+02])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-06 11:01:06,136 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:06,137 DEBUG] ticklocs array([2.e-07, 3.e-07, 4.e-07, 5.e-07, 6.e-07, 7.e-07, 8.e-07, 9.e-07,\n",
      "       2.e-06, 3.e-06, 4.e-06, 5.e-06, 6.e-06, 7.e-06, 8.e-06, 9.e-06,\n",
      "       2.e-05, 3.e-05, 4.e-05, 5.e-05, 6.e-05, 7.e-05, 8.e-05, 9.e-05,\n",
      "       2.e-04, 3.e-04, 4.e-04, 5.e-04, 6.e-04, 7.e-04, 8.e-04, 9.e-04,\n",
      "       2.e-03, 3.e-03, 4.e-03, 5.e-03, 6.e-03, 7.e-03, 8.e-03, 9.e-03,\n",
      "       2.e-02, 3.e-02, 4.e-02, 5.e-02, 6.e-02, 7.e-02, 8.e-02, 9.e-02,\n",
      "       2.e-01, 3.e-01, 4.e-01, 5.e-01, 6.e-01, 7.e-01, 8.e-01, 9.e-01,\n",
      "       2.e+00, 3.e+00, 4.e+00, 5.e+00, 6.e+00, 7.e+00, 8.e+00, 9.e+00,\n",
      "       2.e+01, 3.e+01, 4.e+01, 5.e+01, 6.e+01, 7.e+01, 8.e+01, 9.e+01,\n",
      "       2.e+02, 3.e+02, 4.e+02, 5.e+02, 6.e+02, 7.e+02, 8.e+02, 9.e+02])\n",
      "[2020-07-06 11:01:06,146 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:06,147 DEBUG] ticklocs array([1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00,\n",
      "       1.e+01, 1.e+02])\n",
      "[2020-07-06 11:01:06,149 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:06,149 DEBUG] ticklocs array([1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00,\n",
      "       1.e+01, 1.e+02])\n",
      "[2020-07-06 11:01:06,151 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:06,151 DEBUG] ticklocs array([2.e-07, 3.e-07, 4.e-07, 5.e-07, 6.e-07, 7.e-07, 8.e-07, 9.e-07,\n",
      "       2.e-06, 3.e-06, 4.e-06, 5.e-06, 6.e-06, 7.e-06, 8.e-06, 9.e-06,\n",
      "       2.e-05, 3.e-05, 4.e-05, 5.e-05, 6.e-05, 7.e-05, 8.e-05, 9.e-05,\n",
      "       2.e-04, 3.e-04, 4.e-04, 5.e-04, 6.e-04, 7.e-04, 8.e-04, 9.e-04,\n",
      "       2.e-03, 3.e-03, 4.e-03, 5.e-03, 6.e-03, 7.e-03, 8.e-03, 9.e-03,\n",
      "       2.e-02, 3.e-02, 4.e-02, 5.e-02, 6.e-02, 7.e-02, 8.e-02, 9.e-02,\n",
      "       2.e-01, 3.e-01, 4.e-01, 5.e-01, 6.e-01, 7.e-01, 8.e-01, 9.e-01,\n",
      "       2.e+00, 3.e+00, 4.e+00, 5.e+00, 6.e+00, 7.e+00, 8.e+00, 9.e+00,\n",
      "       2.e+01, 3.e+01, 4.e+01, 5.e+01, 6.e+01, 7.e+01, 8.e+01, 9.e+01,\n",
      "       2.e+02, 3.e+02, 4.e+02, 5.e+02, 6.e+02, 7.e+02, 8.e+02, 9.e+02])\n",
      "[2020-07-06 11:01:06,178 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:06,179 DEBUG] ticklocs array([1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00,\n",
      "       1.e+01, 1.e+02])\n",
      "[2020-07-06 11:01:06,181 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:06,181 DEBUG] ticklocs array([1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00,\n",
      "       1.e+01, 1.e+02])\n",
      "[2020-07-06 11:01:06,184 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:06,185 DEBUG] ticklocs array([2.e-07, 3.e-07, 4.e-07, 5.e-07, 6.e-07, 7.e-07, 8.e-07, 9.e-07,\n",
      "       2.e-06, 3.e-06, 4.e-06, 5.e-06, 6.e-06, 7.e-06, 8.e-06, 9.e-06,\n",
      "       2.e-05, 3.e-05, 4.e-05, 5.e-05, 6.e-05, 7.e-05, 8.e-05, 9.e-05,\n",
      "       2.e-04, 3.e-04, 4.e-04, 5.e-04, 6.e-04, 7.e-04, 8.e-04, 9.e-04,\n",
      "       2.e-03, 3.e-03, 4.e-03, 5.e-03, 6.e-03, 7.e-03, 8.e-03, 9.e-03,\n",
      "       2.e-02, 3.e-02, 4.e-02, 5.e-02, 6.e-02, 7.e-02, 8.e-02, 9.e-02,\n",
      "       2.e-01, 3.e-01, 4.e-01, 5.e-01, 6.e-01, 7.e-01, 8.e-01, 9.e-01,\n",
      "       2.e+00, 3.e+00, 4.e+00, 5.e+00, 6.e+00, 7.e+00, 8.e+00, 9.e+00,\n",
      "       2.e+01, 3.e+01, 4.e+01, 5.e+01, 6.e+01, 7.e+01, 8.e+01, 9.e+01,\n",
      "       2.e+02, 3.e+02, 4.e+02, 5.e+02, 6.e+02, 7.e+02, 8.e+02, 9.e+02])\n",
      "[2020-07-06 11:01:06,194 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:06,195 DEBUG] ticklocs array([1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00,\n",
      "       1.e+01, 1.e+02])\n",
      "[2020-07-06 11:01:06,197 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:06,198 DEBUG] ticklocs array([1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00,\n",
      "       1.e+01, 1.e+02])\n",
      "[2020-07-06 11:01:06,199 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:06,200 DEBUG] ticklocs array([2.e-07, 3.e-07, 4.e-07, 5.e-07, 6.e-07, 7.e-07, 8.e-07, 9.e-07,\n",
      "       2.e-06, 3.e-06, 4.e-06, 5.e-06, 6.e-06, 7.e-06, 8.e-06, 9.e-06,\n",
      "       2.e-05, 3.e-05, 4.e-05, 5.e-05, 6.e-05, 7.e-05, 8.e-05, 9.e-05,\n",
      "       2.e-04, 3.e-04, 4.e-04, 5.e-04, 6.e-04, 7.e-04, 8.e-04, 9.e-04,\n",
      "       2.e-03, 3.e-03, 4.e-03, 5.e-03, 6.e-03, 7.e-03, 8.e-03, 9.e-03,\n",
      "       2.e-02, 3.e-02, 4.e-02, 5.e-02, 6.e-02, 7.e-02, 8.e-02, 9.e-02,\n",
      "       2.e-01, 3.e-01, 4.e-01, 5.e-01, 6.e-01, 7.e-01, 8.e-01, 9.e-01,\n",
      "       2.e+00, 3.e+00, 4.e+00, 5.e+00, 6.e+00, 7.e+00, 8.e+00, 9.e+00,\n",
      "       2.e+01, 3.e+01, 4.e+01, 5.e+01, 6.e+01, 7.e+01, 8.e+01, 9.e+01,\n",
      "       2.e+02, 3.e+02, 4.e+02, 5.e+02, 6.e+02, 7.e+02, 8.e+02, 9.e+02])\n",
      "[2020-07-06 11:01:06,238 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:06,239 DEBUG] ticklocs array([1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00,\n",
      "       1.e+01, 1.e+02])\n",
      "[2020-07-06 11:01:06,241 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:06,242 DEBUG] ticklocs array([1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00,\n",
      "       1.e+01, 1.e+02])\n",
      "[2020-07-06 11:01:06,243 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:06,244 DEBUG] ticklocs array([2.e-07, 3.e-07, 4.e-07, 5.e-07, 6.e-07, 7.e-07, 8.e-07, 9.e-07,\n",
      "       2.e-06, 3.e-06, 4.e-06, 5.e-06, 6.e-06, 7.e-06, 8.e-06, 9.e-06,\n",
      "       2.e-05, 3.e-05, 4.e-05, 5.e-05, 6.e-05, 7.e-05, 8.e-05, 9.e-05,\n",
      "       2.e-04, 3.e-04, 4.e-04, 5.e-04, 6.e-04, 7.e-04, 8.e-04, 9.e-04,\n",
      "       2.e-03, 3.e-03, 4.e-03, 5.e-03, 6.e-03, 7.e-03, 8.e-03, 9.e-03,\n",
      "       2.e-02, 3.e-02, 4.e-02, 5.e-02, 6.e-02, 7.e-02, 8.e-02, 9.e-02,\n",
      "       2.e-01, 3.e-01, 4.e-01, 5.e-01, 6.e-01, 7.e-01, 8.e-01, 9.e-01,\n",
      "       2.e+00, 3.e+00, 4.e+00, 5.e+00, 6.e+00, 7.e+00, 8.e+00, 9.e+00,\n",
      "       2.e+01, 3.e+01, 4.e+01, 5.e+01, 6.e+01, 7.e+01, 8.e+01, 9.e+01,\n",
      "       2.e+02, 3.e+02, 4.e+02, 5.e+02, 6.e+02, 7.e+02, 8.e+02, 9.e+02])\n",
      "[2020-07-06 11:01:06,253 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:06,254 DEBUG] ticklocs array([1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00,\n",
      "       1.e+01, 1.e+02])\n",
      "[2020-07-06 11:01:06,256 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:06,257 DEBUG] ticklocs array([1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00,\n",
      "       1.e+01, 1.e+02])\n",
      "[2020-07-06 11:01:06,258 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:06,259 DEBUG] ticklocs array([2.e-07, 3.e-07, 4.e-07, 5.e-07, 6.e-07, 7.e-07, 8.e-07, 9.e-07,\n",
      "       2.e-06, 3.e-06, 4.e-06, 5.e-06, 6.e-06, 7.e-06, 8.e-06, 9.e-06,\n",
      "       2.e-05, 3.e-05, 4.e-05, 5.e-05, 6.e-05, 7.e-05, 8.e-05, 9.e-05,\n",
      "       2.e-04, 3.e-04, 4.e-04, 5.e-04, 6.e-04, 7.e-04, 8.e-04, 9.e-04,\n",
      "       2.e-03, 3.e-03, 4.e-03, 5.e-03, 6.e-03, 7.e-03, 8.e-03, 9.e-03,\n",
      "       2.e-02, 3.e-02, 4.e-02, 5.e-02, 6.e-02, 7.e-02, 8.e-02, 9.e-02,\n",
      "       2.e-01, 3.e-01, 4.e-01, 5.e-01, 6.e-01, 7.e-01, 8.e-01, 9.e-01,\n",
      "       2.e+00, 3.e+00, 4.e+00, 5.e+00, 6.e+00, 7.e+00, 8.e+00, 9.e+00,\n",
      "       2.e+01, 3.e+01, 4.e+01, 5.e+01, 6.e+01, 7.e+01, 8.e+01, 9.e+01,\n",
      "       2.e+02, 3.e+02, 4.e+02, 5.e+02, 6.e+02, 7.e+02, 8.e+02, 9.e+02])\n",
      "[2020-07-06 11:01:06,290 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:06,290 DEBUG] ticklocs array([1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00,\n",
      "       1.e+01, 1.e+02])\n",
      "[2020-07-06 11:01:06,292 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:06,293 DEBUG] ticklocs array([1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00,\n",
      "       1.e+01, 1.e+02])\n",
      "[2020-07-06 11:01:06,294 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:06,294 DEBUG] ticklocs array([2.e-07, 3.e-07, 4.e-07, 5.e-07, 6.e-07, 7.e-07, 8.e-07, 9.e-07,\n",
      "       2.e-06, 3.e-06, 4.e-06, 5.e-06, 6.e-06, 7.e-06, 8.e-06, 9.e-06,\n",
      "       2.e-05, 3.e-05, 4.e-05, 5.e-05, 6.e-05, 7.e-05, 8.e-05, 9.e-05,\n",
      "       2.e-04, 3.e-04, 4.e-04, 5.e-04, 6.e-04, 7.e-04, 8.e-04, 9.e-04,\n",
      "       2.e-03, 3.e-03, 4.e-03, 5.e-03, 6.e-03, 7.e-03, 8.e-03, 9.e-03,\n",
      "       2.e-02, 3.e-02, 4.e-02, 5.e-02, 6.e-02, 7.e-02, 8.e-02, 9.e-02,\n",
      "       2.e-01, 3.e-01, 4.e-01, 5.e-01, 6.e-01, 7.e-01, 8.e-01, 9.e-01,\n",
      "       2.e+00, 3.e+00, 4.e+00, 5.e+00, 6.e+00, 7.e+00, 8.e+00, 9.e+00,\n",
      "       2.e+01, 3.e+01, 4.e+01, 5.e+01, 6.e+01, 7.e+01, 8.e+01, 9.e+01,\n",
      "       2.e+02, 3.e+02, 4.e+02, 5.e+02, 6.e+02, 7.e+02, 8.e+02, 9.e+02])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-07-06 11:01:06,359 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:06,359 DEBUG] ticklocs array([1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00,\n",
      "       1.e+01, 1.e+02])\n",
      "[2020-07-06 11:01:06,361 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:06,362 DEBUG] ticklocs array([1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00,\n",
      "       1.e+01, 1.e+02])\n",
      "[2020-07-06 11:01:06,363 DEBUG] vmin 2.379756798279619e-06 vmax 1.05\n",
      "[2020-07-06 11:01:06,364 DEBUG] ticklocs array([2.e-07, 3.e-07, 4.e-07, 5.e-07, 6.e-07, 7.e-07, 8.e-07, 9.e-07,\n",
      "       2.e-06, 3.e-06, 4.e-06, 5.e-06, 6.e-06, 7.e-06, 8.e-06, 9.e-06,\n",
      "       2.e-05, 3.e-05, 4.e-05, 5.e-05, 6.e-05, 7.e-05, 8.e-05, 9.e-05,\n",
      "       2.e-04, 3.e-04, 4.e-04, 5.e-04, 6.e-04, 7.e-04, 8.e-04, 9.e-04,\n",
      "       2.e-03, 3.e-03, 4.e-03, 5.e-03, 6.e-03, 7.e-03, 8.e-03, 9.e-03,\n",
      "       2.e-02, 3.e-02, 4.e-02, 5.e-02, 6.e-02, 7.e-02, 8.e-02, 9.e-02,\n",
      "       2.e-01, 3.e-01, 4.e-01, 5.e-01, 6.e-01, 7.e-01, 8.e-01, 9.e-01,\n",
      "       2.e+00, 3.e+00, 4.e+00, 5.e+00, 6.e+00, 7.e+00, 8.e+00, 9.e+00,\n",
      "       2.e+01, 3.e+01, 4.e+01, 5.e+01, 6.e+01, 7.e+01, 8.e+01, 9.e+01,\n",
      "       2.e+02, 3.e+02, 4.e+02, 5.e+02, 6.e+02, 7.e+02, 8.e+02, 9.e+02])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(fpr_avgs, tpr_avgs)\n",
    "plt.semilogx()\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim(0.001,1.05)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-160-23515b8f0e11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mkfoldRoc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'fpr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tpr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'auc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'K-Fold_20_Epochs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutdir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'output/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-159-5b8838556d42>\u001b[0m in \u001b[0;36mkfoldRoc\u001b[1;34m(fpr, tpr, auc, labels, name, outdir)\u001b[0m\n\u001b[0;32m     12\u001b[0m                 \u001b[0mfpr_vals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfpr_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[0mtpr_vals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtpr_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0mfpr_avgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfpr_avgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfold_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m             \u001b[0mtpr_avgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtpr_avgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfold_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m#plt.plot(tpr[label][()],fpr[label][()],\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "kfoldRoc(f['fpr'], f['tpr'], f['auc'], labels=labels, name='K-Fold_20_Epochs', outdir = 'output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5.File('roc_vals.h5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = h5.File('roc_vals.h5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to create file (unable to truncate a file which is already open)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-174-49383ce4f22d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'roc_vals.h5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[0;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m                                swmr=swmr)\n\u001b[0m\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'a'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;31m# Open in append mode (read/write).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to create file (unable to truncate a file which is already open)"
     ]
    }
   ],
   "source": [
    "h = h5.File('roc_vals.h5', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.DataFrame()\n",
    "#fpr = {}\n",
    "#tpr = {}\n",
    "#auc1 = {}\n",
    "#y_pred = model.predict(data_x[test])\n",
    "#for i, label in enumerate(labels):\n",
    "#    fpr[f'{label}_{fold_no}'], tpr[f'{label}_{fold_no}'], threshold = roc_curve(data_y[test][:,i], y_pred[:,i])\n",
    "#    auc1[f'{label}_{fold_no}'] = auc(fpr[f'{label}_{fold_no}'], tpr[f'{label}_{fold_no}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fpr_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#for i,label in enumerate(labels):\n",
    "#    print(f'{label}_{k+1}')\n",
    "#    fpr_dict[label] = np.array([])\n",
    "#    for k in range(fold_no):\n",
    "#        print(k)\n",
    "#        fpr_dict[label] = np.concatenate([fpr_dict[label], fpr[label+f'_{k+1}']], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('MDNtraining_TF': conda)",
   "language": "python",
   "name": "python361064bitmdntrainingtfconda41395b29b3f64ff7b5d12b9937ed94c7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}